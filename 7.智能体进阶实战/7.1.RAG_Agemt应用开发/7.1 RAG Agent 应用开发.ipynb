{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cf1444d",
   "metadata": {},
   "source": [
    "# 1. 环境配置\n",
    "\n",
    "## 1.1 python 环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d8d826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting langchain_chroma\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ae/35/2a6d1191acaad043647e28313b0ecd161d61f09d8be37d1996a90d752c13/langchain_chroma-1.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting chromadb<2.0.0,>=1.3.5 (from langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/00/36/7d2d7b6bb26e53214492d71ccb4e128fa2de4d98a215befb7787deaf2701/chromadb-1.3.7-cp39-abi3-win_amd64.whl (21.9 MB)\n",
      "     ---------------------------------------- 0.0/21.9 MB ? eta -:--:--\n",
      "     ------- -------------------------------- 4.2/21.9 MB 25.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 21.2/21.9 MB 55.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 21.9/21.9 MB 53.1 MB/s  0:00:00\n",
      "Collecting langchain-core<2.0.0,>=1.1.3 (from langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/dd/bb/ddac30cba0c246f7c15d81851311a23dc1455b6e908f624e71fa3b82b3d1/langchain_core-1.2.0-py3-none-any.whl (475 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain_chroma) (2.3.5)\n",
      "Collecting build>=1.0.3 (from chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/cb/8c/2b30c12155ad8de0cf641d76a8b396a16d2c36bc6d50b621a62b7c4567c1/build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain_chroma) (2.12.5)\n",
      "Collecting pybase64>=1.4.1 (from chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/83/e3/507ab649d8c3512c258819c51d25c45d6e29d9ca33992593059e7b646a33/pybase64-1.4.3-cp312-cp312-win_amd64.whl (35 kB)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain_chroma) (0.38.0)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/4f/98/e480cab9a08d1c09b1c59a93dade92c1bb7544826684ff2acbfd10fcfbd4/posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain_chroma) (4.15.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c0/b4/569d298f9fc4d286c11c45e85d9ffa9e877af12ace98af8cab52396e8f46/onnxruntime-1.23.2-cp312-cp312-win_amd64.whl (13.5 MB)\n",
      "     ---------------------------------------- 0.0/13.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 13.5/13.5 MB 76.8 MB/s  0:00:00\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/cf/df/d3f1ddf4bb4cb50ed9b1139cc7b1c54c34a1e7ce8fd1b9a37c0d1551a6bd/opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/81/a3/cc9b66575bd6597b98b886a2067eea2693408d2d5f39dad9ab7fc264f5f3/opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl (19 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/7c/98/e91cf858f203d86f4eccdf763dcf01cf03f1dae80c3750f7e635bfa206b6/opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b3/46/e33a8c93907b631a99377ef4c5f817ab453d0b34f93529421f42ff559671/tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "     ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 2.7/2.7 MB 77.8 MB/s  0:00:00\n",
      "Collecting pypika>=0.48.9 (from chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Using cached pypika-0.48.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain_chroma) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/2c/ab/fc8290c6a4c722e5514d80f62b2dc4c4df1a68a41d1364e625c35990fcf3/overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Collecting importlib-resources (from chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a4/ed/1f1afb2e9e7f38a545d628f864d562a5ae64fe6f7a10e28ffb9b185b4e89/importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/9e/00/7bd478cbb851c04a48baccaa49b75abaa8e4122f7d86da797500cccdd771/grpcio-1.76.0-cp312-cp312-win_amd64.whl (4.7 MB)\n",
      "     ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 4.7/4.7 MB 70.5 MB/s  0:00:00\n",
      "Collecting bcrypt>=4.0.1 (from chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/9f/b9/9d9a641194a730bda138b3dfe53f584d61c58cd5230e37566e83ec2ffa0d/bcrypt-5.0.0-cp39-abi3-win_amd64.whl (150 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/78/64/7713ffe4b5983314e9d436a90d5bd4f63b6054e2aca783a3cfc44cb95bbf/typer-0.20.0-py3-none-any.whl (47 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ca/ec/65f7d563aa4a62dd58777e8f6aa882f15db53b14eb29aba0c28a20f7eb26/kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 2.0/2.0 MB 116.4 MB/s  0:00:00\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain_chroma) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain_chroma) (6.0.3)\n",
      "Collecting mmh3>=4.0.1 (from chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b8/f6/f6abdcfefcedab3c964868048cfe472764ed358c2bf6819a70dd4ed4ed3a/mmh3-5.2.0-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain_chroma) (3.11.5)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain_chroma) (0.28.1)\n",
      "Collecting rich>=10.11.0 (from chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/25/7a/b0178788f8dc6cafce37a212c99565fa1fe7872c70c6c9c1e1a372d9d88f/rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from chromadb<2.0.0,>=1.3.5->langchain_chroma) (4.25.1)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.3->langchain_chroma) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.3->langchain_chroma) (0.4.56)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.3->langchain_chroma) (25.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.3->langchain_chroma) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.3->langchain_chroma) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.3->langchain_chroma) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.3->langchain_chroma) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.3->langchain_chroma) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from httpx>=0.27.0->chromadb<2.0.0,>=1.3.5->langchain_chroma) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from httpx>=0.27.0->chromadb<2.0.0,>=1.3.5->langchain_chroma) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from httpx>=0.27.0->chromadb<2.0.0,>=1.3.5->langchain_chroma) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from httpx>=0.27.0->chromadb<2.0.0,>=1.3.5->langchain_chroma) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb<2.0.0,>=1.3.5->langchain_chroma) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.3.5->langchain_chroma) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.3.5->langchain_chroma) (2.9.0.post0)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/df/73/b6e24bd22e6720ca8ee9a85a0c4a2971af8497d8f3193fa05390cbd46e09/backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.3.5->langchain_chroma) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from pydantic>=1.9->chromadb<2.0.0,>=1.3.5->langchain_chroma) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from pydantic>=1.9->chromadb<2.0.0,>=1.3.5->langchain_chroma) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from pydantic>=1.9->chromadb<2.0.0,>=1.3.5->langchain_chroma) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.3->langchain_chroma) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.3->langchain_chroma) (2.6.1)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/bd/24/12818598c362d7f300f18e74db45963dbcb85150324092410c8b49405e42/pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from build>=1.0.3->chromadb<2.0.0,>=1.3.5->langchain_chroma) (0.4.6)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.3.5->langchain_chroma) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.3.5->langchain_chroma) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.3.5->langchain_chroma) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.3.5->langchain_chroma) (0.30.0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6f/d1/385110a9ae86d91cc14c5282c61fe9f4dc41c0b9f7d423c6ad77038c4448/google_auth-2.43.0-py2.py3-none-any.whl (223 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain_chroma) (1.9.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/3b/5d/63d4ae3b9daea098d5d6f5da83984853c1bbacd5dc826764b249fe119d24/requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.3->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c8/19/4ec628951a74043532ca2cf5d97b7b14863931476d117c471e8e2b1eb39f/urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b0/0d/9feae160378a3553fa9a339b0e9c1a048e147a4127210e286ef18b730f03/durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Collecting cachetools<7.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ab/de/aa4cfc69feb5b3d604310214369979bb222ed0df0e2575a1b6e7af1a5579/cachetools-6.2.3-py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/47/8d/d529b5d697919ba8c11ad626e835d4039be708a35b0d22de83a269a6682c/pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/64/8d/0133e4eb4beed9e425d9a98ed6e081a55d195481b7632472be1af08d2f6b/rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c8/f1/d6a797abb14f6283c0ddff96bbdd46937f64122b8c925cab503dd37f8214/pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ee/1b/00a78aa2e8fbd63f9af08c9c19e6deb3d5d66b4dda677a0f61654680ee89/flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/64/20/4d50191997e917ae13ad0a235c8b42d8c1ab9c3e6fd455ca16d416944355/protobuf-6.33.2-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a2/09/77d55d46fd61b4a135c444fc97158ef34a095e5681d0a6c10b75bf356191/sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "     ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 6.3/6.3 MB 77.4 MB/s  0:00:00\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain_chroma) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain_chroma) (3.23.0)\n",
      "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c4/ab/09169d5a4612a5f92490806649ac8d41e3ec9129c636754575b3553f4ea4/googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8c/02/ffc3e143d89a27ac21fd557365b98bd0653b98de8a101151d5805b5d4c33/opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-proto==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/51/95/b40c96a7b5203005a0b03d8ce8cd212ff23f1793d5ba289c87a097571b18/opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/7a/5e/5958555e09635d09b75de3c4f8b9cae7335ca545d77392ffe7331534c402/opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/94/54/e7d793b573f298e1c9013b8c4dade17d481164aa517d1d7148619c2cedbf/markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.3.5->langchain_chroma) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting huggingface-hub<2.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/df/8d/7ca723a884d55751b70479b8710f06a317296b1fa1c1dec01d0420d13e43/huggingface_hub-1.2.3-py3-none-any.whl (520 kB)\n",
      "Collecting filelock (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/76/91/7216b27286936c16f5b4d0c530087e4a54eead683e6b0b73dd0c64844af6/filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/51/c7/b64cae5dba3a1b138d7123ec36bb5ccd39d39939f18454407e5468f4763f/fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/cb/44/870d44b30e1dcfb6a65932e3e1506c103a8a5aea9103c337e7a53180322c/hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)\n",
      "     ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 2.9/2.9 MB 56.2 MB/s  0:00:00\n",
      "Collecting shellingham (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting typer-slim (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/5e/dd/5cbf31f402f1cc0ab087c94d4669cfa55bd1e818688b910631e131d74e75/typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from typer>=0.9.0->chromadb<2.0.0,>=1.3.5->langchain_chroma) (8.3.1)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6d/de/40a8f202b987d43afc4d54689600ff03ce65680ede2f31df348d7f368b8f/httptools-0.7.1-cp312-cp312-win_amd64.whl (86 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain_chroma) (1.2.1)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/87/0a/90eb755f568de2688cb220171c4191df932232c20946966c27a59c400850/watchfiles-1.1.1-cp312-cp312-win_amd64.whl (288 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/7d/71/abf2ebc3bbfa40f391ce1428c7168fb20582d0ff57019b69ea20fa698043/websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/f0/0f/310fb31e39e2d734ccaa2c0fb981ee41f7bd5056ce9bc29b2248bd569169/humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/5a/dc/491b7661614ab97483abf2056be1deee4dc2490ecbf7bff9ab5cdbac86e1/pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib->kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/be/9c/92789c596b8df838baa98fa71844d84283302f7604ed565dafe5a6b5041a/oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain_chroma)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: pypika, mpmath, flatbuffers, durationpy, websockets, urllib3, sympy, shellingham, pyreadline3, pyproject_hooks, pybase64, pyasn1, protobuf, overrides, oauthlib, mmh3, mdurl, importlib-resources, httptools, hf-xet, grpcio, fsspec, filelock, cachetools, bcrypt, backoff, watchfiles, typer-slim, rsa, pyasn1-modules, opentelemetry-proto, opentelemetry-api, markdown-it-py, humanfriendly, googleapis-common-protos, build, rich, requests-oauthlib, posthog, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, huggingface-hub, google-auth, coloredlogs, typer, tokenizers, opentelemetry-sdk, onnxruntime, kubernetes, opentelemetry-exporter-otlp-proto-grpc, langchain-core, chromadb, langchain_chroma\n",
      "\n",
      "    ---------------------------------------  1/53 [mpmath]\n",
      "    ---------------------------------------  1/53 [mpmath]\n",
      "    ---------------------------------------  1/53 [mpmath]\n",
      "    ---------------------------------------  1/53 [mpmath]\n",
      "   --- ------------------------------------  4/53 [websockets]\n",
      "   --- ------------------------------------  4/53 [websockets]\n",
      "  Attempting uninstall: urllib3\n",
      "   --- ------------------------------------  4/53 [websockets]\n",
      "    Found existing installation: urllib3 2.6.1\n",
      "   --- ------------------------------------  4/53 [websockets]\n",
      "    Uninstalling urllib3-2.6.1:\n",
      "   --- ------------------------------------  4/53 [websockets]\n",
      "      Successfully uninstalled urllib3-2.6.1\n",
      "   --- ------------------------------------  4/53 [websockets]\n",
      "   --- ------------------------------------  5/53 [urllib3]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ---- -----------------------------------  6/53 [sympy]\n",
      "   ----- ----------------------------------  7/53 [shellingham]\n",
      "   ------ ---------------------------------  8/53 [pyreadline3]\n",
      "   -------- ------------------------------- 11/53 [pyasn1]\n",
      "   --------- ------------------------------ 12/53 [protobuf]\n",
      "   --------- ------------------------------ 13/53 [overrides]\n",
      "   ---------- ----------------------------- 14/53 [oauthlib]\n",
      "   ------------ --------------------------- 17/53 [importlib-resources]\n",
      "   -------------- ------------------------- 19/53 [hf-xet]\n",
      "   --------------- ------------------------ 20/53 [grpcio]\n",
      "   --------------- ------------------------ 21/53 [fsspec]\n",
      "   --------------- ------------------------ 21/53 [fsspec]\n",
      "   ---------------- ----------------------- 22/53 [filelock]\n",
      "   -------------------- ------------------- 27/53 [typer-slim]\n",
      "   --------------------- ------------------ 29/53 [pyasn1-modules]\n",
      "   --------------------- ------------------ 29/53 [pyasn1-modules]\n",
      "   --------------------- ------------------ 29/53 [pyasn1-modules]\n",
      "   --------------------- ------------------ 29/53 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 31/53 [opentelemetry-api]\n",
      "   ------------------------ --------------- 32/53 [markdown-it-py]\n",
      "   ------------------------ --------------- 32/53 [markdown-it-py]\n",
      "   ------------------------- -------------- 34/53 [googleapis-common-protos]\n",
      "   ------------------------- -------------- 34/53 [googleapis-common-protos]\n",
      "   --------------------------- ------------ 36/53 [rich]\n",
      "   --------------------------- ------------ 36/53 [rich]\n",
      "   --------------------------- ------------ 36/53 [rich]\n",
      "   ---------------------------- ----------- 38/53 [posthog]\n",
      "   ------------------------ -------- 39/53 [opentelemetry-semantic-conventions]\n",
      "   ------------------------ -------- 39/53 [opentelemetry-semantic-conventions]\n",
      "   ------------------------ -------- 39/53 [opentelemetry-semantic-conventions]\n",
      "   ------------------------------ --------- 41/53 [huggingface-hub]\n",
      "   ------------------------------ --------- 41/53 [huggingface-hub]\n",
      "   ------------------------------ --------- 41/53 [huggingface-hub]\n",
      "   ------------------------------ --------- 41/53 [huggingface-hub]\n",
      "   ------------------------------ --------- 41/53 [huggingface-hub]\n",
      "   ------------------------------- -------- 42/53 [google-auth]\n",
      "   -------------------------------- ------- 43/53 [coloredlogs]\n",
      "   --------------------------------- ------ 45/53 [tokenizers]\n",
      "   ---------------------------------- ----- 46/53 [opentelemetry-sdk]\n",
      "   ---------------------------------- ----- 46/53 [opentelemetry-sdk]\n",
      "   ----------------------------------- ---- 47/53 [onnxruntime]\n",
      "   ----------------------------------- ---- 47/53 [onnxruntime]\n",
      "   ----------------------------------- ---- 47/53 [onnxruntime]\n",
      "   ----------------------------------- ---- 47/53 [onnxruntime]\n",
      "   ----------------------------------- ---- 47/53 [onnxruntime]\n",
      "   ----------------------------------- ---- 47/53 [onnxruntime]\n",
      "   ----------------------------------- ---- 47/53 [onnxruntime]\n",
      "   ----------------------------------- ---- 47/53 [onnxruntime]\n",
      "   ----------------------------------- ---- 47/53 [onnxruntime]\n",
      "   ----------------------------------- ---- 47/53 [onnxruntime]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "  Attempting uninstall: langchain-core\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "    Found existing installation: langchain-core 1.1.2\n",
      "   ------------------------------------ --- 48/53 [kubernetes]\n",
      "   ------------------------------------- -- 50/53 [langchain-core]\n",
      "    Uninstalling langchain-core-1.1.2:\n",
      "   ------------------------------------- -- 50/53 [langchain-core]\n",
      "      Successfully uninstalled langchain-core-1.1.2\n",
      "   ------------------------------------- -- 50/53 [langchain-core]\n",
      "   ------------------------------------- -- 50/53 [langchain-core]\n",
      "   ------------------------------------- -- 50/53 [langchain-core]\n",
      "   ------------------------------------- -- 50/53 [langchain-core]\n",
      "   ------------------------------------- -- 50/53 [langchain-core]\n",
      "   ------------------------------------- -- 50/53 [langchain-core]\n",
      "   -------------------------------------- - 51/53 [chromadb]\n",
      "   -------------------------------------- - 51/53 [chromadb]\n",
      "   -------------------------------------- - 51/53 [chromadb]\n",
      "   -------------------------------------- - 51/53 [chromadb]\n",
      "   -------------------------------------- - 51/53 [chromadb]\n",
      "   -------------------------------------- - 51/53 [chromadb]\n",
      "   -------------------------------------- - 51/53 [chromadb]\n",
      "   -------------------------------------- - 51/53 [chromadb]\n",
      "   ---------------------------------------- 53/53 [langchain_chroma]\n",
      "\n",
      "Successfully installed backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 cachetools-6.2.3 chromadb-1.3.7 coloredlogs-15.0.1 durationpy-0.10 filelock-3.20.0 flatbuffers-25.9.23 fsspec-2025.12.0 google-auth-2.43.0 googleapis-common-protos-1.72.0 grpcio-1.76.0 hf-xet-1.2.0 httptools-0.7.1 huggingface-hub-1.2.3 humanfriendly-10.0 importlib-resources-6.5.2 kubernetes-34.1.0 langchain-core-1.2.0 langchain_chroma-1.1.0 markdown-it-py-4.0.0 mdurl-0.1.2 mmh3-5.2.0 mpmath-1.3.0 oauthlib-3.3.1 onnxruntime-1.23.2 opentelemetry-api-1.39.1 opentelemetry-exporter-otlp-proto-common-1.39.1 opentelemetry-exporter-otlp-proto-grpc-1.39.1 opentelemetry-proto-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 overrides-7.7.0 posthog-5.4.0 protobuf-6.33.2 pyasn1-0.6.1 pyasn1-modules-0.4.2 pybase64-1.4.3 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0 rich-14.2.0 rsa-4.9.1 shellingham-1.5.4 sympy-1.14.0 tokenizers-0.22.1 typer-0.20.0 typer-slim-0.20.0 urllib3-2.3.0 watchfiles-1.1.1 websockets-15.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip install gradio==6.1.0 openai==2.11.0 dashscope==1.25.4 langchain-classic==1.0.0 langchain==1.1.3 langchain-community==0.4.1 langchain-openai==1.1.3 beautifulsoup4==4.14.3 langchain_chroma==1.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d58b25",
   "metadata": {},
   "source": [
    "## 1.2 大模型密钥准备\n",
    "\n",
    "请根据第一章内容获取相关平台的 API KEY，如若未在系统变量中填入，请将 API_KEY 信息写入以下代码（若已设置请忽略）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d381259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxx\"\n",
    "# os.environ[\"DASHSCOPE_API_KEY\"] = \"sk-yyyyyyyy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129be05b",
   "metadata": {},
   "source": [
    "# 2. RAG Agent 应用开发\n",
    "\n",
    "## 2.1 简介\n",
    "\n",
    "在第四章里我们已经学习过如何创建并使用向量数据库（RAG），那假如我们希望从向量数据库中获取信息并应用到智能体中，我们就需要先完成第一步制作数据库后才能实现。\n",
    "\n",
    "在完成向量数据库的创建后，我们就可以将检索的过程进行封装，然后输入就是用户提出或智能体润色后的问题，输出就是搜索到的片段信息。\n",
    "\n",
    "当我们基于前面的代码创建出了一个向量数据库后："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac39ac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://zh.d2l.ai/chapter_introduction/index.html\")\n",
    "docs = loader.load()\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "  chunk_size = 1500,\n",
    "  chunk_overlap = 150)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "import os\n",
    "embeddings = DashScopeEmbeddings(\n",
    "  dashscope_api_key=os.getenv('DASHSCOPE_API_KEY'), \n",
    "  model=\"text-embedding-v1\")\n",
    "vectordb = Chroma.from_documents(documents=splits,\n",
    "  embedding=embeddings,\n",
    "  persist_directory='./chroma')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a3009f",
   "metadata": {},
   "source": [
    "然后我们就可以通过 Chroma 加载向量数据库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0888a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "import os\n",
    "\n",
    "embeddings = DashScopeEmbeddings(\n",
    "    dashscope_api_key=os.getenv(\"DASHSCOPE_API_KEY\"), model=\"text-embedding-v1\"\n",
    ")\n",
    "vectordb = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma\"  # 必须与创建数据库的路径一致\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aab1dc7",
   "metadata": {},
   "source": [
    "然后将提问→检索向量数据库→回复相关片段这一流程改造成工具来进行使用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17729dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_context(query: str):\n",
    "    \"\"\"Retrieve information to help answer a query.\"\"\"\n",
    "    retrieved_docs = vectordb.similarity_search(query, k=1)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e11fd1",
   "metadata": {},
   "source": [
    "这里设置的 response_format 表示不仅把拼接后的 serialized 注入到 ToolMessage 的 content 里。同时也会把 retrieved_docs 单独保存到 ToolMessage 的 artifact 字段中。\n",
    "\n",
    "然后我们需要将大模型、工具、提示词统一配置到 create_agent 中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c1664f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatTongyi\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "llm = ChatTongyi(model=\"qwen-max\") \n",
    "\n",
    "tools = [retrieve_context]\n",
    "\n",
    "prompt = (\n",
    "    \"You have access to a tool that retrieves context from a deep learning book. \"\n",
    "    \"Use the tool to help answer user queries.\"\n",
    ")\n",
    "\n",
    "agent = create_agent(llm, tools, system_prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76a3438",
   "metadata": {},
   "source": [
    "创建完成后我们就可以根据书本里的问题对其进行调用了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98d4a571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the deep learning model used in computer vision tasks? \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (call_d8ce6e626c4b446bb807bc)\n",
      " Call ID: call_d8ce6e626c4b446bb807bc\n",
      "  Args:\n",
      "    query: deep learning model used in computer vision tasks\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "Source: {'source': 'https://zh.d2l.ai/chapter_introduction/index.html', 'title': '1. 引言 — 动手学深度学习 2.0.0 documentation', 'language': 'en'}\n",
      "Content: 1.7. 特点¶\n",
      "到目前为止，本节已经广泛地讨论了机器学习，它既是人工智能的一个分支，也是人工智能的一种方法。\n",
      "虽然深度学习是机器学习的一个子集，但令人眼花缭乱的算法和应用程序集让人很难评估深度学习的具体成分是什么。\n",
      "这就像试图确定披萨所需的配料一样困难，因为几乎每种成分都是可以替代的。\n",
      "如前所述，机器学习可以使用数据来学习输入和输出之间的转换，例如在语音识别中将音频转换为文本。\n",
      "在这样做时，通常需要以适合算法的方式表示数据，以便将这种表示转换为输出。\n",
      "深度学习是“深度”的，模型学习了许多“层”的转换，每一层提供一个层次的表示。\n",
      "例如，靠近输入的层可以表示数据的低级细节，而接近分类输出的层可以表示用于区分的更抽象的概念。\n",
      "由于表示学习（representation\n",
      "learning）目的是寻找表示本身，因此深度学习可以称为“多级表示学习”。\n",
      "本节到目前为止讨论的问题，例如从原始音频信号中学习，图像的原始像素值，或者任意长度的句子与外语中的对应句子之间的映射，都是深度学习优于传统机器学习方法的问题。\n",
      "事实证明，这些多层模型能够以以前的工具所不能的方式处理低级的感知数据。\n",
      "毋庸置疑，深度学习方法中最显著的共同点是使用端到端训练。\n",
      "也就是说，与其基于单独调整的组件组装系统，不如构建系统，然后联合调整它们的性能。\n",
      "例如，在计算机视觉中，科学家们习惯于将特征工程的过程与建立机器学习模型的过程分开。\n",
      "Canny边缘检测器 (Canny, 1987) 和SIFT特征提取器\n",
      "(Lowe, 2004)\n",
      "作为将图像映射到特征向量的算法，在过去的十年里占据了至高无上的地位。\n",
      "在过去的日子里，将机器学习应用于这些问题的关键部分是提出人工设计的特征工程方法，将数据转换为某种适合于浅层模型的形式。\n",
      "然而，与一个算法自动执行的数百万个选择相比，人类通过特征工程所能完成的事情很少。\n",
      "当深度学习开始时，这些特征抽取器被自动调整的滤波器所取代，产生了更高的精确度。\n",
      "因此，深度学习的一个关键优势是它不仅取代了传统学习管道末端的浅层模型，而且还取代了劳动密集型的特征工程过程。\n",
      "此外，通过取代大部分特定领域的预处理，深度学习消除了以前分隔计算机视觉、语音识别、自然语言处理、医学信息学和其他应用领域的许多界限，为解决各种问题提供了一套统一的工具。\n",
      "除了端到端的训练，人们正在经历从参数统计描述到完全非参数模型的转变。\n",
      "当数据稀缺时，人们需要依靠简化对现实的假设来获得有用的模型。\n",
      "当数据丰富时，可以用更准确地拟合实际情况的非参数模型来代替。\n",
      "在某种程度上，这反映了物理学在上个世纪中叶随着计算机的出现所经历的进步。\n",
      "现在人们可以借助于相关偏微分方程的数值模拟，而不是用手来求解电子行为的参数近似。这导致了更精确的模型，尽管常常以牺牲可解释性为代价。\n",
      "与以前工作的另一个不同之处是接受次优解，处理非凸非线性优化问题，并且愿意在证明之前尝试。\n",
      "这种在处理统计问题上新发现的经验主义，加上人才的迅速涌入，导致了实用算法的快速进步。\n",
      "尽管在许多情况下，这是以修改和重新发明存在了数十年的工具为代价的。\n",
      "最后，深度学习社区引以为豪的是，他们跨越学术界和企业界共享工具，发布了许多优秀的算法库、统计模型和经过训练的开源神经网络。\n",
      "正是本着这种精神，本书免费分发和使用。我们努力降低每个人了解深度学习的门槛，希望读者能从中受益。\n",
      "\n",
      "\n",
      "1.8. 小结¶\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "One of the key deep learning models used in computer vision tasks is a multi-layer model, where each layer provides a level of representation. For example, layers closer to the input can represent low-level details of the data, while layers near the classification output can represent more abstract concepts used for differentiation. A significant advantage of deep learning is that it not only replaces the shallow models at the end of the traditional learning pipeline but also the labor-intensive feature engineering process. In the past, manually designed feature extraction methods like the Canny edge detector and SIFT feature extractor were commonly used in computer vision. With the advent of deep learning, these have been replaced by automatically tuned filters, which have led to higher accuracy.\n",
      "\n",
      "A specific type of deep learning model often used in computer vision is Convolutional Neural Networks (CNNs). CNNs are particularly effective for image recognition and processing as they can capture spatial hierarchies from images. They are designed to automatically and adaptively learn spatial hierarchies of features through backpropagation from the raw pixel values. If you need more information on CNNs or any other particular deep learning model, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "query = (\n",
    "    \"What is the deep learning model used in computer vision tasks? \"\n",
    ")\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf03caf",
   "metadata": {},
   "source": [
    "我们可以通过以下方式来进行创建（前提是需要创建并加载数据库）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "facf82ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "@dynamic_prompt\n",
    "def prompt_with_context(request: ModelRequest) -> str:\n",
    "    \"\"\"自动根据用户问题检索知识并注入到系统提示\"\"\"\n",
    "    last_query = request.state[\"messages\"][-1].text\n",
    "    retrieved_docs = vectordb.similarity_search(last_query, k=3)\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "    system_message = (\n",
    "        \"You are a helpful assistant. \"\n",
    "        \"Use the following retrieved context to answer the user:\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    print(system_message)\n",
    "    return system_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a6f42c",
   "metadata": {},
   "source": [
    "创建完后，可以以中间键的形式添加到 Agent 中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81884a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent \n",
    "\n",
    "llm = ChatTongyi(model=\"qwen-max\") \n",
    "agent = create_agent(llm, tools=[], middleware=[prompt_with_context])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f675ad22",
   "metadata": {},
   "source": [
    "然后可以正常对其进行调用，这个时候就会把检索到的信息添加到系统提示词后进行回复："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0d2f40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is computer vision?\n",
      "You are a helpful assistant. Use the following retrieved context to answer the user:\n",
      "\n",
      "同样，上面的列表仅仅触及了机器学习对实际应用的影响之处的皮毛。\n",
      "例如，机器人学、物流、计算生物学、粒子物理学和天文学最近取得的一些突破性进展至少部分归功于机器学习。\n",
      "因此，机器学习正在成为工程师和科学家必备的工具。\n",
      "关于人工智能的非技术性文章中，经常提到人工智能奇点的问题：机器学习系统会变得有知觉，并独立于主人来决定那些直接影响人类生计的事情。\n",
      "在某种程度上，人工智能已经直接影响到人类的生计：信誉度的自动评估，车辆的自动驾驶，保释决定的自动准予等等。\n",
      "甚至，我们可以让Alexa打开咖啡机。\n",
      "幸运的是，我们离一个能够控制人类创造者的有知觉的人工智能系统还很远。\n",
      "首先，人工智能系统是以一种特定的、面向目标的方式设计、训练和部署的。\n",
      "虽然他们的行为可能会给人一种通用智能的错觉，但设计的基础是规则、启发式和统计模型的结合。\n",
      "其次，目前还不存在能够自我改进、自我推理、能够在试图解决一般任务的同时，修改、扩展和改进自己的架构的“人工通用智能”工具。\n",
      "一个更紧迫的问题是人工智能在日常生活中的应用。\n",
      "卡车司机和店员完成的许多琐碎的工作很可能也将是自动化的。\n",
      "农业机器人可能会降低有机农业的成本，它们也将使收割作业自动化。\n",
      "工业革命的这一阶段可能对社会的大部分地区产生深远的影响，因为卡车司机和店员是许多国家最常见的工作之一。\n",
      "此外，如果不加注意地应用统计模型，可能会导致种族、性别或年龄偏见，如果自动驱动相应的决策，则会引起对程序公平性的合理关注。\n",
      "重要的是要确保小心使用这些算法。\n",
      "就我们今天所知，这比恶意超级智能毁灭人类的风险更令人担忧。\n",
      "\n",
      "12. 计算性能\n",
      "12.1. 编译器和解释器\n",
      "12.2. 异步计算\n",
      "12.3. 自动并行\n",
      "12.4. 硬件\n",
      "12.5. 多GPU训练\n",
      "12.6. 多GPU的简洁实现\n",
      "12.7. 参数服务器\n",
      "\n",
      "\n",
      "13. 计算机视觉\n",
      "13.1. 图像增广\n",
      "13.2. 微调\n",
      "13.3. 目标检测和边界框\n",
      "13.4. 锚框\n",
      "13.5. 多尺度目标检测\n",
      "13.6. 目标检测数据集\n",
      "13.7. 单发多框检测（SSD）\n",
      "13.8. 区域卷积神经网络（R-CNN）系列\n",
      "13.9. 语义分割和数据集\n",
      "13.10. 转置卷积\n",
      "13.11. 全卷积网络\n",
      "13.12. 风格迁移\n",
      "13.13. 实战 Kaggle 比赛：图像分类 (CIFAR-10)\n",
      "13.14. 实战Kaggle比赛：狗的品种识别（ImageNet Dogs）\n",
      "\n",
      "\n",
      "14. 自然语言处理：预训练\n",
      "14.1. 词嵌入（word2vec）\n",
      "14.2. 近似训练\n",
      "14.3. 用于预训练词嵌入的数据集\n",
      "14.4. 预训练word2vec\n",
      "14.5. 全局向量的词嵌入（GloVe）\n",
      "14.6. 子词嵌入\n",
      "14.7. 词的相似性和类比任务\n",
      "14.8. 来自Transformers的双向编码器表示（BERT）\n",
      "14.9. 用于预训练BERT的数据集\n",
      "14.10. 预训练BERT\n",
      "\n",
      "\n",
      "15. 自然语言处理：应用\n",
      "15.1. 情感分析及数据集\n",
      "15.2. 情感分析：使用循环神经网络\n",
      "15.3. 情感分析：使用卷积神经网络\n",
      "15.4. 自然语言推断与数据集\n",
      "15.5. 自然语言推断：使用注意力\n",
      "15.6. 针对序列级和词元级应用微调BERT\n",
      "15.7. 自然语言推断：微调BERT\n",
      "\n",
      "\n",
      "16. 附录：深度学习工具\n",
      "16.1. 使用Jupyter Notebook\n",
      "16.2. 使用Amazon SageMaker\n",
      "16.3. 使用Amazon EC2实例\n",
      "16.4. 选择服务器和GPU\n",
      "16.5. 为本书做贡献\n",
      "16.6. d2l API 文档\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "参考文献\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1. 引言¶\n",
      "时至今日，人们常用的计算机程序几乎都是软件开发人员从零编写的。\n",
      "比如，现在开发人员要编写一个程序来管理网上商城。\n",
      "经过思考，开发人员可能提出如下一个解决方案：\n",
      "首先，用户通过Web浏览器（或移动应用程序）与应用程序进行交互；\n",
      "紧接着，应用程序与数据库引擎进行交互，以保存交易历史记录并跟踪每个用户的动态；\n",
      "其中，这个应用程序的核心——“业务逻辑”，详细说明了应用程序在各种情况下进行的操作。\n",
      "为了完善业务逻辑，开发人员必须细致地考虑应用程序所有可能遇到的边界情况，并为这些边界情况设计合适的规则。\n",
      "当买家单击将商品添加到购物车时，应用程序会向购物车数据库表中添加一个条目，将该用户ID与商品ID关联起来。\n",
      "虽然一次编写出完美应用程序的可能性微乎其微，但在大多数情况下，开发人员可以从上述的业务逻辑出发，编写出符合业务逻辑的应用程序，并不断测试直到满足用户的需求。\n",
      "根据业务逻辑设计自动化系统，驱动正常运行的产品和系统，是一个人类认知上的非凡壮举。\n",
      "幸运的是，对日益壮大的机器学习科学家群体来说，实现很多任务的自动化并不再屈从于人类所能考虑到的逻辑。\n",
      "想象一下，假如开发人员要试图解决以下问题之一：\n",
      "\n",
      "1.7. 特点¶\n",
      "到目前为止，本节已经广泛地讨论了机器学习，它既是人工智能的一个分支，也是人工智能的一种方法。\n",
      "虽然深度学习是机器学习的一个子集，但令人眼花缭乱的算法和应用程序集让人很难评估深度学习的具体成分是什么。\n",
      "这就像试图确定披萨所需的配料一样困难，因为几乎每种成分都是可以替代的。\n",
      "如前所述，机器学习可以使用数据来学习输入和输出之间的转换，例如在语音识别中将音频转换为文本。\n",
      "在这样做时，通常需要以适合算法的方式表示数据，以便将这种表示转换为输出。\n",
      "深度学习是“深度”的，模型学习了许多“层”的转换，每一层提供一个层次的表示。\n",
      "例如，靠近输入的层可以表示数据的低级细节，而接近分类输出的层可以表示用于区分的更抽象的概念。\n",
      "由于表示学习（representation\n",
      "learning）目的是寻找表示本身，因此深度学习可以称为“多级表示学习”。\n",
      "本节到目前为止讨论的问题，例如从原始音频信号中学习，图像的原始像素值，或者任意长度的句子与外语中的对应句子之间的映射，都是深度学习优于传统机器学习方法的问题。\n",
      "事实证明，这些多层模型能够以以前的工具所不能的方式处理低级的感知数据。\n",
      "毋庸置疑，深度学习方法中最显著的共同点是使用端到端训练。\n",
      "也就是说，与其基于单独调整的组件组装系统，不如构建系统，然后联合调整它们的性能。\n",
      "例如，在计算机视觉中，科学家们习惯于将特征工程的过程与建立机器学习模型的过程分开。\n",
      "Canny边缘检测器 (Canny, 1987) 和SIFT特征提取器\n",
      "(Lowe, 2004)\n",
      "作为将图像映射到特征向量的算法，在过去的十年里占据了至高无上的地位。\n",
      "在过去的日子里，将机器学习应用于这些问题的关键部分是提出人工设计的特征工程方法，将数据转换为某种适合于浅层模型的形式。\n",
      "然而，与一个算法自动执行的数百万个选择相比，人类通过特征工程所能完成的事情很少。\n",
      "当深度学习开始时，这些特征抽取器被自动调整的滤波器所取代，产生了更高的精确度。\n",
      "因此，深度学习的一个关键优势是它不仅取代了传统学习管道末端的浅层模型，而且还取代了劳动密集型的特征工程过程。\n",
      "此外，通过取代大部分特定领域的预处理，深度学习消除了以前分隔计算机视觉、语音识别、自然语言处理、医学信息学和其他应用领域的许多界限，为解决各种问题提供了一套统一的工具。\n",
      "除了端到端的训练，人们正在经历从参数统计描述到完全非参数模型的转变。\n",
      "当数据稀缺时，人们需要依靠简化对现实的假设来获得有用的模型。\n",
      "当数据丰富时，可以用更准确地拟合实际情况的非参数模型来代替。\n",
      "在某种程度上，这反映了物理学在上个世纪中叶随着计算机的出现所经历的进步。\n",
      "现在人们可以借助于相关偏微分方程的数值模拟，而不是用手来求解电子行为的参数近似。这导致了更精确的模型，尽管常常以牺牲可解释性为代价。\n",
      "与以前工作的另一个不同之处是接受次优解，处理非凸非线性优化问题，并且愿意在证明之前尝试。\n",
      "这种在处理统计问题上新发现的经验主义，加上人才的迅速涌入，导致了实用算法的快速进步。\n",
      "尽管在许多情况下，这是以修改和重新发明存在了数十年的工具为代价的。\n",
      "最后，深度学习社区引以为豪的是，他们跨越学术界和企业界共享工具，发布了许多优秀的算法库、统计模型和经过训练的开源神经网络。\n",
      "正是本着这种精神，本书免费分发和使用。我们努力降低每个人了解深度学习的门槛，希望读者能从中受益。\n",
      "\n",
      "\n",
      "1.8. 小结¶\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Computer vision is a field of artificial intelligence that trains computers to interpret and understand the visual world. Using digital images from cameras and videos, as well as deep learning models, machines can accurately identify and classify objects, and then react to what they \"see.\" This process involves several key steps and techniques, such as image augmentation, fine-tuning, object detection (including the use of bounding boxes and anchor boxes), multi-scale object detection, and semantic segmentation. Additionally, it includes the use of various neural network architectures like Single Shot MultiBox Detector (SSD), Region-based Convolutional Neural Networks (R-CNN) series, fully convolutional networks, and transposed convolutions for tasks such as style transfer. These technologies are widely used in applications ranging from self-driving cars to medical imaging, and even in participating in Kaggle competitions for image classification and object recognition.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is computer vision?\"\n",
    "for step in agent.stream(\n",
    "  {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "  stream_mode=\"values\",\n",
    "):\n",
    "  step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b10af1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chapter1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
