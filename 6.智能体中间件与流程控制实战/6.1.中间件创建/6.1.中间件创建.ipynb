{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da8d393e",
   "metadata": {},
   "source": [
    "# 1. ç¯å¢ƒé…ç½®\n",
    "\n",
    "## 1.1 python ç¯å¢ƒå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea9d7c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: openai==2.11.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: dashscope==1.25.4 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (1.25.4)\n",
      "Requirement already satisfied: langchain-classic==1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain==1.1.3 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: langchain-community==0.4.1 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-openai==1.1.3 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: arxiv==2.3.1 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from openai==2.11.0) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from openai==2.11.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from openai==2.11.0) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from openai==2.11.0) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from openai==2.11.0) (2.12.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from openai==2.11.0) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from openai==2.11.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from openai==2.11.0) (4.15.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (3.13.2)\n",
      "Requirement already satisfied: requests in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (2.32.5)\n",
      "Requirement already satisfied: websocket-client in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (1.9.0)\n",
      "Requirement already satisfied: cryptography in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (46.0.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (2025.11.12)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (1.2.2)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (1.1.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.17 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (0.5.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (6.0.3)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (2.0.45)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain==1.1.3) (1.0.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (2.3.5)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-openai==1.1.3) (0.12.0)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from arxiv==2.3.1) (6.0.12)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from anyio<5,>=3.5.0->openai==2.11.0) (3.11)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1) (0.9.0)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from feedparser~=6.0.10->arxiv==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from httpx<1,>=0.23.0->openai==2.11.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==2.11.0) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic==1.0.0) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic==1.0.0) (25.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic==1.0.0) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-classic==1.0.0) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (0.3.0)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (1.12.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic==1.0.0) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic==1.0.0) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==2.11.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==2.11.0) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==2.11.0) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community==0.4.1) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from requests->dashscope==1.25.4) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from requests->dashscope==1.25.4) (2.6.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from sqlalchemy<3.0.0,>=1.4.0->langchain-classic==1.0.0) (3.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai==1.1.3) (2025.11.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from tqdm>4->openai==2.11.0) (0.4.6)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from cryptography->dashscope==1.25.4) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from cffi>=2.0.0->cryptography->dashscope==1.25.4) (2.23)\n"
     ]
    }
   ],
   "source": [
    "! pip install openai==2.11.0 dashscope==1.25.4 langchain-classic==1.0.0 langchain==1.1.3 langchain-community==0.4.1 langchain-openai==1.1.3 arxiv==2.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc61d32",
   "metadata": {},
   "source": [
    "## 1.2 å¤§æ¨¡å‹å¯†é’¥å‡†å¤‡\n",
    "\n",
    "è¯·æ ¹æ®ç¬¬ä¸€ç« å†…å®¹è·å–ç›¸å…³å¹³å°çš„ API KEYï¼Œå¦‚è‹¥æœªåœ¨ç³»ç»Ÿå˜é‡ä¸­å¡«å…¥ï¼Œè¯·å°† API_KEY ä¿¡æ¯å†™å…¥ä»¥ä¸‹ä»£ç ï¼ˆè‹¥å·²è®¾ç½®è¯·å¿½ç•¥ï¼‰ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "276f3fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxx\"\n",
    "# os.environ[\"DASHSCOPE_API_KEY\"] = \"sk-yyyyyyyy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270ac407",
   "metadata": {},
   "source": [
    "## 1.3 å®è·µä»£ç \n",
    "\n",
    "ä¸ºäº†èƒ½å¤Ÿé¡ºåˆ©çš„æ¼”ç¤ºå†…ç½®ä¸­é—´ä»¶çš„ä½¿ç”¨è¯¦æƒ…ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¸€æ®µç®€å•çš„æ™ºèƒ½ä½“ä»£ç æ¼”ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e7c394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®ºæ–‡ç¼–å· 1605.08386 çš„ä¿¡æ¯å¦‚ä¸‹ï¼š\n",
      "\n",
      "- **å‘è¡¨æ—¥æœŸ**ï¼š2016-05-26\n",
      "- **æ ‡é¢˜**ï¼šHeat-bath random walks with Markov bases\n",
      "- **ä½œè€…**ï¼šCaprice Stanley, Tobias Windisch\n",
      "- **æ‘˜è¦**ï¼šç ”ç©¶äº†ç”±æœ‰é™å…è®¸ç§»åŠ¨é›†ç”Ÿæˆçš„æ ¼ç‚¹å›¾ï¼Œè¿™äº›ç§»åŠ¨å¯ä»¥æ˜¯ä»»æ„é•¿åº¦ã€‚æˆ‘ä»¬è¯æ˜äº†åœ¨å›ºå®šæ•´æ•°çŸ©é˜µçš„çº¤ç»´ä¸Šçš„è¿™äº›å›¾çš„ç›´å¾„å¯ä»¥ä»ä¸Šé¢ç”±ä¸€ä¸ªå¸¸æ•°ç•Œã€‚ç„¶åç ”ç©¶äº†è¿™äº›å›¾ä¸Šçš„çƒ­æµ´éšæœºæ¸¸èµ°çš„æ··åˆè¡Œä¸ºã€‚è¿˜ç»™å‡ºäº†ç§»åŠ¨é›†çš„æ˜¾å¼æ¡ä»¶ï¼Œä½¿å¾—çƒ­æµ´éšæœºæ¸¸èµ°ï¼ˆGlauberåŠ¨åŠ›å­¦çš„ä¸€ç§æ¨å¹¿ï¼‰åœ¨å›ºå®šç»´åº¦ä¸‹æ˜¯ä¸€ä¸ªæ‰©å±•å™¨ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "llm = ChatTongyi(api_key=os.environ.get(\"DASHSCOPE_API_KEY\"), model=\"qwen-turbo\")\n",
    "\n",
    "from langchain_community.agent_toolkits.load_tools import load_tools\n",
    "tools = load_tools([\"arxiv\"])\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver \n",
    "memory = InMemorySaver()\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "agent = create_agent(model=llm, \n",
    "                     tools=tools, \n",
    "                     system_prompt=\"You are a helpful assistant\", \n",
    "                     checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660aa9dc",
   "metadata": {},
   "source": [
    "# 2. åˆ›å»ºä¸­é—´ä»¶ï¼ˆMiddleWareï¼‰\n",
    "\n",
    "## 2.1 ä¸­é—´ä»¶ç®€ä»‹\n",
    "\n",
    "ä¼ ç»Ÿ ReAct Agent çš„æ ¸å¿ƒå¾ªç¯è™½ç„¶å·²ç»èƒ½å®ç°ã€Œæ¨ç†â€”è¡ŒåŠ¨â€”è§‚å¯Ÿã€çš„é—­ç¯ï¼Œä½†åœ¨å®é™…ç”Ÿäº§ä¸­ï¼Œæˆ‘ä»¬å¸¸å¸¸éœ€è¦æ›´ç»†ç²’åº¦åœ°æ§åˆ¶æ¨¡å‹è°ƒç”¨å’Œå·¥å…·è°ƒç”¨çš„è¿‡ç¨‹ï¼ˆä¾‹å¦‚ï¼šæ—¥å¿—è®°å½•ã€å¼‚å¸¸æ•è·ã€å®‰å…¨è¿‡æ»¤ã€åŠ¨æ€ä¸Šä¸‹æ–‡æ³¨å…¥ç­‰ï¼‰ã€‚\n",
    "\n",
    "å› æ­¤ï¼ŒLangChain v1.0 åœ¨åŸºäº create_agent() çš„åŸºç¡€ä¸Šï¼Œåœ¨åº•å±‚å¼•å…¥äº† Middlewareï¼ˆä¸­é—´ä»¶ï¼‰æœºåˆ¶ â€”â€” è®©å¼€å‘è€…å¯ä»¥åœ¨æ™ºèƒ½ä½“æ‰§è¡Œçš„æ¯ä¸€ä¸ªå…³é”®é˜¶æ®µã€Œå‰åæŒ‚é’©ã€ã€‚\n",
    "\n",
    "æ¯”å¦‚åœ¨æ¨¡å‹è°ƒç”¨å‰å¤„ç†è¾“å…¥ã€åœ¨å·¥å…·è°ƒç”¨åæ‹¦æˆªè¾“å‡ºï¼Œä»è€ŒçœŸæ­£å®ç°å¯è§‚æµ‹ã€å¯è°ƒè¯•ã€å¯æ‰©å±•çš„æ™ºèƒ½ä½“æ‰§è¡Œæµç¨‹ã€‚\n",
    "\n",
    "æˆ‘ä»¬å¯ä»¥æŠŠ MiddleWare ä¸­é—´ä»¶æƒ³è±¡ä¸ºæ˜¯ä¸€ä¸ªâ€œé’©å­ç³»ç»Ÿï¼ˆhook systemï¼‰â€ï¼Œå¯ä»¥åœ¨æ™ºèƒ½ä½“æ¯ä¸€æ­¥æ‰§è¡Œå‰åæ’å…¥è‡ªå®šä¹‰é€»è¾‘ã€‚å¸¸è§çš„å¯æ’å…¥ä½ç½®åŒ…æ‹¬ï¼š\n",
    "- agent å¼€å§‹å‰åï¼šbefore_agent/after_agent\n",
    "- æ¨¡å‹è°ƒç”¨å‰åï¼šbefore_model/after_model\n",
    "- å·¥å…·è°ƒç”¨æ—¶ï¼šwrap_tool_call\n",
    "- æ¨¡å‹è°ƒç”¨æ—¶ï¼šwrap_model_call\n",
    "\n",
    "è¿™äº›å¯æ’å…¥ä½ç½®æ•´ä½“å¯ä»¥åˆ†ä¸ºä¸¤ç±»ï¼š\n",
    "- Node-style hooksï¼šæ˜¯åœ¨å›ºå®šèŠ‚ç‚¹çš„æ‰§è¡Œå‰æˆ–æ‰§è¡Œåè¿è¡Œçš„å‡½æ•°ã€‚å…¶ç‰¹ç‚¹æ˜¯ä¸ä¼šæ‹¦æˆªæ‰§è¡Œæµç¨‹ï¼Œå‡å¦‚æœ‰è¿”å›å€¼ä¼šåˆå¹¶è¿›å½“å‰çš„ stateï¼Œå¹¶ä¸”å¯ä»¥æå‰ç»ˆæ­¢æ‰§è¡Œï¼ˆjump_toï¼‰ã€‚\n",
    "- Wrap-style hooksï¼šæ˜¯çœŸæ­£çš„æ‹¦æˆªå™¨ï¼Œå› ä¸ºå…¶åŒ…è£¹ç€æ¨¡å‹æˆ–å·¥å…·çš„æ‰§è¡Œé€»è¾‘ï¼Œå¹¶ä¸”æ‹¥æœ‰å®Œå…¨æ§åˆ¶æƒã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ handler(request) æ¥å†³å®šè¦ä¸è¦è°ƒç”¨ã€ä½•æ—¶è°ƒç”¨ã€è°ƒç”¨å‡ æ¬¡ã€‚å¹¶ä¸”å¯ä»¥æ”¹è¾“å…¥ã€æ”¹è¾“å‡ºã€å¤„ç†å¼‚å¸¸ï¼Œç”šè‡³å¯ä»¥å®Œå…¨æ›¿æ¢æ•´ä¸ªæ‰§è¡Œé€»è¾‘ã€‚\n",
    "\n",
    "åœ¨ LangChain ä¸­ï¼Œå‡å¦‚æˆ‘ä»¬è¦è‡ªå®šä¹‰ä¸­é—´ä»¶ï¼Œé€šå¸¸æœ‰ä¸¤ç§å†™æ³•ã€‚ä¸€ç§æ˜¯â€œè£…é¥°å™¨å¼ï¼ˆDecorator-basedï¼‰â€ã€‚å¦ä¸€ç§æ˜¯â€œç±»å¼ï¼ˆClass-basedï¼‰â€ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66ffecb",
   "metadata": {},
   "source": [
    "## 2.2 è£…é¥°å™¨å¼ï¼ˆDecorator-basedï¼‰\n",
    "\n",
    "è£…é¥°å™¨å¼ä¸­é—´ä»¶ç­‰äºæˆ‘ä»¬å†™ä¸€ä¸ªæ™®é€šçš„ Python å‡½æ•°ï¼Œç„¶åç”¨å®˜æ–¹æä¾›çš„è£…é¥°å™¨ï¼ˆæ¯”å¦‚ @before_model , @after_model , @wrap_tool_callï¼‰æŠŠè¿™ä¸ªå‡½æ•°æ³¨å†Œæˆä¸€ä¸ªâ€œä¸­é—´ä»¶é’©å­ï¼ˆhookï¼‰â€ã€‚è¿™ä¸ªæ–¹æ³•ä¸»è¦é’ˆå¯¹æŸä¸€ä¸ªç‰¹å®šçš„æ’å…¥ä½ç½®å®ç°ï¼Œé€‚ç”¨äºæ¯”è¾ƒç®€å•çš„åœºæ™¯ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de55dcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import before_model, AgentState\n",
    "from langgraph.runtime import Runtime\n",
    "\n",
    "@before_model\n",
    "def log_before_model(state: AgentState, runtime: Runtime):\n",
    "    print(f\"ğŸ“¤ è°ƒç”¨æ¨¡å‹å‰çš„æ¶ˆæ¯æ•°é‡: {len(state['messages'])}\")\n",
    "\n",
    "agent = create_agent(model=llm, \n",
    " tools=tools, \n",
    " system_prompt=\"You are a helpful assistant\", \n",
    " middleware=[log_before_model], # æ·»åŠ ä¸­é—´ä»¶\n",
    " checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f79523",
   "metadata": {},
   "source": [
    "## 2.2 ç±»å¼ï¼ˆClass-basedï¼‰\n",
    "\n",
    "ç±»å¼ä¸­é—´ä»¶æ˜¯â€œé¢å‘å¯¹è±¡é£æ ¼çš„é’©å­é›†åˆâ€ã€‚å…¶å…è®¸æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªç»§æ‰¿è‡ª AgentMiddleware çš„ç±»ï¼Œè¿™ä¸ªç±»æœ¬èº«å°±èƒ½å¤Ÿå»å®šä¹‰ before_modelï¼Œafter_model ç­‰æ–¹æ³•ã€‚ç„¶ååœ¨è¿™ä¸ªç±»é‡Œå®ç°ä»»æ„å¤šä¸ªç”Ÿå‘½å‘¨æœŸæ–¹æ³•ï¼ˆHookï¼‰ï¼Œè¿™äº›æ–¹æ³•åœ¨ Agent çš„ä¸åŒé˜¶æ®µè‡ªåŠ¨è¢«è°ƒç”¨ã€‚æˆ‘ä»¬ä¼ å…¥ä¸€ä¸ªä¸­é—´ä»¶ç±»å°±ç­‰äºåŒæ—¶ä¼ å…¥å¤šä¸ªè£…é¥°å™¨å¼ä¸­é—´ä»¶ï¼Œå› æ­¤é€‚ç”¨äºæ¯”è¾ƒå¤æ‚çš„åœºæ™¯ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b22f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import AgentMiddleware\n",
    "\n",
    "class MyMiddleware(AgentMiddleware):\n",
    "    def before_model(self, state, runtime):\n",
    "        ...\n",
    "    def after_model(self, state, runtime):\n",
    "        ...\n",
    "\n",
    "agent = create_agent(model=llm, \n",
    " tools=tools, \n",
    " system_prompt=\"You are a helpful assistant\", \n",
    " middleware=[MyMiddleware()],\n",
    " checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e069ffbd",
   "metadata": {},
   "source": [
    "å…¶å®å‰é¢çš„è£…é¥°å™¨å¼çš„æ–¹å¼ä»åº•å±‚æ¥è¯´ä¹Ÿæ˜¯ç”Ÿæˆäº†ä¸€ä¸ª AgentMiddleware å­ç±»ã€‚æ¯”å¦‚ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4b1f642",
   "metadata": {},
   "outputs": [],
   "source": [
    "@before_model\n",
    "def log_before_model(state, runtime):\n",
    "    print(f\"æ¨¡å‹å³å°†è°ƒç”¨ï¼Œæ¶ˆæ¯æ•° {len(state['messages'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdf914a",
   "metadata": {},
   "source": [
    "LangChain å†…éƒ¨å…¶å®æ‰§è¡Œäº†ç±»ä¼¼çš„ä»£ç ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "314a645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogBeforeModel(AgentMiddleware):\n",
    "    def before_model(self, state, runtime):\n",
    "        print(f\"æ¨¡å‹å³å°†è°ƒç”¨ï¼Œæ¶ˆæ¯æ•° {len(state['messages'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37758b86",
   "metadata": {},
   "source": [
    "æ‰€ä»¥æˆ‘ä»¬å†™è£…é¥°å™¨ç‰ˆæœ¬ï¼Œæœ¬è´¨ä¸Šå°±æ˜¯å†™â€œåŒ¿åç±»ä¸­é—´ä»¶â€ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66cf47d",
   "metadata": {},
   "source": [
    "# 3. Node-style hooks\n",
    "\n",
    "Node-style hooks åŒ…æ‹¬ï¼š\n",
    "- agent å¼€å§‹å‰åï¼šbefore_agent/after_agent\n",
    "- æ¨¡å‹è°ƒç”¨å‰åï¼šbefore_model/after_model\n",
    "\n",
    "å¯¹äº Node-style hooks è€Œè¨€ï¼Œå…¶æ•´ä½“çš„è¾“å…¥å’Œè¾“å‡ºçš„å‚æ•°éƒ½æ˜¯ä¸€è‡´çš„ï¼Œæ‰€ä»¥è¿™é‡Œæˆ‘ä»¬å°±æ‰“åŒ…ä¸€èµ·æ¥è¿›è¡Œå±•ç¤ºï¼š\n",
    "- è¾“å…¥å‚æ•°ï¼šstateï¼ˆå½“å‰ Agent çš„å®Œæ•´çŠ¶æ€ï¼‰, runtimeï¼ˆå½“å‰è¿è¡Œç¯å¢ƒå¯¹è±¡ï¼‰\n",
    "- è¾“å‡ºå†…å®¹ï¼šNoneï¼ˆä¸æ›´æ–°çŠ¶æ€ï¼‰ï¼Œdictï¼ˆæ›´æ–°çŠ¶æ€ï¼‰\n",
    "\n",
    "## 3.1 è¾“å…¥å‚æ•° AgentState ï¼ˆåŠ¨æ€ä¿¡æ¯ï¼‰\n",
    "\n",
    "AgentState æ˜¯ä¸€ä¸ªç”¨äºç®¡ç† Agent å½“å‰çŠ¶æ€çš„ç»“æ„ï¼ˆSchemaï¼‰ã€‚å®ƒä¿å­˜æ™ºèƒ½ä½“åœ¨æ¯ä¸ªæ—¶é—´ç‚¹ä¸Šéœ€è¦è®°ä½çš„æ‰€æœ‰ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚å…¶é»˜è®¤çš„ç»“æ„æ˜¯ä¸‹é¢è¿™æ ·çš„ï¼š\n",
    "\n",
    "```python\n",
    "{\"messages\": [...],\n",
    "  \"thread_model_call_count\": 1,\n",
    "  \"run_model_call_count\": 1}\n",
    "```\n",
    "\n",
    "é‚£æ‰€æœ‰çš„ä¸Šä¸‹æ–‡è®°å¿†éƒ½ä¼šå­˜åœ¨ messages ä¹‹ä¸­ã€‚\n",
    "\n",
    "å‡å¦‚æˆ‘ä»¬æƒ³è¦æ·»åŠ ä¸€äº›è‡ªå®šä¹‰çš„å­—æ®µåˆ° AgentStateä¸­ï¼Œæˆ‘ä»¬éœ€è¦å…ˆå®šä¹‰ä¸€ä¸ªç±»ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52ef7bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import AgentState\n",
    "\n",
    "class CustomAgentState(AgentState):\n",
    "    user_id: str\n",
    "    preferences: dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ce8348",
   "metadata": {},
   "source": [
    "è¿™ä¸ªç±»æ˜¯ç»§æ‰¿åŸæœ¬çš„ AgentState çš„ï¼Œæ‰€ä»¥ä¼šæŠŠåŸæœ¬çš„å†…å®¹éƒ½ä¿ç•™ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥åœ¨ create_agent çš„æ—¶å€™é€šè¿‡ state_schema å‚æ•°å°†å…¶åŠ å…¥è¿›å»ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fdfbd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    " model=llm,\n",
    " tools=tools,\n",
    " state_schema=CustomAgentState,\n",
    " checkpointer=InMemorySaver(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933d589d",
   "metadata": {},
   "source": [
    "å¹¶åœ¨è°ƒç”¨æ—¶è¿›è¡Œä¼ å…¥ï¼Œæ­¤æ—¶æ‰“å°çš„å†…å®¹ä¸­å°±å¯ä»¥çœ‹åˆ°ä¼ å…¥çš„ç›¸å…³ä¿¡æ¯äº†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6386cec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Hello', additional_kwargs={}, response_metadata={}, id='e50b53b8-aa97-47e8-8d80-84b7d6af8f60'), AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'stop', 'request_id': 'eec3ac6b-a0da-47d6-aeb4-ba0bb17f1c64', 'token_usage': {'input_tokens': 206, 'output_tokens': 9, 'prompt_tokens_details': {'cached_tokens': 0}, 'total_tokens': 215}}, id='lc_run--019b2fc3-b236-7960-b009-63d0dc53c321-0')], 'user_id': 'user_123', 'preferences': {'theme': 'dark'}}\n",
      "user_123\n",
      "{'theme': 'dark'}\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "        \"user_id\": \"user_123\",  \n",
    "        \"preferences\": {\"theme\": \"dark\"}  \n",
    "    },\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}})\n",
    "\n",
    "print(result)\n",
    "print(result[\"user_id\"])\n",
    "print(result[\"preferences\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de267b7",
   "metadata": {},
   "source": [
    "## 3.2 è¾“å…¥å‚æ•° Runtime ï¼ˆé™æ€ä¿¡æ¯ï¼‰\n",
    "\n",
    "Runtime æ˜¯ LangChain åœ¨æ¯æ¬¡ agent æ‰§è¡ŒæœŸé—´ä¼ é€’ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å¯¹è±¡ï¼Œé€šå¸¸ç”¨äºå­˜æ”¾ç”¨æˆ·ä¿¡æ¯ã€æ•°æ®åº“è¿æ¥ã€é•¿æœŸè®°å¿†ç­‰è¿è¡Œæ‰€éœ€èµ„æºã€‚\n",
    "å…¶å†…éƒ¨å­˜æ”¾ç€ä¸‰ç±»çš„ä¿¡æ¯ï¼š\n",
    "- .contextï¼šç”¨æˆ·ä¿¡æ¯ï¼ˆè‡ªè¡Œåœ¨ create_agent() ä¸­å®šä¹‰çš„ï¼‰\n",
    "- .storeï¼šé•¿æœŸè®°å¿†çš„ç›¸å…³ä¿¡æ¯\n",
    "- .streamï¼šæµå¤±è¾“å‡ºç›¸å…³ä¿¡æ¯\n",
    "\n",
    "```python\n",
    "Runtime(context=Context(\n",
    "    user_id=\"user_123\",\n",
    "    role=\"admin\"\n",
    "  ),\n",
    "  store=<RedisStore>,\n",
    "  stream=<CustomStreamWriter>)\n",
    "```\n",
    "\n",
    "å‡å¦‚æˆ‘ä»¬å¸Œæœ›è‡ªå·±æ¥å®šä¹‰ runtime.context çš„è¯ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦è‡ªå®šä¹‰ä¸€ä¸ªæœ‰ user_name å­—æ®µçš„ç±»ï¼Œå¹¶ä¸”æ ‡æ˜å…¶å¯¹äºçš„æ ¼å¼ä¿¡æ¯ï¼ˆä½¿ç”¨ dataclass è£…é¥°å™¨å®šä¹‰ç»“æ„ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd993443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_name: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd02c114",
   "metadata": {},
   "source": [
    "ç„¶ååœ¨åˆ›å»º agent æ—¶è¿›è¡Œç»‘å®šï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4221cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    " model=llm,\n",
    " tools=tools,\n",
    " context_schema=Context, # âœ… è¿™é‡ŒæŒ‡å®šç»“æ„\n",
    " checkpointer=InMemorySaver(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66890a6",
   "metadata": {},
   "source": [
    "ä½†æ˜¯æˆ‘ä»¬ç›´æ¥æ‰“å°è°ƒç”¨ç»“æœçš„è¯æ˜¯æ²¡åŠæ³•çœ‹åˆ° Runtime çš„ï¼Œå› ä¸ºé‡Œé¢åªä¼šæ˜¾ç¤º AgentState çš„åŠ¨æ€ä¿¡æ¯ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f8b5ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='893c416d-34df-44d3-9500-c5b2f2bac9c7'), AIMessage(content=\"I don't have access to personal information about individual users. If you have any questions or need assistance, feel free to ask!\", additional_kwargs={}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'stop', 'request_id': 'f0a1bfa3-3b18-43c9-82c4-7ad0c7c1fc45', 'token_usage': {'input_tokens': 210, 'output_tokens': 26, 'prompt_tokens_details': {'cached_tokens': 0}, 'total_tokens': 236}}, id='lc_run--019b2fc3-b6fa-76b3-8000-5f7a1229d965-0')]}\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my name?\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": \"2\"}},\n",
    "    context=Context(user_name=\"John Smith\") # âœ… è¿™é‡Œä¼ å…¥å®ä¾‹\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a7ec4c",
   "metadata": {},
   "source": [
    "æ‰€ä»¥æˆ‘ä»¬å‡å¦‚æƒ³è¦ä½¿ç”¨çš„è¯å°±éœ€è¦æ·»åŠ ä¸­é—´ä»¶è¿›è¡Œå±•ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe2ffd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing request for user: John Smith\n"
     ]
    }
   ],
   "source": [
    "@before_model\n",
    "def log_before_model(state: AgentState, runtime: Runtime[Context]) -> dict | None:  \n",
    "    print(f\"Processing request for user: {runtime.context.user_name}\")  \n",
    "    return None\n",
    "\n",
    "agent = create_agent(\n",
    " model=llm,\n",
    " tools=tools,\n",
    " context_schema=Context, # âœ… è¿™é‡ŒæŒ‡å®šç»“æ„\n",
    " checkpointer=InMemorySaver(),\n",
    " middleware=[log_before_model],\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my name?\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": \"2\"}},\n",
    "    context=Context(user_name=\"John Smith\") # âœ… è¿™é‡Œä¼ å…¥å®ä¾‹\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d50255",
   "metadata": {},
   "source": [
    "æˆ–åœ¨ Agent å·¥å…·è°ƒç”¨æ—¶è¿›è¡Œä½¿ç”¨ï¼Œå½“ç„¶è¿™å°±è¦æ±‚æˆ‘ä»¬åœ¨å®šä¹‰å·¥å…·çš„æ—¶å€™å°±å¿…é¡»æŠŠ runtime å‚æ•°è½½å…¥è¿›å»ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2813bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool, ToolRuntime  \n",
    "\n",
    "@tool\n",
    "def fetch_user_email_preferences(runtime: ToolRuntime[Context]) -> str:  \n",
    "    \"\"\"Fetch the user's email preferences from the store.\"\"\"\n",
    "    user_id = runtime.context.user_id  \n",
    "\n",
    "    preferences: str = \"The user prefers you to write a brief and polite email.\"\n",
    "    if runtime.store:  \n",
    "        if memory := runtime.store.get((\"users\",), user_id):  \n",
    "            preferences = memory.value[\"preferences\"]\n",
    "\n",
    "    return preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67123bb3",
   "metadata": {},
   "source": [
    "## 3.3 è¾“å‡ºè¿”å›å€¼ None | dict\n",
    "\n",
    "Node-style çš„æ ¸å¿ƒæœºåˆ¶åœ¨äºï¼šè¿”å›ä¸€ä¸ªå­—å…¸ç”¨äºâ€œæ›´æ–° Agent çš„çŠ¶æ€â€æˆ–â€œæ”¹å˜æ‰§è¡Œæµç¨‹â€ã€‚\n",
    "\n",
    "å®ƒçš„è¿”å›å€¼å¯ä»¥æ˜¯ï¼š\n",
    "- None â€”â€” è¡¨ç¤ºä¸åšä»»ä½•æ›´æ”¹ï¼Œç»§ç»­æ‰§è¡Œï¼›\n",
    "- dict[str, Any] â€”â€” ç”¨äºä¿®æ”¹å½“å‰çš„ Agent çŠ¶æ€ï¼ˆå°±æ˜¯å‰é¢æåˆ°çš„ AgentStateï¼‰ï¼Œæ¯”å¦‚å¢åŠ  messageã€æ›´æ–°å˜é‡ã€ç”šè‡³ç›´æ¥è·³å‡ºæµç¨‹ã€‚\n",
    "\n",
    "åœ¨ Node-style hook ä¸­ï¼Œå¦‚æœè¿”å›çš„å­—å…¸åŒ…å«æŸä¸ªå­—æ®µï¼Œå°±ä¼šè¦†ç›–åŸæ¥çš„å€¼ï¼›å¦‚æœæ²¡è¿”å›è¯¥å­—æ®µï¼Œå°±ç»§ç»­ä¿ç•™ AgentState ä¸­å·²æœ‰çš„å€¼ä¸å˜ã€‚\n",
    "\n",
    "å¸¸è§çš„è¿”å›å­—å…¸æ ¼å¼ä¸ºï¼š\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"messages\": [AIMessage(\"å†…å®¹\")],    # æ›´æ–°æ¶ˆæ¯åˆ—è¡¨ï¼Œæ›¿æ¢æ‰åŸæœ‰æ¶ˆæ¯ï¼ˆå¦‚æœè®¾ç½® jump_toï¼‰\n",
    "    \"jump_to\": \"end\",                  # è·³è½¬åˆ°æŸä¸ªèŠ‚ç‚¹ï¼Œå¦‚ \"end\"ã€\"tools\"ã€\"model\"\n",
    "    \"custom_key\": \"value\",             # è‡ªå®šä¹‰çŠ¶æ€é”®å€¼å¯¹ï¼ˆå¦‚æœä½¿ç”¨äº†è‡ªå®šä¹‰ AgentStateï¼‰\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c23a6f",
   "metadata": {},
   "source": [
    "## 3.4 Node-style hooks åˆ›å»ºæ¡ˆä¾‹\n",
    "\n",
    "ä¸‹é¢æˆ‘ä»¬å°±æ¥ç”¨å‡ ä¸ªçœŸå®çš„æ¡ˆä¾‹æ¥å±•ç¤ºä¸€ä¸‹å¦‚ä½•åˆ›å»º Node-style Hooks çš„ MiddleWare ã€‚\n",
    "\n",
    "### 3.4.1 æ¡ˆä¾‹ 1ï¼šlog_before_model\n",
    "ä¸‹é¢è¿™ä¸ªä¸­é—´ä»¶æ˜¯ä¸€ä¸ªä½œç”¨åœ¨æ¨¡å‹å‰ï¼ˆbefore_modelï¼‰ï¼Œå…¶ä½œç”¨ä¹Ÿéå¸¸ç®€å•ï¼Œå°±æ˜¯å»æ‰“å°ä¸€ä¸‹å½“å‰çš„å†å²è®°å½•ä¸­æœ‰å¤šå°‘æ¡ä¿¡æ¯ã€‚\n",
    "\n",
    "æ‰€ä»¥è¿™é‡Œæˆ‘ä»¬é€šè¿‡ state['messages'] çš„æ–¹å¼å°†æ•´ä¸ªå†å²è®°å½•çš„ä¿¡æ¯è¿›è¡Œè·å–ï¼Œç„¶åé€šè¿‡ len() å‡½æ•°å»è®°å½•å¯¹åº”å†å²è®°å½•ä¿¡æ¯çš„æ•°é‡ï¼ˆæ¯ä¸€æ¡ HumanMessages æˆ–è€… AIMessage éƒ½ç®—æ˜¯åˆ—è¡¨ä¸­çš„ä¸€æ¡ä¿¡æ¯ï¼‰ï¼Œå¹¶æœ€åå°†å…¶æ‰“å°å‡ºæ¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48fb71d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to call model with 1 messages\n",
      "{'messages': [HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='3dbdea0f-ed3f-4a57-b412-ecdda29a82d6'), AIMessage(content=\"I don't have access to your personal information. You'll need to provide your name for me to know it.\", additional_kwargs={}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'stop', 'request_id': '02ea6d1b-356b-4928-b074-7421870a348d', 'token_usage': {'input_tokens': 210, 'output_tokens': 23, 'prompt_tokens_details': {'cached_tokens': 128}, 'total_tokens': 233}}, id='lc_run--019b2fc3-bb26-7302-92d5-a51229999652-0')]}\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "from langchain.agents import AgentState, create_agent\n",
    "from langchain.agents.middleware import before_model\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.runtime import Runtime  \n",
    "\n",
    "@before_model\n",
    "def log_before_model(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    print(f\"About to call model with {len(state['messages'])} messages\")\n",
    "    return None\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[log_before_model],\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my name?\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": \"1\"}}\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bfe800",
   "metadata": {},
   "source": [
    "### 3.4.2 æ¡ˆä¾‹ 2ï¼švalidate_output\n",
    "\n",
    "è€Œ validate_output è¿™ä¸ªä¸­é—´ä»¶çš„ä½œç”¨ä½ç½®æ—¶åœ¨æ¨¡å‹è¾“å‡ºåï¼ˆafter_modelï¼‰ï¼Œå…¶ä¸»è¦ç›®çš„æ˜¯å®¡æŸ¥æ¨¡å‹çš„è¾“å‡ºé‡Œæ˜¯å¦åŒ…å«å…³é”®å­—â€œBLOCKEDâ€œï¼ˆç³»ç»Ÿæç¤ºè¯ä¸­è¿›è¡Œè®¾ç½®ï¼‰ã€‚\n",
    "\n",
    "ä¸»è¦ä½¿ç”¨çš„æ–¹æ³•ä¹Ÿæ˜¯ä» AgentState ä¸­è·å–å®Œæ•´çš„å†å²è®°å½•åˆ—è¡¨ messagesï¼Œç„¶åè·å–é‡Œé¢æœ€åä¸€æ¡ï¼ˆåˆšæ¨¡å‹è°ƒç”¨å®Œä¹Ÿå°±æ˜¯ AIMessageï¼‰é‡Œçš„å†…å®¹ content ï¼Œçœ‹é‡Œé¢æ˜¯å¦åŒ…å«å…³é”®å­—ã€‚å‡å¦‚åŒ…å«çš„è¯å°±æ›´æ–°ä¿¡æ¯ï¼ˆdictï¼‰è¿”å›ä¸èƒ½å›åº”å¹¶è·³è½¬åˆ°ç»“æŸ endï¼Œå¦åˆ™å°±æ— äº‹å‘ç”Ÿï¼ˆNoneï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ced293a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cannot respond to that request.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import after_model\n",
    "from langchain.messages import AIMessage\n",
    "\n",
    "@after_model(can_jump_to=[\"end\"])\n",
    "def validate_output(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if \"BLOCKED\" in last_message.content:\n",
    "        return {\"messages\": [AIMessage(\"I cannot respond to that request.\")],\n",
    "            \"jump_to\": \"end\"}\n",
    "    return None\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a safety-controlled assistant.\n",
    "Your single task is to check whether the user's message contains harmful, dangerous, illegal, violent, self-harm, hateful, criminal, or unethical content.\n",
    "\n",
    "If the user's question or instruction is unsafe, sensitive, or prohibited in any way,\n",
    "your ONLY output must be:\n",
    "\n",
    "BLOCKED\n",
    "\n",
    "Do NOT provide explanations, warnings, apologies, or alternative suggestions.\n",
    "\n",
    "If the user's message is safe and harmless, answer normally.\n",
    "\"\"\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=system_prompt,\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[validate_output], # å†™å…¥ä¸­é—´ä»¶\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"how to destroy a building?\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": \"1\"}}\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7273fbc3",
   "metadata": {},
   "source": [
    "ç±»ä¼¼çš„ï¼Œå‡å¦‚æˆ‘ä»¬è¦ç”¨ç±»è£…é¥°å™¨å®ç°ä¿¡æ¯çš„æˆªè·ï¼Œå¯ä»¥æŒ‰ä»¥ä¸‹æ–¹å¼å®ç°ã€‚ç•¥å¾®ä¸åŒçš„æ˜¯å‰é¢ @after_model ä¸­å¯ä»¥ä¼ å…¥ can_jump_to å‚æ•°ï¼Œè€Œè¿™é‡Œçš„è¯å¯ä»¥æ·»åŠ  @hook_config æ¥è®© LangGraph çŸ¥é“æˆ‘ä»¬è¦è·³è½¬çš„ä½ç½®ï¼ˆåœ¨ç±»åˆ›å»ºæ–¹æ³•é‡Œï¼Œä¸æ·»åŠ å°±æ˜¯ä»»æ„ä½ç½®éƒ½èƒ½å»ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a895184c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cannot respond to that request.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import AgentMiddleware, hook_config, AgentState\n",
    "from langchain.messages import AIMessage\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any\n",
    "\n",
    "class BlockedContentMiddleware(AgentMiddleware):\n",
    "    @hook_config(can_jump_to=[\"end\"])\n",
    "    def after_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if \"BLOCKED\" in last_message.content:\n",
    "            return {\n",
    "                \"messages\": [AIMessage(\"I cannot respond to that request.\")],\n",
    "                \"jump_to\": \"end\"\n",
    "            }\n",
    "        return None\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=system_prompt,\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[BlockedContentMiddleware()], # æ›¿æ¢å‰é¢çš„å‡½æ•°å¼ä¸­é—´ä»¶\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"how to destroy a building?\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": \"1\"}}\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d937043",
   "metadata": {},
   "source": [
    "### 3.4.3 æ¡ˆä¾‹ 3ï¼šå¤šä¸­é—´ä»¶\n",
    "\n",
    "åœ¨ç±»è£…é¥°å™¨é‡Œï¼Œæˆ‘ä»¬å¯ä»¥åŒæ—¶è®¾ç½®æ¨¡å‹å¼€å§‹å‰åçš„ä¸­é—´ä»¶ï¼š\n",
    "- æ¯”å¦‚æ¨¡å‹å¼€å§‹å‰æˆ‘ä»¬å’Œä¹‹å‰ä¸€æ ·æ‰“å°ä¸€ä¸‹å½“å¤©èŠå¤©è®°å½•ä¸­ä¿¡æ¯çš„æ•°é‡\n",
    "- æ¨¡å‹å¼€å§‹åæˆ‘ä»¬æ‰“å°ä¸€ä¸‹æ¨¡å‹è¾“å‡ºçš„å†…å®¹ï¼ˆæœ€æ–°ä¸€æ¡ä¹Ÿå°±æ˜¯ AIMessageï¼‰\n",
    "- ä¸¤è€…éƒ½åªæ˜¯ä¿¡æ¯çš„æ‰“å°ï¼Œè€Œä¸è¿›è¡Œæµç¨‹æˆ–ä¿¡æ¯çš„æ›´æ–°ï¼ˆreturn Noneï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b45c994e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to call model with 1 messages\n",
      "Model returned: ä½ å¥½ï¼æˆ‘æ˜¯Qwenï¼Œæ˜¯é˜¿é‡Œå·´å·´é›†å›¢æ——ä¸‹çš„é€šä¹‰å®éªŒå®¤è‡ªä¸»ç ”å‘çš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ã€‚æˆ‘å¯ä»¥å¸®åŠ©ä½ å›ç­”é—®é¢˜ã€åˆ›ä½œæ–‡å­—ã€é€»è¾‘æ¨ç†ã€ç¼–ç¨‹ç­‰ã€‚å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œéšæ—¶å‘Šè¯‰æˆ‘ï¼\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import AgentMiddleware, AgentState\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any\n",
    "\n",
    "class LoggingMiddleware(AgentMiddleware):\n",
    "    def before_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        print(f\"About to call model with {len(state['messages'])} messages\")\n",
    "        return None\n",
    "\n",
    "    def after_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        print(f\"Model returned: {state['messages'][-1].content}\")\n",
    "        return None\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[LoggingMiddleware()], # æ›¿æ¢å‰é¢çš„ä¸­é—´ä»¶\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹è‡ªå·±å§\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": \"2\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750b0957",
   "metadata": {},
   "source": [
    "### 3.4.4 ç±»è£…é¥°å™¨å±æ€§æ·»åŠ \n",
    "\n",
    "å½“ç„¶ç±»è£…é¥°å™¨é‡Œå¯ä»¥åŠ å…¥ä¸€äº›æ›´å¤æ‚çš„ä¸œè¥¿ï¼Œæ¯”å¦‚æˆ‘ä»¬å¯ä»¥æ·»åŠ ä¸€ä¸ªå†å²è®°å½•çš„é™åˆ¶ã€‚è¿™é‡Œé¦–å…ˆæˆ‘ä»¬åœ¨ç±»ä¸­è°ƒç”¨çˆ¶ç±»çš„åˆå§‹åŒ–æ–¹æ³• super().__init__() å¹¶è‡ªå®šä¹‰äº†ä¸€ä¸ªå±æ€§ max_messages ç”¨äºåç»­çš„æ•°é‡åˆ¤å®šã€‚ç„¶ååœ¨å®é™…çš„è°ƒç”¨ä¸­ï¼Œå‡å¦‚è¶…è¿‡äº†è¿™ä¸ªè®¾ç½®çš„æ•°é‡çš„è¯ï¼Œå°±æ›´æ–°ä¿¡æ¯å¹¶è·³è½¬åˆ°ç»“å°¾ endã€‚åœ¨å®é™…åˆ›å»º agent æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠè¿™ä¸ªç±»ä»¥åŠå±æ€§çš„å€¼ä¹Ÿç»™å†™å…¥ï¼Œè¿™æ ·å°±å¯ä»¥è¿›è¡Œåº”ç”¨äº†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54af59ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘æ˜¯ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œç”±é˜¿é‡Œäº‘å¼€å‘ã€‚æˆ‘çš„åå­—æ˜¯é€šä¹‰åƒé—®ï¼Œæˆ‘å¯ä»¥å¸®åŠ©ç”¨æˆ·å›ç­”é—®é¢˜ã€åˆ›ä½œæ–‡å­—ã€é€»è¾‘æ¨ç†ã€ç¼–ç¨‹ç­‰ã€‚æˆ‘çš„ç›®æ ‡æ˜¯ä¸ºç”¨æˆ·æä¾›é«˜è´¨é‡çš„æœåŠ¡ï¼Œå¸®åŠ©ä»–ä»¬æ›´å¥½åœ°å®Œæˆå·¥ä½œå’Œå­¦ä¹ ã€‚å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œéšæ—¶å¯ä»¥é—®æˆ‘ï¼\n",
      "Conversation limit reached.\n"
     ]
    }
   ],
   "source": [
    "class MessageLimitMiddleware(AgentMiddleware):\n",
    "    def __init__(self, max_messages: int = 50):\n",
    "        super().__init__()\n",
    "        self.max_messages = max_messages\n",
    "    @hook_config(can_jump_to=[\"end\"]) \n",
    "    def before_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        if len(state[\"messages\"]) >= self.max_messages:\n",
    "            return {\n",
    "                \"messages\": [AIMessage(\"Conversation limit reached.\")],\n",
    "                \"jump_to\": \"end\"\n",
    "            }\n",
    "        return None\n",
    "    \n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[MessageLimitMiddleware(max_messages=2)], # æ·»åŠ å±æ€§\n",
    ")\n",
    "\n",
    "result1 = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ä½ æ˜¯è°å‘€ï¼Œ200å­—ä»‹ç»ä¸€ä¸‹\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": \"1\"}}\n",
    ")\n",
    "\n",
    "result2 = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ä½ èƒ½åšä»€ä¹ˆï¼Ÿ\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": \"1\"}}\n",
    ")\n",
    "\n",
    "print(result1[\"messages\"][-1].content)\n",
    "print(result2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a65a251",
   "metadata": {},
   "source": [
    "### 3.4.5 è‡ªå®šä¹‰ Agent State\n",
    "\n",
    "é™¤æ­¤ä¹‹å¤–æˆ‘ä»¬è¿˜å¯ä»¥æ·»åŠ è‡ªå®šä¹‰çš„ state è¿›å»ã€‚è¿™ä¸ªæ—¶å€™ä¼ å…¥çš„ç±»å°±ä¸æ˜¯ AgentMiddleware ï¼Œè€Œæ˜¯ AgentMiddleware[CustomState]ï¼Œå¹¶ä¸”å†™å…¥æ—¶ä¹Ÿè¦ state_schema = CustomStateã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3dc302c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import AgentState, AgentMiddleware\n",
    "from typing_extensions import NotRequired\n",
    "from typing import Any\n",
    "\n",
    "class CustomState(AgentState):\n",
    "    model_call_count: NotRequired[int]\n",
    "    user_id: NotRequired[str]\n",
    "\n",
    "class CallCounterMiddleware(AgentMiddleware[CustomState]):\n",
    "    state_schema = CustomState\n",
    "    \n",
    "    @hook_config(can_jump_to=[\"end\"])\n",
    "    def before_model(self, state: CustomState, runtime) -> dict[str, Any] | None:\n",
    "        count = state.get(\"model_call_count\", 0)\n",
    "        user_id = state.get(\"user_id\", \"Unknown\")\n",
    "        if count >= 1:\n",
    "            return {\n",
    "                \"messages\": [AIMessage(content=f\"{user_id} BLOCKED: model call limit exceeded.\")],\n",
    "                \"jump_to\": \"end\"\n",
    "            }\n",
    "        return None\n",
    "\n",
    "    def after_model(self, state: CustomState, runtime) -> dict[str, Any] | None:\n",
    "        return {\"model_call_count\": state.get(\"model_call_count\", 0) + 1}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7bdf67",
   "metadata": {},
   "source": [
    "ç„¶åè¿™é‡Œæˆ‘ä»¬é€šè¿‡ agent.invoke çš„å†…å®¹å°† messages, model_call_count, user_id ç­‰å‚æ•°è¿›è¡Œå†™å…¥ï¼Œç„¶ååœ¨æ¨¡å‹è¿è¡Œåé€šè¿‡ @after_model è¿›è¡Œ model_call_count åŠ¨æ€çš„æ›´æ–°ã€‚è¿™æ ·æˆ‘ä»¬å°±èƒ½å¤Ÿåœ¨ before_model è·å–æ¨¡å‹è¿è¡Œæ¬¡æ•°ï¼Œå‡å¦‚å¤§äºä¸€æ¬¡å°±è·³è½¬åˆ° END å¤„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "216cd9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œæ—¨åœ¨å¸®åŠ©æ‚¨è§£ç­”å„ç§é—®é¢˜å’Œæä¾›ç›¸å…³ä¿¡æ¯ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼\n",
      "user-123 BLOCKED: model call limit exceeded.\n"
     ]
    }
   ],
   "source": [
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    middleware=[CallCounterMiddleware()],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "result1 = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ä½ æ˜¯è°\"}],\n",
    "    \"model_call_count\": 0,\n",
    "    \"user_id\": \"user-123\",},\n",
    "    config={\"configurable\": {\"thread_id\": \"10\"}}\n",
    ")\n",
    "\n",
    "result2 = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ä½ èƒ½åšä»€ä¹ˆ\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": \"10\"}}\n",
    ")\n",
    "\n",
    "print(result1[\"messages\"][-1].content)\n",
    "print(result2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9ef344",
   "metadata": {},
   "source": [
    "å½“ç„¶è°ƒç”¨çš„æ—¶å€™ä¸å†™å…¥çš„è¯ä¹Ÿä¼šè‡ªåŠ¨åˆ›å»ºçš„ï¼Œé»˜è®¤èµ·å§‹çš„æ•°é‡ä¸º 0 ä¸” user_id æœª Unknownã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6491377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘æ˜¯é€šä¹‰åƒé—®ï¼Œç”±é˜¿é‡Œå·´å·´é›†å›¢æ——ä¸‹çš„é€šä¹‰å®éªŒå®¤ç ”å‘çš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ã€‚æˆ‘å¯ä»¥å¸®åŠ©ä½ è§£ç­”é—®é¢˜ã€åˆ›ä½œæ–‡å­—ã€ç¼–ç¨‹ã€é€»è¾‘æ¨ç†ç­‰å„ç§ä»»åŠ¡ã€‚ä½ å¯ä»¥é—®æˆ‘ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½åŠ›æä¾›å¸®åŠ©ã€‚\n",
      "Unknown BLOCKED: model call limit exceeded.\n"
     ]
    }
   ],
   "source": [
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    middleware=[CallCounterMiddleware()],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "result1 = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ä½ æ˜¯è°\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": \"10\"}}\n",
    ")\n",
    "\n",
    "result2 = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ä½ èƒ½åšä»€ä¹ˆ\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": \"10\"}}\n",
    ")\n",
    "\n",
    "print(result1[\"messages\"][-1].content)\n",
    "print(result2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39387c71",
   "metadata": {},
   "source": [
    "## 4 Wrap-Style hooks\n",
    "\n",
    "Wrap-style hooks åŒ…æ‹¬ï¼š\n",
    "- å·¥å…·è°ƒç”¨æ—¶ï¼šwrap_tool_call\n",
    "- æ¨¡å‹è°ƒç”¨æ—¶ï¼šwrap_model_call\n",
    "\n",
    "å¯¹äº wrap_tool_call å’Œ wrap_model_call è€Œè¨€ï¼Œè™½ç„¶ä¸¤è€…çš„è¾“å…¥å‚æ•°å’Œè¾“å‡ºå†…å®¹å¾ˆç±»ä¼¼ï¼Œä½†æ˜¯æ•´ä½“è¿˜æœ‰ä¸€äº›ä¸åŒï¼š\n",
    "- è¾“å…¥å‚æ•°ï¼šrequestï¼ˆæ¨¡å‹å·¥å…·è°ƒç”¨è¯·æ±‚ ModelRequest æˆ–å·¥å…·è°ƒç”¨è¯·æ±‚ ToolCallRequestï¼‰ï¼Œhandlerï¼ˆæ¨¡å‹æˆ–å·¥å…·è°ƒç”¨å‡½æ•°ï¼‰\n",
    "- è¾“å‡ºå†…å®¹ï¼šå¯¹äº wrap_model_call è¾“å‡ºçš„æ˜¯ ModelResponseã€‚è€Œå¯¹äº wrap_tool_call è€Œè¨€è¾“å‡ºçš„å¯èƒ½æ˜¯ ToolMessage ï¼ˆç›´æ¥è¿è¡Œè·å–ç»“æœï¼‰ï¼Œä¹Ÿå¯èƒ½æ˜¯ Command ï¼ˆç­‰å¾…äººç±»åé¦ˆåæ‰§è¡Œä¸‹ä¸€æ­¥æ“ä½œï¼‰\n",
    "\n",
    "å› æ­¤ä¸‹é¢æˆ‘ä»¬å°†åˆ†åˆ«æ¥è¿›è¡Œå‰–æä¸è®²è§£ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae6b48",
   "metadata": {},
   "source": [
    "## 4.1 Wrap_model_call\n",
    "\n",
    "### 4.1.1 è¾“å…¥å‚æ•° ModelRequest\n",
    "\n",
    "åœ¨ Wrap-style hook ä¸­ï¼Œrequest è¡¨ç¤ºçš„æ˜¯å½“å‰æ¨¡å‹è°ƒç”¨/å·¥å…·è°ƒç”¨çš„å®Œæ•´è¯·æ±‚å¯¹è±¡ã€‚\n",
    "\n",
    "å®ƒæ˜¯ä¸€ä¸ªå°è£…äº†è¾“å…¥ä¿¡æ¯ã€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€è¿è¡ŒçŠ¶æ€çš„ç»“æ„ä½“ï¼Œä½ å¯ä»¥åœ¨è¿™é‡Œè¯»å–ã€ä¿®æ”¹ç”šè‡³æ›¿æ¢æ‰æ•´ä¸ªè¯·æ±‚å†…å®¹ï¼Œå†å†³å®šæ˜¯å¦è¦ç»§ç»­è°ƒç”¨ã€å¦‚ä½•è°ƒç”¨ã€‚\n",
    "\n",
    "å¯¹äº ModelResponse è€Œè¨€ï¼Œå…¶å†…éƒ¨åŒ…å«çš„å†…å®¹å¦‚ä¸‹ï¼š\n",
    "\n",
    "```python\n",
    "ModelRequest(\n",
    "    model: BaseChatModel,                    # âœ… å½“å‰ä½¿ç”¨çš„æ¨¡å‹å®ä¾‹\n",
    "    messages: list[BaseMessage],             # âœ… å¯¹è¯å†å²ï¼ˆç”¨æˆ·ã€åŠ©æ‰‹ã€ç³»ç»Ÿæ¶ˆæ¯ï¼‰\n",
    "    system_prompt: Optional[str] = None,     # âœ… ç³»ç»ŸæŒ‡ä»¤ï¼ˆéƒ¨åˆ†æ¨¡å‹ç”¨ä½œ system roleï¼‰\n",
    "    tool_choice: Optional[Union[str, dict]] = \"auto\",  # âœ… å·¥å…·è°ƒç”¨ç­–ç•¥\n",
    "    tools: Optional[list[BaseTool]] = None,  # âœ… å¯ç”¨çš„å·¥å…·åˆ—è¡¨\n",
    "    response_format: Optional[str] = \"text\", # âœ… è¿”å›æ ¼å¼ï¼štext / jsonï¼ˆå¯é€‰ï¼‰\n",
    "    state: AgentState,                                 # è¿è¡Œè¿‡ç¨‹ä¸­çš„åŠ¨æ€å‚æ•°\n",
    "    runtime: Runtime[ContextT],                 # è¿è¡Œè¿‡ç¨‹ä¸­çš„é™æ€ä¿¡æ¯ \n",
    "    model_settings: Optional[dict] = {},     # âœ… ä¼ ç»™æ¨¡å‹çš„é™„åŠ å‚æ•°ï¼Œå¦‚æ¸©åº¦ã€max_tokens\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfa2439",
   "metadata": {},
   "source": [
    "å¯¹äº ModelRequest çš„å†…å®¹ï¼Œå…¶å®æˆ‘ä»¬ä¹Ÿæ˜¯èƒ½å¤Ÿä¿®æ”¹åå†ä¼ ç»™æ¨¡å‹çš„ã€‚æˆ‘ä»¬åªéœ€è¦ä½¿ç”¨ .override() æ–¹æ³•è¿›è¡Œä¿®æ”¹å³å¯ã€‚\n",
    "\n",
    "æ¯”å¦‚æˆ‘ä»¬å¯ä»¥ç”¨ .override() åˆ›å»ºæ–°è¯·æ±‚å†è°ƒç”¨ handlerï¼š\n",
    "\n",
    "```python\n",
    "new_request = request.override(\n",
    "    model_settings={\"temperature\": 0.1},\n",
    "    system_prompt=\"ä½ æ˜¯ä¸€ä¸ªæç®€é£æ ¼ä¸­æ–‡åŠ©æ‰‹\")\n",
    "response = handler(new_request)\n",
    "```\n",
    "\n",
    "æˆ‘ä»¬ç”šè‡³å¯ä»¥è¿™æ ·åšæ¥ç»„åˆå¤šä¸ª overrideï¼š\n",
    "\n",
    "```python\n",
    "request = request.override(messages=filtered_messages)\n",
    "request = request.override(model=new_model)\n",
    "response = handler(request)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef134c0",
   "metadata": {},
   "source": [
    "### 4.1.2 è¾“å…¥å‚æ•° handler\n",
    "\n",
    "åœ¨ Wrap_model_call é‡Œï¼Œæˆ‘ä»¬å…¶å®å¯ä»¥çœ‹åˆ°è¿˜ä¼ å…¥äº†ä¸€ä¸ªå‚æ•° handlerï¼Œè¿™ä¸ª handler çš„ç±»å‹æ˜¯ä¸€ä¸ª Callable[[ModelRequest], ModelResponse]ï¼Œè¿™æ„å‘³ç€è¯´ handler æ˜¯ä¸€ä¸ª LangChain å†…ç½®å¥½çš„å‡½æ•°ï¼Œæˆ‘ä»¬åªéœ€è¦è¾“å…¥ ModelRequestï¼Œ å°±ä¼šè¾“å‡º ModelResponseã€‚\n",
    "\n",
    "è¿™ä¸ªå‡½æ•°å¯èƒ½æ˜¯ä¸‹é¢è¿™æ ·ï¼š\n",
    "\n",
    "```python\n",
    "def handler(request: ModelRequest) -> ModelResponse:\n",
    "    # 1. ç»„è£… prompt\n",
    "    prompt = build_prompt_from(request.messages, request.system_prompt)\n",
    "    # 2. ä» model_settings é‡Œå–å‚æ•°\n",
    "    temperature = request.model_settings.get(\"temperature\", 0.7)\n",
    "    # 3. è°ƒç”¨æ¨¡å‹\n",
    "    response_text = request.model.invoke(prompt=prompt, temperature=temperature)\n",
    "    # 4. åŒ…è£…æˆæ ‡å‡†æ ¼å¼\n",
    "    return ModelResponse(result=[AIMessage(content=response_text)])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6d2ca3",
   "metadata": {},
   "source": [
    "### 4.1.3 è¾“å‡ºå†…å®¹ ModelResponse\n",
    "\n",
    "ModelResponse æ˜¯å¤§è¯­è¨€æ¨¡å‹å®Œæˆä¸€æ¬¡æ¨ç†ä¹‹åï¼ŒLangChain Agent æ¥æ”¶åˆ°çš„ç»“æœå°è£…ã€‚\n",
    "\n",
    "å…¶å­—æ®µç»“æ„å¦‚ä¸‹ï¼š\n",
    "\n",
    "```python\n",
    "ModelResponse(\n",
    "    result: list[BaseMessage],         # æ¨¡å‹ç”Ÿæˆçš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆä¸»è¦æ˜¯ AI å›å¤ï¼‰\n",
    "    structured_response: Any = None    # è‹¥ä½¿ç”¨ç»“æ„åŒ–å“åº”ï¼Œè§£æåçš„ JSON å¯¹è±¡\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99a75d9",
   "metadata": {},
   "source": [
    "### 4.1.4 wrap_model_call åˆ›å»ºæ¡ˆä¾‹\n",
    "\n",
    "#### æ¡ˆä¾‹ 1ï¼šretry_model\n",
    "\n",
    "å¯¹äº Wrap-style hooks è¿™ç±»çš„ä¸­é—´ä»¶ï¼Œä¸»è¦è§£å†³å¹¶å†æ˜¯ä¿¡æ¯çš„å®¡æŸ¥ç±»å‹çš„é—®é¢˜äº†ã€‚è€Œæ˜¯å¯¹å®é™…è°ƒç”¨å‰åå¯èƒ½å‡ºç°çš„ä¸€äº›çŠ¶å†µè¿›è¡Œå‡†å¤‡ã€‚\n",
    "\n",
    "æ¯”å¦‚åœ¨æ¨¡å‹è°ƒç”¨è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬æœ€æ€•çš„å°±æ˜¯æ¨¡å‹è°ƒç”¨æ—¶å‡ºç°ç½‘ç»œæ³¢åŠ¨ï¼Œå¯¼è‡´æ— æ³•æˆåŠŸè¿æ¥ä¸Šæ¨¡å‹å‡ºç°æŠ¥é”™ã€‚é‚£ä¸‹é¢çš„ retry_model å‡½æ•°å…¶å®å°±æ˜¯è®©å¤§æ¨¡å‹åœ¨è°ƒç”¨æ—¶å‡å¦‚å‡ºç°æŠ¥é”™çš„è¯æœ‰ä¸‰æ¬¡é‡å¯çš„æœºä¼šï¼Œå‡å¦‚ä¸‰æ¬¡éƒ½å‡ºç°é”™è¯¯æ‰æ˜¾ç¤ºæŠ¥é”™ä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c15670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from typing import Callable\n",
    "\n",
    "@wrap_model_call\n",
    "def retry_model(request: ModelRequest, handler: Callable[[ModelRequest], ModelResponse]) -> ModelResponse:\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            return handler(request)\n",
    "        except Exception as e:\n",
    "            if attempt == 2:\n",
    "                raise\n",
    "            print(f\"Retry {attempt + 1}/3 after error: {e}\")\n",
    "            \n",
    "            \n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    middleware=[retry_model],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892bc954",
   "metadata": {},
   "source": [
    "å‡å¦‚æˆ‘ä»¬é€šè¿‡ç±»è¿›è¡Œåˆ›å»ºçš„è¯ï¼Œå°±å¯ä»¥åœ¨ä¼ å…¥åˆ° agent æ—¶æ¥è‡ªå®šä¹‰è®¾ç½®é‡è¯•çš„æ¬¡æ•° max_retriesï¼ˆé»˜è®¤å€¼ä¸º 3 ï¼‰ã€‚\n",
    "\n",
    "å¦‚æœè¿è¡ŒæˆåŠŸçš„è¯ï¼Œå°±ç›´æ¥æ‰§è¡Œæ¨¡å‹è°ƒç”¨çš„æ“ä½œã€‚ä½†å¦‚æœå‡ºç°æŠ¥é”™å¹¶è¶…è¿‡æŒ‡å®šæ¬¡æ•°çš„è¯ï¼Œåˆ™æ‰“å°å¹¶æ˜¾ç¤ºæŠ¥é”™ä¿¡æ¯ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8655f763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘æ˜¯Qwenï¼Œæ˜¯é˜¿é‡Œå·´å·´é›†å›¢æ——ä¸‹çš„é€šä¹‰å®éªŒå®¤è‡ªä¸»ç ”å‘çš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ã€‚æˆ‘èƒ½å¤Ÿå›ç­”é—®é¢˜ã€åˆ›ä½œæ–‡å­—ã€é€»è¾‘æ¨ç†ã€ç¼–ç¨‹ç­‰å¤šç§ä»»åŠ¡ã€‚å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œæ¬¢è¿éšæ—¶å‘Šè¯‰æˆ‘ï¼\n",
      "æˆ‘èƒ½å¤Ÿå›ç­”é—®é¢˜ã€åˆ›ä½œæ–‡å­—ã€é€»è¾‘æ¨ç†ã€ç¼–ç¨‹ç­‰å¤šç§ä»»åŠ¡ã€‚æ— è®ºæ˜¯éœ€è¦å¸®åŠ©è§£å†³å¤æ‚çš„é—®é¢˜ï¼Œè¿˜æ˜¯æƒ³è¦åˆ›ä½œæ•…äº‹ã€é‚®ä»¶ã€å…¬æ–‡ç­‰æ–‡å­—å†…å®¹ï¼Œæˆ–æ˜¯è¿›è¡Œæ•°æ®åˆ†æå’Œç¼–ç¨‹ï¼Œæˆ‘éƒ½å¯ä»¥æä¾›æ”¯æŒã€‚å¦‚æœä½ æœ‰ä»»ä½•å…·ä½“çš„éœ€æ±‚æˆ–é—®é¢˜ï¼Œæ¬¢è¿éšæ—¶å‘Šè¯‰æˆ‘ï¼\n"
     ]
    }
   ],
   "source": [
    "class RetryMiddleware(AgentMiddleware):\n",
    "    def __init__(self, max_retries: int = 3):\n",
    "        super().__init__()\n",
    "        self.max_retries = max_retries\n",
    "    def wrap_model_call(self, request: ModelRequest, handler: Callable[[ModelRequest], ModelResponse]) -> ModelResponse:\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                return handler(request)\n",
    "            except Exception as e:\n",
    "                if attempt == self.max_retries - 1:\n",
    "                    raise\n",
    "                print(f\"Retry {attempt + 1}/{self.max_retries} after error: {e}\")\n",
    "                \n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    middleware=[RetryMiddleware()],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "result1 = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ä½ æ˜¯è°\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": \"10\"}}\n",
    ")\n",
    "\n",
    "result2 = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ä½ èƒ½åšä»€ä¹ˆ\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": \"10\"}}\n",
    ")\n",
    "\n",
    "print(result1[\"messages\"][-1].content)\n",
    "print(result2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267d7c88",
   "metadata": {},
   "source": [
    "#### æ¡ˆä¾‹ 2ï¼šDynamicModelMiddleware å¤šæ¨¡å‹é€‰æ‹©\n",
    "\n",
    "é™¤äº†é‡è¯•æ¨¡å‹ä»¥å¤–ï¼Œæˆ‘ä»¬åœ¨è°ƒç”¨æ¨¡å‹çš„æ—¶å€™è¿˜å¯ä»¥è€ƒè™‘æ ¹æ®ç”¨æˆ·çš„æé—®çš„è½®æ•°æ¥æ›´æ”¹ä½¿ç”¨çš„æ¨¡å‹ã€‚æ¯”å¦‚åƒä¸‹é¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬æ ¹æ® request ä¸­çš„ messages åˆ—è¡¨ï¼ˆé‡Œé¢å­˜æ”¾äº†ä¹‹å‰çš„å¯¹è¯è®°å½•ï¼‰æ¥å†³å®šæ˜¯ä½¿ç”¨ qwen-max æ¨¡å‹è¿˜æ˜¯ qwen-turbo æ¨¡å‹ã€‚è¿™é‡Œå®ç°çš„æ–¹å¼å°±æ˜¯é€šè¿‡ä¿®æ”¹ request.model å†…çš„ä¿¡æ¯æ¥å®ç°çš„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93a1ada2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\76391\\AppData\\Local\\Temp\\ipykernel_27364\\3124932934.py:6: DeprecationWarning: Direct attribute assignment to ModelRequest.model is deprecated. Use request.override(model=...) instead to create a new request with the modified attribute.\n",
      "  request.model = ChatTongyi(api_key=os.environ.get(\"DASHSCOPE_API_KEY\"), model=\"qwen-max\")\n",
      "C:\\Users\\76391\\AppData\\Local\\Temp\\ipykernel_27364\\3124932934.py:6: DeprecationWarning: Direct attribute assignment to ModelRequest.model is deprecated. Use request.override(model=...) instead to create a new request with the modified attribute.\n",
      "  request.model = ChatTongyi(api_key=os.environ.get(\"DASHSCOPE_API_KEY\"), model=\"qwen-max\")\n",
      "C:\\Users\\76391\\AppData\\Local\\Temp\\ipykernel_27364\\3124932934.py:4: DeprecationWarning: Direct attribute assignment to ModelRequest.model is deprecated. Use request.override(model=...) instead to create a new request with the modified attribute.\n",
      "  request.model = ChatTongyi(api_key=os.environ.get(\"DASHSCOPE_API_KEY\"), model=\"qwen-turbo\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwen-max\n",
      "qwen-turbo\n"
     ]
    }
   ],
   "source": [
    "class DynamicModelMiddleware(AgentMiddleware):\n",
    "  def wrap_model_call(self, request: ModelRequest, handler):\n",
    "    if len(request.messages) > 3:\n",
    "      request.model = ChatTongyi(api_key=os.environ.get(\"DASHSCOPE_API_KEY\"), model=\"qwen-turbo\")\n",
    "    else:\n",
    "      request.model = ChatTongyi(api_key=os.environ.get(\"DASHSCOPE_API_KEY\"), model=\"qwen-max\")\n",
    "    return handler(request)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    middleware=[DynamicModelMiddleware()],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"è¯·ä½¿ç”¨ arxiv å·¥å…·æŸ¥è¯¢è®ºæ–‡ç¼–å· 1605.08386\"}]}, config={\"configurable\": {\"thread_id\": \"10\"}})\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ä½ æ˜¯è°\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": \"10\"}}\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][1].response_metadata[\"model_name\"])\n",
    "print(result[\"messages\"][-1].response_metadata[\"model_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7524b5",
   "metadata": {},
   "source": [
    "ä½†æ˜¯è¿™ç§æ–¹æ³•å·²ç»è¢«ä¸¢å¼ƒäº†ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦ä½¿ç”¨æ–°çš„ .override() çš„æ–¹æ³•å®ç°ã€‚\n",
    "\n",
    "LangChain v1.0 å¼€å§‹ï¼ŒModelRequest è¢«è®¾è®¡ä¸ºä¸å¯å˜å¯¹è±¡ï¼ˆimmutabilityï¼‰ï¼Œä¸ºäº†ä¿è¯é“¾è·¯ç¨³å®šä¸å¯è¿½è¸ªæ€§ï¼Œå®˜æ–¹å¼ºåˆ¶æ¨èä½¿ç”¨ .override() çš„æ–¹æ³•ç›¸å½“äºæ˜¯é‡æ–°åˆ›å»ºä¸€ä¸ªæ–°çš„ request ï¼Œå¹¶ä¸”æˆ‘ä»¬è¿˜å¯ä»¥åŠ ä¸Šä¸€äº›å‚æ•°æ¥é™åˆ¶ max_messages çš„æ•°é‡ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fb3fc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwen-max\n",
      "qwen-turbo\n"
     ]
    }
   ],
   "source": [
    "class DynamicModelMiddleware(AgentMiddleware):\n",
    "    def __init__(self, max_messages: int = 3):\n",
    "        super().__init__()\n",
    "        self.max_messages = max_messages\n",
    "    def wrap_model_call(self, request: ModelRequest, handler):\n",
    "        if len(request.messages) > self.max_messages:\n",
    "            new_model = ChatTongyi(api_key=os.environ.get(\"DASHSCOPE_API_KEY\"), model=\"qwen-turbo\")\n",
    "        else:\n",
    "            new_model = ChatTongyi(api_key=os.environ.get(\"DASHSCOPE_API_KEY\"), model=\"qwen-max\")\n",
    "        new_request = request.override(model=new_model)\n",
    "        return handler(new_request)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    middleware=[DynamicModelMiddleware(max_messages=4)],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"è¯·ä½¿ç”¨ arxiv å·¥å…·æŸ¥è¯¢è®ºæ–‡ç¼–å· 1605.08386\"}]}, \n",
    "    config={\"configurable\": {\"thread_id\": \"10\"}})\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ä½ æ˜¯è°\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": \"10\"}})\n",
    "\n",
    "print(result[\"messages\"][1].response_metadata[\"model_name\"])\n",
    "print(result[\"messages\"][-1].response_metadata[\"model_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a495430",
   "metadata": {},
   "source": [
    "è¿™æ ·æˆ‘ä»¬æ­£å¸¸çš„è¿›è¡Œè°ƒç”¨å°±ä¼šå‘ç°ç¬¬äºŒæ¬¡è°ƒç”¨çš„æ¨¡å‹å°±ä»åŸæœ¬çš„ qwen-max è½¬å˜ä¸ºäº† qwen-trubo ï¼Œè¿™æ ·å°±å¯ä»¥å¤§å¤§èŠ‚çœ token çš„æ¶ˆè€—äº†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bad626",
   "metadata": {},
   "source": [
    "#### æ¡ˆä¾‹ 3ï¼šdynamic_prompt\n",
    "\n",
    "é™¤äº†ä¼ ç»Ÿçš„ wrap_model_call ä»¥å¤–ï¼Œåœ¨ LangChain å®˜æ–¹æ–‡æ¡£ä¸­è¿˜ä»‹ç»äº†ä¸€ä¸ªåŸºäºå…¶æ”¹é€ çš„è£…é¥°å™¨ dynamic_promptã€‚ç›¸æ¯”äº wrap_model_callï¼Œdynamic_prompt ä»…ä»…ä½œç”¨åœ¨æ¨¡å‹è°ƒç”¨å‰ï¼Œæ‰€ä»¥å…¶ä¼ å…¥çš„åªæœ‰ request çš„ä¿¡æ¯è€Œæ²¡æœ‰ handlerã€‚\n",
    "\n",
    "æ‰€ä»¥ä»æŠ€æœ¯çš„è§’åº¦ä¸Šçœ‹ï¼Œ@dynamic_prompt æ˜¯åŸºäº @wrap_model_call çš„ç‰¹ä¾‹å°è£…ï¼ˆä¸“ç”¨äº system_prompt åŠ¨æ€æ³¨å…¥ï¼‰ã€‚\n",
    "\n",
    "ä¸‹é¢è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ get() è·å– request é‡Œçš„ runtime.context ä¿¡æ¯ï¼Œçœ‹é‡Œé¢æ˜¯å¦æœ‰ä¿å­˜å’Œ user_id çš„å†…å®¹ï¼Œå‡å¦‚æœ‰å°±ç”¨é‡Œé¢çš„å†…å®¹ã€‚å‡å¦‚æ²¡æœ‰å°±ç”¨é»˜è®¤çš„ guest å†™å…¥æç¤ºè¯ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ea25cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘æ˜¯å‰‘é”‹å¤§ä½¬çš„å°åŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import dynamic_prompt\n",
    "\n",
    "@dynamic_prompt\n",
    "def dynamic_system_prompt(request: ModelRequest) -> str:\n",
    "    user_name = getattr(request.runtime.context, \"user_name\", \"guest\")\n",
    "    system_prompt = f\"ä½ æ˜¯ {user_name} å¤§ä½¬çš„å°åŠ©æ‰‹ï¼Œè®°å¥½äº†å“¦ï¼\"\n",
    "    return system_prompt\n",
    "\n",
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_name: str\n",
    "\n",
    "agent = create_agent(\n",
    " model=llm,\n",
    " tools=tools,\n",
    " middleware=[dynamic_system_prompt],\n",
    " context_schema=Context, # âœ… è¿™é‡ŒæŒ‡å®šç»“æ„\n",
    " checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ä½ æ˜¯è°ï¼Ÿ\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": \"1\"}},\n",
    "    context=Context(user_name=\"å‰‘é”‹\") # âœ… è¿™é‡Œä¼ å…¥å®ä¾‹\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3260179",
   "metadata": {},
   "source": [
    "## 4.2 Wrap_tool_call\n",
    "\n",
    "### 4.2.1 è¾“å…¥å‚æ•° ToolCallRequest\n",
    "\n",
    "ä¸ ModelRequest ç±»ä¼¼ï¼Œ ToolCallRequest æ˜¯åœ¨æ¨¡å‹è§¦å‘å·¥å…·è°ƒç”¨ï¼ˆFunction Callingï¼‰ ä¹‹åï¼Œä¼ å…¥ç»™ wrap_tool_call è¿™ä¸ª hook çš„å‚æ•°å¯¹è±¡ã€‚å…¶å†…éƒ¨åŒ…å«çš„å‚æ•°å¦‚ä¸‹ï¼š\n",
    "\n",
    "```python\n",
    "ToolCallRequest(\n",
    "    tool_call: ToolCall,              # âœ… å·¥å…·è°ƒç”¨ä¿¡æ¯ï¼ˆåŒ…å« nameã€argsã€idï¼‰\n",
    "    tool: Optional[BaseTool] = None,  # âœ… å½“å‰æ³¨å†Œçš„å·¥å…·ï¼ˆæœªæ³¨å†Œåˆ™ä¸º Noneï¼‰\n",
    "    state: Any,                       # âœ… å½“å‰æ™ºèƒ½ä½“çŠ¶æ€ï¼ˆé€šå¸¸æ˜¯ AgentState å­—å…¸ï¼‰\n",
    "    runtime: Optional[ToolRuntime] = None  # âœ… å·¥å…·è¿è¡Œæ—¶ä¸Šä¸‹æ–‡\n",
    ")\n",
    "```\n",
    "\n",
    "#### ToolRuntime\n",
    "\n",
    "ToolRuntime æ˜¯ LangChain åœ¨å·¥å…·è°ƒç”¨è¿‡ç¨‹ä¸­è‡ªåŠ¨æ³¨å…¥çš„è¿è¡Œç¯å¢ƒå¯¹è±¡ï¼Œå®ƒä¸ºå·¥å…·å‡½æ•°æä¾›äº†å¯¹æ™ºèƒ½ä½“å½“å‰æ‰§è¡Œä¸Šä¸‹æ–‡ï¼ˆstate/context/configï¼‰çš„è®¿é—®èƒ½åŠ›ï¼Œå¸®åŠ©æˆ‘ä»¬å®ç°æ›´çµæ´»ã€æ›´æ™ºèƒ½çš„å·¥å…·è¡Œä¸ºã€‚\n",
    "\n",
    "```python\n",
    "ToolRuntime(\n",
    "  state: dict | BaseModel,    # ğŸ§  AgentState å½“å‰æ™ºèƒ½ä½“çŠ¶æ€ï¼ˆçŸ­æœŸè®°å¿†ï¼‰\n",
    "  context: dict | None,     # ğŸŒ Runtime Context æ‰§è¡Œä¸Šä¸‹æ–‡ï¼ˆè¿è¡Œæ—¶ä¼ å…¥ï¼‰\n",
    "  config: RunnableConfig,    # âš™ï¸ å½“å‰æ‰§è¡Œé…ç½®ï¼ŒåŒ…å« run_idã€metadataã€tags ç­‰\n",
    "  stream_writer: StreamWriter,  # ğŸ“¡ å®æ—¶æµå¼è¾“å‡ºå¯¹è±¡\n",
    "  tool_call_id: str | None,   # ğŸ”— å½“å‰å·¥å…·è°ƒç”¨å”¯ä¸€æ ‡è¯†ç¬¦\n",
    "  store: BaseStore | None    # ğŸ’¾ Store æŒä¹…åŒ–å­˜å‚¨æ¥å£ï¼ˆé•¿æœŸè®°å¿†ï¼‰\n",
    ")\n",
    "```\n",
    "\n",
    "#### æ›´æ–° ToolCallRequest\n",
    "\n",
    "ç±»ä¼¼äº ModelRequest ï¼ŒToolCallRequest çš„å†…å®¹ä¹Ÿæ˜¯èƒ½å¤Ÿä¿®æ”¹åå†ä¼ ç»™æ¨¡å‹çš„ã€‚æˆ‘ä»¬ä¹Ÿæ˜¯ä½¿ç”¨ .override() æ–¹æ³•è¿›è¡Œä¿®æ”¹å³å¯ã€‚\n",
    "\n",
    "æ¯”å¦‚æˆ‘ä»¬ä¹Ÿå¯ä»¥ç”¨ .override() åˆ›å»ºæ–°è¯·æ±‚å†è°ƒç”¨ handlerï¼š\n",
    "\n",
    "```python\n",
    "# ä½ æƒ³ä¿®æ”¹å·¥å…·å‚æ•°ï¼Œæ¯”å¦‚æŠŠåŸå¸‚æ”¹æˆâ€œæ·±åœ³â€\n",
    "new_args = {\"city\": \"æ·±åœ³\"}\n",
    "new_tool_call = request.tool_call.override(args=new_args)\n",
    "\n",
    "# ä½¿ç”¨ override åˆ›å»ºæ–°è¯·æ±‚å‰¯æœ¬\n",
    "new_request = request.override(tool_call=new_tool_call)\n",
    "\n",
    "# åŒæ—¶ä¿®æ”¹å¤šä¸ªå†…å®¹æ„å»º ToolCallRequest\n",
    "new_request = request.override(\n",
    "    tool_call=new_tool_call,     # ä¿®æ”¹è°ƒç”¨å†…å®¹\n",
    "    state=new_state,             # æ›¿æ¢ agent state\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### 4.2.2 è¾“å…¥å‚æ•° handler\n",
    "\n",
    "ä¸ Wrap_model_call ç±»ä¼¼ï¼ŒWrap_tool_call æœ¬è´¨ä¸Šä¹Ÿæ˜¯ä¸€ä¸ª Callable çš„å‡½æ•°ï¼ˆCallable[[ToolCallRequest], ToolMessage | Command]ï¼‰\n",
    "\n",
    "å…¶è¾“å…¥çš„æ˜¯ ToolCallRequestï¼Œ è¿”å›çš„å¯èƒ½æ˜¯ ToolMessage æˆ– Commandã€‚\n",
    "\n",
    "ä¸€ä¸ªå¯èƒ½çš„ handler å†…éƒ¨åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæµç¨‹ï¼š\n",
    "- ä» Function Calling è¿”å›çš„ä¿¡æ¯ä¸­è·å–å¿…è¦ä¿¡æ¯\n",
    "- æ ¡éªŒå·¥å…·æ˜¯å¦å­˜åœ¨\n",
    "- æ‰§è¡Œå·¥å…·\n",
    "- å°†ç»“æœå°è£…ä¸º ToolMessage\n",
    "\n",
    "```python\n",
    "def handler(request: ToolCallRequest) -> ToolMessage:\n",
    "    # 1. æå–å·¥å…·è°ƒç”¨ç›¸å…³ä¿¡æ¯\n",
    "    tool_call = request.tool_call           # è·å–æ¨¡å‹çš„è°ƒç”¨ä¿¡æ¯\n",
    "    tool = request.tool                     # è·å–å·²æ³¨å†Œçš„å·¥å…·\n",
    "\n",
    "    # 2. æ ¡éªŒå·¥å…·æ˜¯å¦å­˜åœ¨ï¼ˆå¯é€‰ï¼‰\n",
    "    if tool is None:\n",
    "        raise ValueError(f\"å·¥å…· {tool_call.name} æœªæ³¨å†Œ\")\n",
    "\n",
    "    # 3. æ‰§è¡Œå·¥å…·ï¼ˆ** è§£åŒ…å‚æ•°ï¼‰\n",
    "    try:\n",
    "        result = tool.invoke(**tool_call.args)\n",
    "    except Exception as e:\n",
    "        result = f\"å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}\"\n",
    "\n",
    "    # 4. å°è£…ä¸º ToolMessage\n",
    "    return ToolMessage(\n",
    "        tool_call_id=tool_call.id,\n",
    "        content=str(result)  # å·¥å…·è¿”å›å€¼å¿…é¡»æ˜¯å­—ç¬¦ä¸²\n",
    "    )\n",
    "```\n",
    "\n",
    "### 4.2.3 è¾“å‡ºå†…å®¹ ToolMessage\n",
    "\n",
    "å½“ä¸€ä¸ªå·¥å…·è¢«è°ƒç”¨åï¼ŒLangChain / LangGraph ä¼šæŠŠè¯¥å·¥å…·çš„æ‰§è¡Œç»“æœï¼ŒåŒ…è£…æˆä¸€ä¸ª ToolMessageï¼Œç„¶åæŠŠè¿™ä¸ª ToolMessage è¿½åŠ åˆ°å¯¹è¯å†å²é‡Œï¼Œäº¤è¿˜ç»™å¤§æ¨¡å‹ã€‚\n",
    "\n",
    "è¿™ä¸ªæ—¶å€™ ToolMessage çš„å†…éƒ¨å¦‚ä¸‹æ‰€ç¤ºï¼š\n",
    "\n",
    "```python\n",
    "ToolMessage(\n",
    "    tool_call_id: str,                        # âœ… å¿…å¡«ï¼Œå¯¹åº”æ¨¡å‹å‘èµ·çš„æŸä¸ª tool è°ƒç”¨çš„å”¯ä¸€ ID\n",
    "    content: Union[str, list[str | dict]],    # âœ… å·¥å…·æ‰§è¡Œç»“æœï¼Œå‘å›æ¨¡å‹çš„ä¸»è¦å†…å®¹ï¼ˆä¼šå¼ºåˆ¶è½¬æˆ str æˆ– listï¼‰\n",
    "    type: Literal[\"tool\"] = \"tool\",           # âœ… å›ºå®šå€¼ï¼š\"tool\"ï¼Œè¡¨ç¤ºè¿™æ˜¯ä¸€æ¡å·¥å…·è¿”å›æ¶ˆæ¯\n",
    "    artifact: Any = None,                     # â›³ å¯é€‰ï¼Œå·¥å…·çš„å®Œæ•´åŸå§‹äº§å‡ºï¼ˆé€šå¸¸ä¸å‘ç»™æ¨¡å‹ï¼‰\n",
    "    status: Literal[\"success\", \"error\"] = \"success\",  # â›³ å¯é€‰ï¼Œæ‰§è¡ŒçŠ¶æ€\n",
    "    additional_kwargs: dict = {},             # â›³ é¢„ç•™å­—æ®µï¼Œå½“å‰æœªä½¿ç”¨\n",
    "    response_metadata: dict = {},             # â›³ é¢„ç•™å­—æ®µï¼Œå½“å‰æœªä½¿ç”¨\n",
    ")\n",
    "```\n",
    "\n",
    "### 4.2.4 è¾“å‡ºå†…å®¹ Command\n",
    "\n",
    "Command æ˜¯ LangGraph é‡Œä¸€ä¸ªâ€œæŒ‡ä»¤å¯¹è±¡â€ï¼ŒèŠ‚ç‚¹è¿”å›å®ƒä¹‹åï¼Œå¯ä»¥åŒæ—¶åšä¸¤ä»¶äº‹ï¼š\n",
    "- æ›´æ–°çŠ¶æ€ï¼ˆstateï¼‰\n",
    "- å†³å®šä¸‹ä¸€æ­¥è·³åˆ°å“ªä¸ªèŠ‚ç‚¹\n",
    "\n",
    "å¸¸è§çš„ä½¿ç”¨æ–¹å¼å¦‚ä¸‹ï¼š\n",
    "- update={...}ï¼šæŠŠè¿™äº›é”®å€¼å†™å›å…¨å±€çŠ¶æ€ï¼Œåˆ«çš„èŠ‚ç‚¹ä¹‹åå°±èƒ½ç”¨åˆ°ã€‚\n",
    "- goto=\"show_dashboard\"ï¼šä¸‹ä¸€æ­¥åˆ«æŒ‰é»˜è®¤è¿çº¿èµ°äº†ï¼Œç›´æ¥å»è·‘ show_dashboard è¿™ä¸ªèŠ‚ç‚¹ã€‚\n",
    "\n",
    "```python\n",
    "def check_login(state: dict) -> Command[Literal[\"show_dashboard\"]]:\n",
    "    # å‡è®¾æˆ‘ä»¬éªŒè¯ç™»å½•æˆåŠŸäº†\n",
    "    return Command(\n",
    "        update={\"user\": \"alice\", \"login_ok\": True},  # â‘  æ›´æ–°çŠ¶æ€\n",
    "        goto=\"show_dashboard\"                        # â‘¡ æŒ‡å®šä¸‹ä¸€ä¸ªèŠ‚ç‚¹\n",
    "    )\n",
    "```\n",
    "\n",
    "Command ä¸åªæ˜¯â€œå»å›ºå®šä¸‹ä¸€ä¸ªèŠ‚ç‚¹â€ï¼Œè¿˜å¯ä»¥â€œæ ¹æ®çŠ¶æ€å†³å®šå»å“ªä¸ªèŠ‚ç‚¹â€ï¼Œæ¯”å¦‚ï¼š\n",
    "\n",
    "``` python\n",
    "def route_question(state: dict) -> Command[Literal[\"faq_bot\", \"human_agent\"]]:\n",
    "    # å¦‚æœæ˜¯ç®€å•é—®é¢˜ -> æœºå™¨äººå›ç­”\n",
    "    if state[\"question_type\"] == \"FAQ\":\n",
    "        return Command(\n",
    "            update={\"handled_by\": \"bot\"},\n",
    "            goto=\"faq_bot\"\n",
    "        )\n",
    "    # å¦åˆ™ -> è½¬äººå·¥å®¢æœ\n",
    "    else:\n",
    "        return Command(\n",
    "            update={\"handled_by\": \"human\"},\n",
    "            goto=\"human_agent\"\n",
    "        )\n",
    "```\n",
    "\n",
    " -> Command[Literal[\"faq_bot\", \"human_agent\"]] è¿™é‡Œè¡¨ç¤ºå¯èƒ½è·³è½¬çš„èŠ‚ç‚¹\n",
    "\n",
    "é™¤äº†æœ€å¸¸è§çš„ update å’Œ goto ä»¥å¤–ï¼ŒCommand è¿˜æœ‰ä¸¤ä¸ªå…¶ä»–çš„å‚æ•° graph å’Œ resumeï¼š\n",
    "\n",
    "- graph å¸¸ç”¨äºå¤šæ™ºèƒ½ä½“/å¤šå­æµç¨‹åä½œã€‚æ¯”å¦‚å½“å‰åªæ˜¯æŸä¸ªå­ä»»åŠ¡åœ¨è¿›è¡Œï¼Œå®Œæˆåéœ€è¦å›åˆ°ä¸»æµç¨‹ä¸­æ—¶éœ€è¦ä½¿ç”¨ï¼š\n",
    "\n",
    "```python\n",
    "def refund_agent(state: dict) -> Command[Literal[\"handoff_to_main\"]]:\n",
    "    # å­å›¾é‡Œçš„èŠ‚ç‚¹\n",
    "    return Command(\n",
    "        update={\"refund_status\": \"submitted\"},\n",
    "        goto=\"handoff_to_main\",  # äº¤è¿˜å›ä¸»æµç¨‹é‡Œçš„èŠ‚ç‚¹\n",
    "        graph=Command.PARENT     # ğŸ‘ˆ å…³é”®ï¼šå‘Šè¯‰ LangGraphï¼Œæˆ‘ç°åœ¨è¦è·³å›çˆ¶å›¾\n",
    "    )\n",
    "```\n",
    "\n",
    "- resume å¸¸ç”¨äºäººç±»ä»‹å…¥æ—¶ä½¿ç”¨ã€‚å½“äººç±»ä»‹å…¥åï¼Œå…ˆæ˜¯ä¼šæœ‰ä¸€ä¸ªæš‚åœç‚¹ï¼ˆinterruptï¼‰ä¸­æ–­æµç¨‹ï¼Œç„¶åå†æ¥æ”¶åé¦ˆï¼ˆresumeï¼‰ åé‡å¯ã€‚åç»­è®²è§£ Human-In-Loop ä¼šæ·±å…¥è®²è§£ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda45f8e",
   "metadata": {},
   "source": [
    "### 4.2.5 wrap_tool_call æ¡ˆä¾‹å±•ç¤º\n",
    "\n",
    "#### æ¡ˆä¾‹ 1ï¼šmonitor_tool\n",
    "\n",
    "è€Œå¯¹äºå·¥å…·è°ƒç”¨è€Œè¨€ï¼Œå…¶å®å’Œæ¨¡å‹è°ƒç”¨ä¸€æ ·ï¼Œä¸»è¦æ˜¯æŸ¥çœ‹ä¸€ä¸‹è°ƒç”¨çš„å·¥å…·æ˜¯å¦æ˜¯æ­£ç¡®çš„ï¼Œæˆ–è€…è¯´å½“å·¥å…·è°ƒç”¨å‡ºç°é—®é¢˜çš„æ—¶å€™æ¥é‡è¯•å‡ æ¬¡ç”šè‡³æ¢ä¸ªå·¥å…·ã€‚\n",
    "\n",
    "é‚£å¯¹äºä¸‹é¢çš„ä¸­é—´ä»¶ monitor_tool ï¼Œå…¶å…ˆæ˜¯æ‰“å°äº†ä¸€ä¸‹ä½¿ç”¨çš„å·¥å…·å’Œä¼ å…¥çš„å‚æ•°ä¿¡æ¯ï¼Œç„¶åé€šè¿‡ handler å»è°ƒç”¨äº†ä¸€ä¸‹ã€‚å‡å¦‚æˆåŠŸå°±æ‰“å°ä¿¡æ¯è¿”å›ç»“æœï¼Œå‡å¦‚å¤±è´¥å°±æŠ¥é”™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3689ff24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing tool: arxiv\n",
      "Arguments: {'query': '1605.08386'}\n",
      "Tool completed successfully\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import wrap_tool_call\n",
    "from langchain.tools.tool_node import ToolCallRequest\n",
    "from langchain.messages import ToolMessage\n",
    "from langgraph.types import Command\n",
    "from typing import Callable\n",
    "\n",
    "@wrap_tool_call\n",
    "def monitor_tool(request: ToolCallRequest, handler: Callable[[ToolCallRequest], ToolMessage | Command]) -> ToolMessage | Command:\n",
    "    print(f\"Executing tool: {request.tool_call['name']}\")\n",
    "    print(f\"Arguments: {request.tool_call['args']}\")\n",
    "    try:\n",
    "        result = handler(request)\n",
    "        print(f\"Tool completed successfully\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Tool failed: {e}\")\n",
    "        raise\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    middleware=[monitor_tool],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"è¯·ä½¿ç”¨ arxiv å·¥å…·æŸ¥è¯¢è®ºæ–‡ç¼–å· 1605.08386\"}]}, \n",
    "    config={\"configurable\": {\"thread_id\": \"10\"}})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8522a374",
   "metadata": {},
   "source": [
    "ç±»ä¼¼çš„ï¼Œè¿™ä¸ªä¸­é—´ä»¶æˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡ç±»è¿›è¡Œåˆ›å»ºï¼ŒåŒºåˆ«å°±æ˜¯åç§°æ”¹ä¸ºäº† ToolMonitoringMiddleware è€Œå·²ï¼Œå¹¶ä¸”ä¼ å…¥ç»™ middleware æ—¶è¦å†™ä¸º middleware=[ToolMonitoringMiddleware()] ã€‚å…¶ä»–åœ¨å®é™…ä½¿ç”¨ä¸Šå…¶å®æ²¡æœ‰ä»»ä½•åŒºåˆ«ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b31f467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing tool: arxiv\n",
      "Arguments: {'query': '1605.08386'}\n",
      "Tool completed successfully\n"
     ]
    }
   ],
   "source": [
    "class ToolMonitoringMiddleware(AgentMiddleware):\n",
    "    def wrap_tool_call(self, request: ToolCallRequest, handler: Callable[[ToolCallRequest], ToolMessage | Command]) -> ToolMessage | Command:\n",
    "        print(f\"Executing tool: {request.tool_call['name']}\")\n",
    "        print(f\"Arguments: {request.tool_call['args']}\")\n",
    "\n",
    "        try:\n",
    "            result = handler(request)\n",
    "            print(f\"Tool completed successfully\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Tool failed: {e}\")\n",
    "            raise\n",
    "        \n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    middleware=[ToolMonitoringMiddleware()],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"è¯·ä½¿ç”¨ arxiv å·¥å…·æŸ¥è¯¢è®ºæ–‡ç¼–å· 1605.08386\"}]}, \n",
    "    config={\"configurable\": {\"thread_id\": \"10\"}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chapter_6_2025_12_15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
