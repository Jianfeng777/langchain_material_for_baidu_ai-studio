{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be38a4ea",
   "metadata": {},
   "source": [
    "# 1. 环境配置\n",
    "\n",
    "## 1.1 python 环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68bc798e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: openai==2.11.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: dashscope==1.25.4 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (1.25.4)\n",
      "Requirement already satisfied: langchain-classic==1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain==1.1.3 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: langchain-community==0.4.1 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-openai==1.1.3 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: arxiv==2.3.1 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from openai==2.11.0) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from openai==2.11.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from openai==2.11.0) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from openai==2.11.0) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from openai==2.11.0) (2.12.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from openai==2.11.0) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from openai==2.11.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from openai==2.11.0) (4.15.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (3.13.2)\n",
      "Requirement already satisfied: requests in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (2.32.5)\n",
      "Requirement already satisfied: websocket-client in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (1.9.0)\n",
      "Requirement already satisfied: cryptography in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (46.0.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (2025.11.12)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (1.2.2)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (1.1.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.17 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (0.5.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (6.0.3)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (2.0.45)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain==1.1.3) (1.0.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (2.3.5)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-openai==1.1.3) (0.12.0)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from arxiv==2.3.1) (6.0.12)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from anyio<5,>=3.5.0->openai==2.11.0) (3.11)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1) (0.9.0)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from feedparser~=6.0.10->arxiv==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from httpx<1,>=0.23.0->openai==2.11.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==2.11.0) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic==1.0.0) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic==1.0.0) (25.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic==1.0.0) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-classic==1.0.0) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (0.3.0)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (1.12.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic==1.0.0) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic==1.0.0) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==2.11.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==2.11.0) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==2.11.0) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community==0.4.1) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from requests->dashscope==1.25.4) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from requests->dashscope==1.25.4) (2.6.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from sqlalchemy<3.0.0,>=1.4.0->langchain-classic==1.0.0) (3.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai==1.1.3) (2025.11.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from tqdm>4->openai==2.11.0) (0.4.6)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from cryptography->dashscope==1.25.4) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\76391\\.conda\\envs\\chapter_6_2025_12_15\\lib\\site-packages (from cffi>=2.0.0->cryptography->dashscope==1.25.4) (2.23)\n"
     ]
    }
   ],
   "source": [
    "! pip install openai==2.11.0 dashscope==1.25.4 langchain-classic==1.0.0 langchain==1.1.3 langchain-community==0.4.1 langchain-openai==1.1.3 arxiv==2.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c134430",
   "metadata": {},
   "source": [
    "## 1.2 大模型密钥准备\n",
    "\n",
    "请根据第一章内容获取相关平台的 API KEY，如若未在系统变量中填入，请将 API_KEY 信息写入以下代码（若已设置请忽略）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f510216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxx\"\n",
    "# os.environ[\"DASHSCOPE_API_KEY\"] = \"sk-yyyyyyyy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de64801e",
   "metadata": {},
   "source": [
    "## 1.3 实践代码\n",
    "\n",
    "为了能够顺利的演示内置中间件的使用详情，这里我们使用一段简单的智能体代码演示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51e588a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "论文编号 1605.08386 的标题是 \"Heat-bath random walks with Markov bases\"，作者是 Caprice Stanley 和 Tobias Windisch。该论文于 2016 年 5 月 26 日发布。\n",
      "\n",
      "这篇论文研究了格点上的图，其边来自于有限集的允许移动。我们证明了在固定整数矩阵的纤维上，这些图的直径可以被常数从上方界。然后我们研究了这些图上的热浴随机游走的混合行为。我们还给出了移动集的显式条件，使得热浴随机游走（Glauber 动态的一种推广）在固定维度中是一个扩展器。\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "llm = ChatTongyi(api_key=os.environ.get(\"DASHSCOPE_API_KEY\"), model=\"qwen-turbo\")\n",
    "\n",
    "from langchain_community.agent_toolkits.load_tools import load_tools\n",
    "tools = load_tools([\"arxiv\"])\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver \n",
    "memory = InMemorySaver()\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "agent = create_agent(model=llm, \n",
    "                     tools=tools, \n",
    "                     system_prompt=\"You are a helpful assistant\", \n",
    "                     checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab73bb9",
   "metadata": {},
   "source": [
    "# 2. 内置中间件\n",
    "\n",
    "## 2.1 简介\n",
    "\n",
    "针对于一些智能体开发常用的中间件，LangChain 官方团队给出了一系列的内置中间件来帮助大家进行快速上手。这些中间件包括：\n",
    "- ModelFallbackMiddleware：主模型失败时自动换模型\n",
    "- ModelCallLimitMiddleware：限制模型调用次数\n",
    "- ToolCallLimitMiddleware：限制工具调用频率\n",
    "- ToolRetryMiddleware：工具失败时自动重试\n",
    "- LLMToolEmulator：用LLM模拟工具执行\n",
    "- SummarizationMiddleware：摘要对话历史\n",
    "- ContextEditingMiddleware：清理旧上下文\n",
    "- PIIMiddleware：检测/脱敏个人隐私信息\n",
    "- HumanInTheLoopMiddleware：人工审批确认机制\n",
    "- ...\n",
    "\n",
    "## 2.2 ModelFallbackMiddleware：模型容灾与降级策略\n",
    "\n",
    "在实际部署智能体（Agent）时，经常会遇到这些情况：\n",
    "- 主模型（如 qwen-max）暂时不可用或返回错误；\n",
    "- 模型超时、API 限额、或延迟太高；\n",
    "- 想节省成本，用小模型在轻任务中“兜底”。\n",
    "\n",
    "所以 LangChain 官方提供了一个作用在 wrap_model_call 的内置中间件 ModelFallbackMiddleware ，在主模型失败时自动切换备用模型，保持任务不中断。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc21d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "论文信息如下：\n",
      "\n",
      "**发表时间**：2016-05-26  \n",
      "**标题**：Heat-bath random walks with Markov bases（具有马尔可夫基的热浴随机游走）  \n",
      "**作者**：Caprice Stanley, Tobias Windisch  \n",
      "\n",
      "**摘要**：研究了格点上图的边来自任意长度有限允许移动集的情况。我们证明了这些图在固定整数矩阵纤维上的直径可以从上方用一个常数来限定。然后我们研究了在这些图上热浴随机游走的混合行为。我们还给出了移动集合的明确条件，使得热浴随机游走（Glauber动力学的一种推广）在固定维度下是一个扩张器。\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import ModelFallbackMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "  model=ChatTongyi(model=\"xxx\"), # 错误模型\n",
    "  tools=tools,\n",
    "  system_prompt=\"You are a helpful assistant\",\n",
    "  middleware=[ModelFallbackMiddleware(\n",
    "      ChatTongyi(model=\"qwen-plus\"),\n",
    "      ChatTongyi(model=\"qwen-turbo\",\n",
    "      checkpointer=memory))])\n",
    "\n",
    "result1 = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"请使用 arxiv 工具查询论文编号 1605.08386\"}]}, config={\"configurable\": {\"thread_id\": \"user_1\"}})\n",
    "\n",
    "print(result1[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cbf4b6",
   "metadata": {},
   "source": [
    "## 2.3 ModelCallLimitMiddleware：限制模型调用次数\n",
    "\n",
    "在一个智能体执行循环（Agent Loop）中，模型会多次被调用：\n",
    "- 一次决定“要不要用工具”；\n",
    "- 一次执行后判断“是否需要再次调用”；\n",
    "- 再次思考结果、继续调用或返回最终结果。\n",
    "\n",
    "在 ReAct-style agent 中，如果 LLM 的输出不够理性，可能会进入：输入→ 模型思考 → 工具调用 → 模型思考 → 工具调用 → 模型思考... 这种循环，轻则多花钱，重则“跑爆上下文”。\n",
    "\n",
    "因此，ModelCallLimitMiddleware 的作用就是限定模型调用次数，一旦达到上限，就让 Agent 自动停止或报错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce2f70cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model call limits exceeded: thread limit (2/2)\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import ModelCallLimitMiddleware\n",
    "\n",
    "middleware_model_limit = ModelCallLimitMiddleware(thread_limit=2, run_limit=1)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    "    middleware=[middleware_model_limit],\n",
    "    checkpointer=InMemorySaver()\n",
    ")\n",
    "\n",
    "config3 = {\"configurable\": {\"thread_id\": \"user_3\"}}\n",
    "\n",
    "result1 = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"请使用 arxiv 工具查询论文编号 1605.08386，100字即可\"}]}, config=config3)\n",
    "result2 = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"你能总结一下吗？100字即可\"}]}, config=config3)\n",
    "result3 = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"推荐几篇拓展阅读吧\"}]}, config=config3)\n",
    "\n",
    "print(result3[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d860216",
   "metadata": {},
   "source": [
    "## 2.4 ToolCallLimitMiddleware：限制工具调用次数\n",
    "类似的，除了有模型调用的限制以外，还有一个就是限制工具调用的次数。在实际智能体（Agent）执行循环中，工具调用（Tool Calls）往往是最昂贵或最不确定的环节：\n",
    "- 有的工具访问外部 API（比如搜索、数据库查询）；\n",
    "- 有的工具运行时间长（比如爬虫、OCR、代码执行）；\n",
    "- 如果模型逻辑出错，可能疯狂调用工具，导致成本暴涨或资源占满。\n",
    "\n",
    "这也是为什么 LangChain 提供了 ToolCallLimitMiddleware ，通过在调用工具的前后设置调用次数上限，防止 Agent 过度调用工具或陷入无穷循环。\n",
    "- before_model：判断调用次数是否达到上限；\n",
    "- after_model：统计这次模型调用中生成了几个 tool_call 并计数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af1faf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool call limit exceeded. Do not call 'arxiv' again.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import ToolCallLimitMiddleware\n",
    "\n",
    "middleware=[\n",
    "    ToolCallLimitMiddleware(run_limit=10),  # 全局\n",
    "    ToolCallLimitMiddleware(tool_name=\"arxiv\", thread_limit=1),  # 局部\n",
    "]\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    "    middleware=middleware,\n",
    "    checkpointer=InMemorySaver()\n",
    ")\n",
    "\n",
    "config3 = {\"configurable\": {\"thread_id\": \"user_3\"}}\n",
    "\n",
    "result1 = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"请使用 arxiv 工具查询论文编号 1605.08386，100字即可\"}]}, config=config3)\n",
    "result2 = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"请使用 arxiv 工具查询论文编号 2103.08386，100字即可\"}]}, config=config3)\n",
    "\n",
    "\n",
    "print(result2[\"messages\"][-2].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b523cee7",
   "metadata": {},
   "source": [
    "## 2.5 ToolRetryMiddleware：工具调用自动重试机制\n",
    "\n",
    "在工具调用的过程中，我们常常还会遇到一些外部的问题，比如网络连接失败、数据库连接失败、模型执行有问题等等。那在工具调用（Tool call）失败时，如何让 Agent 不会立即崩溃或返回错误，这就成了急切需要解决的问题。\n",
    "\n",
    "所以这个时候，ToolRetryMiddleware 就给出了一个方案，不仅仅可以在调用工具的时候重复多次，还能够设置延时、指数回退（exponential backoff）、随机扰动（jitter）等机制。从而让智能体在调用不稳定外部服务（例如网络请求、搜索接口、数据库API）时更加鲁棒（robust）。\n",
    "\n",
    "其作用的位置是在 wrap_tool_call 中，也就是工具调用时。其目标就是如果工具出错，就重试几次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f7b51cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import ToolRetryMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "  model=llm,\n",
    "  tools=tools,\n",
    "  system_prompt=\"You are a helpful assistant\",\n",
    "  middleware=[\n",
    "    ToolRetryMiddleware(\n",
    "      max_retries=3,   # 最多重试 3 次\n",
    "      backoff_factor=2.0, # 指数退避倍数\n",
    "      initial_delay=1.0, # 首次延迟 1 秒\n",
    "      max_delay=60.0,   # 最大等待时间 60 秒\n",
    "      jitter=True,    # 添加随机扰动，防止雪崩重试\n",
    "    ),\n",
    "  ],\n",
    "  checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc854974",
   "metadata": {},
   "source": [
    "## 2.6 LLMToolEmulator：用模型“假装”执行工具\n",
    "有些时候，在还没有实现具体的工具逻辑的时候，但是这个工具又非常重要的时候，我们可以通过用 LLM 来模拟工具的执行结果（tool emulation）。这样就可以让整体流程先顺利进行，后面再补充相对应的逻辑。\n",
    "\n",
    "比如当 agent 决定调用某个工具时（如 search_database()），这个中间件会拦截掉真正的工具调用，然后由另一个 LLM 生成“模拟的工具返回结果”。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73696d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "论文编号 1605.08386 的标题是《The Nonlinear Electrodynamics of the Dirac-Born-Infeld Type》。该论文由 R. R. C. G. B. de Almeida 和 A. P. de Carvalho 撰写，发表于 2016 年 5 月 27 日。\n",
      "\n",
      "摘要中提到，这篇论文研究了五维时空中的 Dirac-Born-Infeld 类非线性电动力学。作者推导了电磁场的运动方程，并分析了不同极限下的行为。所得解显示出有趣的物理特性，包括形成规则黑洞的可能性。\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import LLMToolEmulator\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    middleware=[\n",
    "        LLMToolEmulator(\n",
    "            model = ChatTongyi(model=\"qwen-turbo\"),\n",
    "            tools=[\"arxiv\"],\n",
    "        ), \n",
    "    ],\n",
    ")\n",
    "\n",
    "result1 = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"请使用 arxiv 工具查询论文编号 1605.08386\"}]}, config={\"configurable\": {\"thread_id\": \"user_1\"}})\n",
    "print(result1[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c7e473",
   "metadata": {},
   "source": [
    "当我们希望所有的工具都用 LLM 进行模拟，我们可以这样写入（tools 参数里传入 None）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "405f7f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "广州的天气目前是多云，气温28摄氏度，湿度65%，风速10公里每小时。\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import LLMToolEmulator\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    ''' 获取指定位置的天气信息 '''\n",
    "    message = f\"获取 {location} 的天气信息\"\n",
    "    print(message)  \n",
    "    return message\n",
    "\n",
    "@tool\n",
    "def search_database(query: str) -> str:\n",
    "    ''' 从数据库中搜索相关信息 '''\n",
    "    message = f\"数据库中关于 {query} 的信息是：...\"\n",
    "    print(message)  \n",
    "    return message  \n",
    "    \n",
    "@tool\n",
    "def send_email(to: str, subject: str, body: str) -> str:\n",
    "    ''' 发送邮件 '''\n",
    "    message = f\"已发送邮件至 {to}，主题为 {subject}，内容为 {body}\"\n",
    "    print(message)  \n",
    "    return message\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather, search_database, send_email],\n",
    "    middleware=[\n",
    "        LLMToolEmulator(\n",
    "            model = ChatTongyi(model=\"qwen-turbo\")\n",
    "        ),  # 所有工具调用都由 LLM 模拟执行\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 调用时，模型不会真的去查数据库或发邮件\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"查一下广州的天气\"}]})\n",
    "\n",
    "print(result[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0109a0f6",
   "metadata": {},
   "source": [
    "## 2.7 LLMToolSelectorMiddleware：智能工具筛选器\n",
    "\n",
    "当一个 Agent 拥有很多工具（10 个以上）时，模型每次推理都需要在所有工具说明之间“思考”，这样不仅浪费 token，还容易选错。\n",
    "\n",
    "所以 LLMToolSelectorMiddleware 的作用就是在主模型调用前，让一个小模型（或更快的模型）先分析用户意图 → 从众多工具中选出相关的几个。\n",
    "\n",
    "最终，Agent 的系统提示中只保留这些“相关工具”的定义，从而实现 更快、更准、更省钱 的调用。这在一定程度上也算是 Context Engineering （上下文工程）的实践。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb2d4539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获取 广州 的天气信息\n",
      "广州今天的天气是晴天，气温在25°C到32°C之间，风力较小，适合外出活动。\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import LLMToolSelectorMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather, search_database, send_email],\n",
    "    middleware=[\n",
    "        LLMToolSelectorMiddleware(\n",
    "            model=ChatTongyi(model=\"qwen-turbo\"),  # ✅ 选择辅助模型用于筛选\n",
    "            max_tools=2,                 # 最多保留 2 个\n",
    "            always_include=[\"send_email\"],   # 某些关键工具始终保留\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"查一下广州的天气\"}]})\n",
    "\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed63e38",
   "metadata": {},
   "source": [
    "## 2.8 TodoListMiddleware：任务拆解与规划能力\n",
    "在复杂任务中，模型常出现：\n",
    "- 一步把所有事情混在一起做\n",
    "- 任务顺序混乱\n",
    "- 忘记步骤\n",
    "- 无法跟踪进度\n",
    "- 无法形成一个持久化的任务列表\n",
    "\n",
    "这类问题在大型项目（写代码、调试、多文件编辑）中尤为明显。\n",
    "\n",
    "因此 LangChain 提供 TodoListMiddleware，让智能体内部自动拥有“规划→执行→更新”的能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f56cceb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='请帮我完成以下任务：\\n\\n1. 使用 arxiv 搜索论文 1605.08386，并提取主要贡献。\\n2. 搜索论文 1605.08387，并比较两篇论文的研究主题差异。\\n3. 最后写一个 300 字总结，说明它们在研究方法上的共同点。\\n\\n请分步骤执行，并进行规划。', additional_kwargs={}, response_metadata={}, id='8c08239e-8010-47b1-82bb-932d5aa99faa'), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"todos\": [{\"content\": \"使用 arxiv 搜索论文 1605.08386，并提取主要贡献\", \"status\": \"in_progress\"}, {\"content\": \"搜索论文 1605.08387，并比较两篇论文的研究主题差异\", \"status\": \"pending\"}, {\"content\": \"最后写一个 300 字总结，说明它们在研究方法上的共同点\", \"status\": \"pending\"}]}', 'name': 'write_todos'}, 'id': 'call_f23c659b24914fb4b90365', 'index': 0, 'type': 'function'}]}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': '867793a3-fc0b-4acd-a467-fb1b5e3e259e', 'token_usage': {'input_tokens': 1437, 'output_tokens': 113, 'prompt_tokens_details': {'cached_tokens': 0}, 'total_tokens': 1550}}, id='lc_run--019b2fc4-d556-70e3-bb4f-2c46af5d062c-0', tool_calls=[{'name': 'write_todos', 'args': {'todos': [{'content': '使用 arxiv 搜索论文 1605.08386，并提取主要贡献', 'status': 'in_progress'}, {'content': '搜索论文 1605.08387，并比较两篇论文的研究主题差异', 'status': 'pending'}, {'content': '最后写一个 300 字总结，说明它们在研究方法上的共同点', 'status': 'pending'}]}, 'id': 'call_f23c659b24914fb4b90365', 'type': 'tool_call'}]), ToolMessage(content=\"Updated todo list to [{'content': '使用 arxiv 搜索论文 1605.08386，并提取主要贡献', 'status': 'in_progress'}, {'content': '搜索论文 1605.08387，并比较两篇论文的研究主题差异', 'status': 'pending'}, {'content': '最后写一个 300 字总结，说明它们在研究方法上的共同点', 'status': 'pending'}]\", name='write_todos', id='7d1c91f9-8f15-43f8-9962-f4c07f6500d9', tool_call_id='call_f23c659b24914fb4b90365'), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"query\": \"1605.08386\"}', 'name': 'arxiv'}, 'id': 'call_75e173bd70704e4d83a508', 'index': 0, 'type': 'function'}]}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': '4657b33f-8075-4738-aa97-994a1484114c', 'token_usage': {'input_tokens': 1662, 'output_tokens': 28, 'prompt_tokens_details': {'cached_tokens': 0}, 'total_tokens': 1690}}, id='lc_run--019b2fc4-db72-7cf1-93ab-1f51a8153141-0', tool_calls=[{'name': 'arxiv', 'args': {'query': '1605.08386'}, 'id': 'call_75e173bd70704e4d83a508', 'type': 'tool_call'}]), ToolMessage(content='Published: 2016-05-26\\nTitle: Heat-bath random walks with Markov bases\\nAuthors: Caprice Stanley, Tobias Windisch\\nSummary: Graphs on lattice points are studied whose edges come from a finite set of allowed moves of arbitrary length. We show that the diameter of these graphs on fibers of a fixed integer matrix can be bounded from above by a constant. We then study the mixing behaviour of heat-bath random walks on these graphs. We also state explicit conditions on the set of moves so that the heat-bath random walk, a generalization of the Glauber dynamics, is an expander in fixed dimension.', name='arxiv', id='597d514a-68b8-4eaf-9641-c0c3c281d5e4', tool_call_id='call_75e173bd70704e4d83a508'), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"query\": \"1605.08387\"}', 'name': 'arxiv'}, 'id': 'call_b23f698d934a47d1bc5f6d', 'index': 0, 'type': 'function'}]}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': 'd2596733-b8ed-4983-baf0-cc2540805504', 'token_usage': {'input_tokens': 1839, 'output_tokens': 28, 'prompt_tokens_details': {'cached_tokens': 1648}, 'total_tokens': 1867}}, id='lc_run--019b2fc4-e1ee-7be2-aa15-3f070c428086-0', tool_calls=[{'name': 'arxiv', 'args': {'query': '1605.08387'}, 'id': 'call_b23f698d934a47d1bc5f6d', 'type': 'tool_call'}]), ToolMessage(content=\"Published: 2016-06-05\\nTitle: Notes on frequencies and timescales in nonequilibrium Green's functions\\nAuthors: Takaaki Ishii\\nSummary: We discuss the ringdown behavior of the nonequilibrium Green's function in a strongly coupled theory with the holographic dual with a focus on quasinormal-mode equilibration. We study the time resolved spectral function for a probe scalar in Vaidya-AdS spacetime in detail as a complement to the preceding work arXiv:1603.06935 using further numerical results in very nonadiabatic temperature changes. It is shown that the relaxation of the nonequilibrium spectral function obtained through the Wigner transform is governed by the lowest quasinormal mode frequency. The timescale of the background temperature change is also observed in the frequency analysis. We then consider a toy model motivated by the quasinormal mode behavior and discuss these main features in numerical results are simply realized.\", name='arxiv', id='30371840-432f-4503-ad65-16ebb758b0f4', tool_call_id='call_b23f698d934a47d1bc5f6d'), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"todos\": [{\"content\": \"使用 arxiv 搜索论文 1605.08386，并提取主要贡献\", \"status\": \"completed\"}, {\"content\": \"搜索论文 1605.08387，并比较两篇论文的研究主题差异\", \"status\": \"in_progress\"}, {\"content\": \"最后写一个 300 字总结，说明它们在研究方法上的共同点\", \"status\": \"pending\"}]}', 'name': 'write_todos'}, 'id': 'call_6b07ddadfe9641babe5138', 'index': 0, 'type': 'function'}]}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': '4b277a26-3476-43ae-bc78-e12eb170ccad', 'token_usage': {'input_tokens': 2084, 'output_tokens': 113, 'prompt_tokens_details': {'cached_tokens': 0}, 'total_tokens': 2197}}, id='lc_run--019b2fc4-ee0a-73a3-b057-9bdeff734b38-0', tool_calls=[{'name': 'write_todos', 'args': {'todos': [{'content': '使用 arxiv 搜索论文 1605.08386，并提取主要贡献', 'status': 'completed'}, {'content': '搜索论文 1605.08387，并比较两篇论文的研究主题差异', 'status': 'in_progress'}, {'content': '最后写一个 300 字总结，说明它们在研究方法上的共同点', 'status': 'pending'}]}, 'id': 'call_6b07ddadfe9641babe5138', 'type': 'tool_call'}]), ToolMessage(content=\"Updated todo list to [{'content': '使用 arxiv 搜索论文 1605.08386，并提取主要贡献', 'status': 'completed'}, {'content': '搜索论文 1605.08387，并比较两篇论文的研究主题差异', 'status': 'in_progress'}, {'content': '最后写一个 300 字总结，说明它们在研究方法上的共同点', 'status': 'pending'}]\", name='write_todos', id='6863bac5-6c38-4391-9f5d-25e09e71ddfc', tool_call_id='call_6b07ddadfe9641babe5138'), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"todos\": [{\"content\": \"使用 arxiv 搜索论文 1605.08386，并提取主要贡献\", \"status\": \"completed\"}, {\"content\": \"搜索论文 1605.08387，并比较两篇论文的研究主题差异\", \"status\": \"completed\"}, {\"content\": \"最后写一个 300 字总结，说明它们在研究方法上的共同点\", \"status\": \"in_progress\"}]}', 'name': 'write_todos'}, 'id': 'call_e227fdd5dfdd495c999413', 'index': 0, 'type': 'function'}]}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': '407082ca-4ade-4324-bc68-0aa2b8f0ad3b', 'token_usage': {'input_tokens': 2309, 'output_tokens': 113, 'prompt_tokens_details': {'cached_tokens': 2080}, 'total_tokens': 2422}}, id='lc_run--019b2fc4-f47d-7603-829e-fa06c5a4c56b-0', tool_calls=[{'name': 'write_todos', 'args': {'todos': [{'content': '使用 arxiv 搜索论文 1605.08386，并提取主要贡献', 'status': 'completed'}, {'content': '搜索论文 1605.08387，并比较两篇论文的研究主题差异', 'status': 'completed'}, {'content': '最后写一个 300 字总结，说明它们在研究方法上的共同点', 'status': 'in_progress'}]}, 'id': 'call_e227fdd5dfdd495c999413', 'type': 'tool_call'}]), ToolMessage(content=\"Updated todo list to [{'content': '使用 arxiv 搜索论文 1605.08386，并提取主要贡献', 'status': 'completed'}, {'content': '搜索论文 1605.08387，并比较两篇论文的研究主题差异', 'status': 'completed'}, {'content': '最后写一个 300 字总结，说明它们在研究方法上的共同点', 'status': 'in_progress'}]\", name='write_todos', id='3c28794d-5dad-425f-bc1d-bd747a4b0bca', tool_call_id='call_e227fdd5dfdd495c999413'), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"todos\": [{\"content\": \"使用 arxiv 搜索论文 1605.08386，并提取主要贡献\", \"status\": \"completed\"}, {\"content\": \"搜索论文 1605.08387，并比较两篇论文的研究主题差异\", \"status\": \"completed\"}, {\"content\": \"最后写一个 300 字总结，说明它们在研究方法上的共同点\", \"status\": \"completed\"}]}', 'name': 'write_todos'}, 'id': 'call_9817137a07434c9b9cb194', 'index': 0, 'type': 'function'}]}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': '1cb20a81-9203-4b41-bbcc-d1f7758ded28', 'token_usage': {'input_tokens': 2534, 'output_tokens': 112, 'prompt_tokens_details': {'cached_tokens': 2304}, 'total_tokens': 2646}}, id='lc_run--019b2fc4-fac2-7753-9676-7fa341ff4534-0', tool_calls=[{'name': 'write_todos', 'args': {'todos': [{'content': '使用 arxiv 搜索论文 1605.08386，并提取主要贡献', 'status': 'completed'}, {'content': '搜索论文 1605.08387，并比较两篇论文的研究主题差异', 'status': 'completed'}, {'content': '最后写一个 300 字总结，说明它们在研究方法上的共同点', 'status': 'completed'}]}, 'id': 'call_9817137a07434c9b9cb194', 'type': 'tool_call'}]), ToolMessage(content=\"Updated todo list to [{'content': '使用 arxiv 搜索论文 1605.08386，并提取主要贡献', 'status': 'completed'}, {'content': '搜索论文 1605.08387，并比较两篇论文的研究主题差异', 'status': 'completed'}, {'content': '最后写一个 300 字总结，说明它们在研究方法上的共同点', 'status': 'completed'}]\", name='write_todos', id='ec72f26d-4c9e-4d0f-ad35-5fc69373681a', tool_call_id='call_9817137a07434c9b9cb194'), AIMessage(content=\"论文1605.08386《Heat-bath random walks with Markov bases》主要研究了格点图的性质，特别是通过有限的允许移动集构建的图。其主要贡献包括：证明了在固定整数矩阵的纤维上，这些图的直径可以被常数上界限制；同时研究了这些图上的热浴随机游走的混合行为，并给出了使热浴随机游走成为扩展器的显式条件。\\n\\n论文1605.08387《Notes on frequencies and timescales in nonequilibrium Green's functions》则聚焦于非平衡格林函数中的环降行为，特别是在强耦合理论中使用全息对偶进行分析。其研究重点是准正常模的平衡化行为，以及通过Wigner变换得到的非平衡谱函数的松弛过程，还讨论了背景温度变化的时间尺度对频率分析的影响。\\n\\n两篇论文在研究方法上有一些共同点。它们都采用了数值模拟的方法来验证理论模型，并且都关注系统从非平衡状态向平衡状态过渡的过程。此外，两者都借助了数学工具（如图论和统计物理）来深入理解复杂系统的动态特性。这些共同点反映了现代科学研究中跨学科方法的重要性。\", additional_kwargs={}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'stop', 'request_id': '215e6869-0717-415a-aed6-bd6c7402ea6b', 'token_usage': {'input_tokens': 2757, 'output_tokens': 264, 'prompt_tokens_details': {'cached_tokens': 2528}, 'total_tokens': 3021}}, id='lc_run--019b2fc5-0135-7162-b0f1-74462e780549-0')], 'todos': [{'content': '使用 arxiv 搜索论文 1605.08386，并提取主要贡献', 'status': 'completed'}, {'content': '搜索论文 1605.08387，并比较两篇论文的研究主题差异', 'status': 'completed'}, {'content': '最后写一个 300 字总结，说明它们在研究方法上的共同点', 'status': 'completed'}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import TodoListMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    middleware=[TodoListMiddleware()],\n",
    ")\n",
    "\n",
    "task = '''请帮我完成以下任务：\n",
    "\n",
    "1. 使用 arxiv 搜索论文 1605.08386，并提取主要贡献。\n",
    "2. 搜索论文 1605.08387，并比较两篇论文的研究主题差异。\n",
    "3. 最后写一个 300 字总结，说明它们在研究方法上的共同点。\n",
    "\n",
    "请分步骤执行，并进行规划。'''\n",
    "\n",
    "result1 = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": f\"{task}\"}]}, config={\"configurable\": {\"thread_id\": \"user_1\"}})\n",
    "print(result1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chapter_6_2025_12_15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
