{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be38a4ea",
   "metadata": {},
   "source": [
    "# 1. 环境配置\n",
    "\n",
    "## 1.1 python 环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68bc798e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: openai==2.11.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: dashscope==1.25.4 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (1.25.4)\n",
      "Requirement already satisfied: langchain-classic==1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain==1.1.3 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: langchain-community==0.4.1 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-openai==1.1.3 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: arxiv==2.3.1 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from openai==2.11.0) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from openai==2.11.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from openai==2.11.0) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from openai==2.11.0) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from openai==2.11.0) (2.12.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from openai==2.11.0) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from openai==2.11.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from openai==2.11.0) (4.15.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from dashscope==1.25.4) (3.13.2)\n",
      "Requirement already satisfied: requests in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from dashscope==1.25.4) (2.32.5)\n",
      "Requirement already satisfied: websocket-client in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from dashscope==1.25.4) (1.9.0)\n",
      "Requirement already satisfied: cryptography in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from dashscope==1.25.4) (46.0.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from dashscope==1.25.4) (2025.11.12)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langchain-classic==1.0.0) (1.2.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langchain-classic==1.0.0) (1.1.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.17 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langchain-classic==1.0.0) (0.4.59)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langchain-classic==1.0.0) (6.0.3)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langchain-classic==1.0.0) (2.0.45)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langchain==1.1.3) (1.0.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langchain-community==0.4.1) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langchain-community==0.4.1) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langchain-community==0.4.1) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langchain-community==0.4.1) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langchain-community==0.4.1) (2.3.5)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langchain-openai==1.1.3) (0.12.0)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from arxiv==2.3.1) (6.0.12)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from anyio<5,>=3.5.0->openai==2.11.0) (3.11)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1) (0.9.0)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from feedparser~=6.0.10->arxiv==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from httpx<1,>=0.23.0->openai==2.11.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==2.11.0) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic==1.0.0) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic==1.0.0) (25.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic==1.0.0) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-classic==1.0.0) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (0.3.0)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (1.12.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic==1.0.0) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic==1.0.0) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==2.11.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==2.11.0) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==2.11.0) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community==0.4.1) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from requests->dashscope==1.25.4) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from requests->dashscope==1.25.4) (2.3.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from sqlalchemy<3.0.0,>=1.4.0->langchain-classic==1.0.0) (3.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai==1.1.3) (2025.11.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from tqdm>4->openai==2.11.0) (0.4.6)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from cryptography->dashscope==1.25.4) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\76391\\.conda\\envs\\chapter1\\lib\\site-packages (from cffi>=2.0.0->cryptography->dashscope==1.25.4) (2.23)\n"
     ]
    }
   ],
   "source": [
    "! pip install openai==2.11.0 dashscope==1.25.4 langchain-classic==1.0.0 langchain==1.1.3 langchain-community==0.4.1 langchain-openai==1.1.3 arxiv==2.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c134430",
   "metadata": {},
   "source": [
    "## 1.2 大模型密钥准备\n",
    "\n",
    "请根据第一章内容获取相关平台的 API KEY，如若未在系统变量中填入，请将 API_KEY 信息写入以下代码（若已设置请忽略）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f510216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxx\"\n",
    "# os.environ[\"DASHSCOPE_API_KEY\"] = \"sk-yyyyyyyy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de64801e",
   "metadata": {},
   "source": [
    "## 1.3 实践代码\n",
    "\n",
    "为了能够顺利的演示内置中间件的使用详情，这里我们使用一段简单的智能体代码演示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c51e588a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "论文编号 1605.08386 的信息如下：\n",
      "\n",
      "- **发表日期**: 2016-05-26\n",
      "- **标题**: Heat-bath random walks with Markov bases\n",
      "- **作者**: Caprice Stanley, Tobias Windisch\n",
      "- **摘要**: 研究了格点上的图，其边来自于有限集的允许移动。我们证明了这些图在固定整数矩阵的纤维上的直径可以被常数上界限制。然后研究了这些图上的热浴随机游走的混合行为。还给出了移动集的显式条件，使得热浴随机游走（Glauber动力学的一种推广）在固定维度中是扩展器。\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "llm = ChatTongyi(api_key=os.environ.get(\"DASHSCOPE_API_KEY\"), model=\"qwen-turbo\")\n",
    "\n",
    "from langchain_community.agent_toolkits.load_tools import load_tools\n",
    "tools = load_tools([\"arxiv\"])\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver \n",
    "memory = InMemorySaver()\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "agent = create_agent(model=llm, \n",
    "                     tools=tools, \n",
    "                     system_prompt=\"You are a helpful assistant\", \n",
    "                     checkpointer=memory)\n",
    "\n",
    "result1 = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"请使用 arxiv 工具查询论文编号 1605.08386\"}]}, config={\"configurable\": {\"thread_id\": \"user_1\"}})\n",
    "print(result1[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab73bb9",
   "metadata": {},
   "source": [
    "# 2. 内置中间件\n",
    "\n",
    "## 2.1 简介\n",
    "\n",
    "针对于一些智能体开发常用的中间件，LangChain 官方团队给出了一系列的内置中间件来帮助大家进行快速上手。这些中间件包括：\n",
    "- ModelFallbackMiddleware：主模型失败时自动换模型\n",
    "- ModelCallLimitMiddleware：限制模型调用次数\n",
    "- ToolCallLimitMiddleware：限制工具调用频率\n",
    "- ToolRetryMiddleware：工具失败时自动重试\n",
    "- LLMToolEmulator：用LLM模拟工具执行\n",
    "- SummarizationMiddleware：摘要对话历史\n",
    "- ContextEditingMiddleware：清理旧上下文\n",
    "- PIIMiddleware：检测/脱敏个人隐私信息\n",
    "- HumanInTheLoopMiddleware：人工审批确认机制\n",
    "- ...\n",
    "\n",
    "## 2.2 ModelFallbackMiddleware：模型容灾与降级策略\n",
    "\n",
    "在实际部署智能体（Agent）时，经常会遇到这些情况：\n",
    "- 主模型（如 qwen-max）暂时不可用或返回错误；\n",
    "- 模型超时、API 限额、或延迟太高；\n",
    "- 想节省成本，用小模型在轻任务中“兜底”。\n",
    "\n",
    "所以 LangChain 官方提供了一个作用在 wrap_model_call 的内置中间件 ModelFallbackMiddleware ，在主模型失败时自动切换备用模型，保持任务不中断。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc21d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据您查询的论文编号 1605.08386，以下是相关信息：\n",
      "\n",
      "**发表时间**: 2016-05-26  \n",
      "**标题**: Heat-bath random walks with Markov bases (使用马尔可夫基的热浴随机游走)  \n",
      "**作者**: Caprice Stanley, Tobias Windisch  \n",
      "\n",
      "**摘要**: 研究了格点上具有来自有限组任意长度允许移动的边的图。我们证明了这些图在固定整数矩阵纤维上的直径可以从上方由一个常数限定。然后我们研究了这些图上热浴随机游走的混合行为。我们还给出了移动集合的明确条件，使得热浴随机游走（Glauber动力学的一种推广）在固定维度下是一个扩张器。\n",
      "\n",
      "这篇论文主要研究了基于马尔可夫基的热浴随机游走的数学性质，特别是其在特定图结构上的混合行为和扩张性。\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import ModelFallbackMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "  model=ChatTongyi(model=\"xxx\"), # 错误模型\n",
    "  tools=tools,\n",
    "  system_prompt=\"You are a helpful assistant\",\n",
    "  middleware=[ModelFallbackMiddleware(\n",
    "      ChatTongyi(model=\"qwen-plus\"),\n",
    "      ChatTongyi(model=\"qwen-turbo\",\n",
    "      checkpointer=memory))])\n",
    "\n",
    "result1 = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"请使用 arxiv 工具查询论文编号 1605.08386\"}]}, config={\"configurable\": {\"thread_id\": \"user_1\"}})\n",
    "\n",
    "print(result1[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cbf4b6",
   "metadata": {},
   "source": [
    "## 2.3 ModelCallLimitMiddleware：限制模型调用次数\n",
    "\n",
    "在一个智能体执行循环（Agent Loop）中，模型会多次被调用：\n",
    "- 一次决定“要不要用工具”；\n",
    "- 一次执行后判断“是否需要再次调用”；\n",
    "- 再次思考结果、继续调用或返回最终结果。\n",
    "\n",
    "在 ReAct-style agent 中，如果 LLM 的输出不够理性，可能会进入：输入→ 模型思考 → 工具调用 → 模型思考 → 工具调用 → 模型思考... 这种循环，轻则多花钱，重则“跑爆上下文”。\n",
    "\n",
    "因此，ModelCallLimitMiddleware 的作用就是限定模型调用次数，一旦达到上限，就让 Agent 自动停止或报错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2f70cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model call limits exceeded: thread limit (2/2)\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import ModelCallLimitMiddleware\n",
    "\n",
    "middleware_model_limit = ModelCallLimitMiddleware(thread_limit=2, run_limit=1)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    "    middleware=[middleware_model_limit],\n",
    "    checkpointer=InMemorySaver()\n",
    ")\n",
    "\n",
    "config3 = {\"configurable\": {\"thread_id\": \"user_3\"}}\n",
    "\n",
    "result1 = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"请使用 arxiv 工具查询论文编号 1605.08386，100字即可\"}]}, config=config3)\n",
    "result2 = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"你能总结一下吗？100字即可\"}]}, config=config3)\n",
    "result3 = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"推荐几篇拓展阅读吧\"}]}, config=config3)\n",
    "\n",
    "print(result3[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d860216",
   "metadata": {},
   "source": [
    "## 2.4 ToolCallLimitMiddleware：限制工具调用次数\n",
    "类似的，除了有模型调用的限制以外，还有一个就是限制工具调用的次数。在实际智能体（Agent）执行循环中，工具调用（Tool Calls）往往是最昂贵或最不确定的环节：\n",
    "- 有的工具访问外部 API（比如搜索、数据库查询）；\n",
    "- 有的工具运行时间长（比如爬虫、OCR、代码执行）；\n",
    "- 如果模型逻辑出错，可能疯狂调用工具，导致成本暴涨或资源占满。\n",
    "\n",
    "这也是为什么 LangChain 提供了 ToolCallLimitMiddleware ，通过在调用工具的前后设置调用次数上限，防止 Agent 过度调用工具或陷入无穷循环。\n",
    "- before_model：判断调用次数是否达到上限；\n",
    "- after_model：统计这次模型调用中生成了几个 tool_call 并计数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af1faf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool call limit exceeded. Do not call 'arxiv' again.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import ToolCallLimitMiddleware\n",
    "\n",
    "middleware=[\n",
    "    ToolCallLimitMiddleware(run_limit=10),  # 全局\n",
    "    ToolCallLimitMiddleware(tool_name=\"arxiv\", thread_limit=1),  # 局部\n",
    "]\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    "    middleware=middleware,\n",
    "    checkpointer=InMemorySaver()\n",
    ")\n",
    "\n",
    "config3 = {\"configurable\": {\"thread_id\": \"user_3\"}}\n",
    "\n",
    "result1 = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"请使用 arxiv 工具查询论文编号 1605.08386，100字即可\"}]}, config=config3)\n",
    "result2 = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"请使用 arxiv 工具查询论文编号 2103.08386，100字即可\"}]}, config=config3)\n",
    "\n",
    "\n",
    "print(result2[\"messages\"][-2].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b523cee7",
   "metadata": {},
   "source": [
    "## 2.5 ToolRetryMiddleware：工具调用自动重试机制\n",
    "\n",
    "在工具调用的过程中，我们常常还会遇到一些外部的问题，比如网络连接失败、数据库连接失败、模型执行有问题等等。那在工具调用（Tool call）失败时，如何让 Agent 不会立即崩溃或返回错误，这就成了急切需要解决的问题。\n",
    "\n",
    "所以这个时候，ToolRetryMiddleware 就给出了一个方案，不仅仅可以在调用工具的时候重复多次，还能够设置延时、指数回退（exponential backoff）、随机扰动（jitter）等机制。从而让智能体在调用不稳定外部服务（例如网络请求、搜索接口、数据库API）时更加鲁棒（robust）。\n",
    "\n",
    "其作用的位置是在 wrap_tool_call 中，也就是工具调用时。其目标就是如果工具出错，就重试几次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f7b51cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import ToolRetryMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "  model=llm,\n",
    "  tools=tools,\n",
    "  system_prompt=\"You are a helpful assistant\",\n",
    "  middleware=[\n",
    "    ToolRetryMiddleware(\n",
    "      max_retries=3,   # 最多重试 3 次\n",
    "      backoff_factor=2.0, # 指数退避倍数\n",
    "      initial_delay=1.0, # 首次延迟 1 秒\n",
    "      max_delay=60.0,   # 最大等待时间 60 秒\n",
    "      jitter=True,    # 添加随机扰动，防止雪崩重试\n",
    "    ),\n",
    "  ],\n",
    "  checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc854974",
   "metadata": {},
   "source": [
    "## 2.6 LLMToolEmulator：用模型“假装”执行工具\n",
    "有些时候，在还没有实现具体的工具逻辑的时候，但是这个工具又非常重要的时候，我们可以通过用 LLM 来模拟工具的执行结果（tool emulation）。这样就可以让整体流程先顺利进行，后面再补充相对应的逻辑。\n",
    "\n",
    "比如当 agent 决定调用某个工具时（如 search_database()），这个中间件会拦截掉真正的工具调用，然后由另一个 LLM 生成“模拟的工具返回结果”。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73696d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "论文编号 1605.08386 的标题是《The Nonlinear Diffusion Equation》，作者是 J. M. Burgers。该论文发表于 1960 年 1 月 1 日，属于“Mathematical Physics”领域。摘要中提到，该论文详细研究了非线性扩散方程，重点分析了其数学结构和物理意义，并在流体力学和热传递的背景下探讨了冲击波的形成以及在不同初始条件下的解的行为。\n",
      "\n",
      "你可以通过 [此链接](https://arxiv.org/pdf/1605.08386.pdf) 查看或下载这篇论文的 PDF 版本。\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import LLMToolEmulator\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    middleware=[\n",
    "        LLMToolEmulator(\n",
    "            model = ChatTongyi(model=\"qwen-turbo\"),\n",
    "            tools=[\"arxiv\"],\n",
    "        ), \n",
    "    ],\n",
    ")\n",
    "\n",
    "result1 = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"请使用 arxiv 工具查询论文编号 1605.08386\"}]}, config={\"configurable\": {\"thread_id\": \"user_1\"}})\n",
    "print(result1[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c7e473",
   "metadata": {},
   "source": [
    "当我们希望所有的工具都用 LLM 进行模拟，我们可以这样写入（tools 参数里传入 None）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405f7f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "广州的天气是多云，气温28摄氏度，湿度65%，风速10公里每小时。\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import LLMToolEmulator\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    ''' 获取指定位置的天气信息 '''\n",
    "    message = f\"获取 {location} 的天气信息\"\n",
    "    print(message)  \n",
    "    return message\n",
    "\n",
    "@tool\n",
    "def search_database(query: str) -> str:\n",
    "    ''' 从数据库中搜索相关信息 '''\n",
    "    message = f\"数据库中关于 {query} 的信息是：...\"\n",
    "    print(message)  \n",
    "    return message  \n",
    "    \n",
    "@tool\n",
    "def send_email(to: str, subject: str, body: str) -> str:\n",
    "    ''' 发送邮件 '''\n",
    "    message = f\"已发送邮件至 {to}，主题为 {subject}，内容为 {body}\"\n",
    "    print(message)  \n",
    "    return message\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather, search_database, send_email],\n",
    "    middleware=[\n",
    "        LLMToolEmulator(\n",
    "            model = ChatTongyi(model=\"qwen-turbo\")\n",
    "        ),  # 所有工具调用都由 LLM 模拟执行\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 调用时，模型不会真的去查数据库或发邮件\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"查一下广州的天气\"}]})\n",
    "\n",
    "print(result[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0109a0f6",
   "metadata": {},
   "source": [
    "## 2.7 LLMToolSelectorMiddleware：智能工具筛选器\n",
    "\n",
    "当一个 Agent 拥有很多工具（10 个以上）时，模型每次推理都需要在所有工具说明之间“思考”，这样不仅浪费 token，还容易选错。\n",
    "\n",
    "所以 LLMToolSelectorMiddleware 的作用就是在主模型调用前，让一个小模型（或更快的模型）先分析用户意图 → 从众多工具中选出相关的几个。\n",
    "\n",
    "最终，Agent 的系统提示中只保留这些“相关工具”的定义，从而实现 更快、更准、更省钱 的调用。这在一定程度上也算是 Context Engineering （上下文工程）的实践。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb2d4539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获取 广州 的天气信息\n",
      "广州今天的天气是晴天，气温在25°C到32°C之间，风力较小，适合外出活动。\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import LLMToolSelectorMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather, search_database, send_email],\n",
    "    middleware=[\n",
    "        LLMToolSelectorMiddleware(\n",
    "            model=ChatTongyi(model=\"qwen-turbo\"),  # ✅ 选择辅助模型用于筛选\n",
    "            max_tools=2,                 # 最多保留 2 个\n",
    "            always_include=[\"send_email\"],   # 某些关键工具始终保留\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"查一下广州的天气\"}]})\n",
    "\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed63e38",
   "metadata": {},
   "source": [
    "## 2.8 TodoListMiddleware：任务拆解与规划能力\n",
    "在复杂任务中，模型常出现：\n",
    "- 一步把所有事情混在一起做\n",
    "- 任务顺序混乱\n",
    "- 忘记步骤\n",
    "- 无法跟踪进度\n",
    "- 无法形成一个持久化的任务列表\n",
    "\n",
    "这类问题在大型项目（写代码、调试、多文件编辑）中尤为明显。\n",
    "\n",
    "因此 LangChain 提供 TodoListMiddleware，让智能体内部自动拥有“规划→执行→更新”的能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f56cceb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='请帮我完成以下任务：\\n\\n1. 使用 arxiv 搜索论文 1605.08386，并提取主要贡献。\\n2. 搜索论文 1605.08387，并比较两篇论文的研究主题差异。\\n3. 最后写一个 300 字总结，说明它们在研究方法上的共同点。\\n\\n请分步骤执行，并进行规划。', additional_kwargs={}, response_metadata={}, id='bcfba9ed-7878-48a3-99fc-787bf1e1dd95'), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"todos\": [{\"content\": \"使用 arxiv 搜索论文 1605.08386，并提取主要贡献。\", \"status\": \"in_progress\"}, {\"content\": \"搜索论文 1605.08387，并比较两篇论文的研究主题差异。\", \"status\": \"pending\"}, {\"content\": \"最后写一个 300 字总结，说明它们在研究方法上的共同点。\", \"status\": \"pending\"}]}', 'name': 'write_todos'}, 'id': 'call_94d704fa7743401b9c38a2', 'index': 0, 'type': 'function'}]}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': '1d8e3e7d-232c-4579-b5fd-9965696c0a40', 'token_usage': {'input_tokens': 1437, 'output_tokens': 116, 'prompt_tokens_details': {'cached_tokens': 0}, 'total_tokens': 1553}}, id='lc_run--019b220e-2a0c-7b60-9679-57d01a53f494-0', tool_calls=[{'name': 'write_todos', 'args': {'todos': [{'content': '使用 arxiv 搜索论文 1605.08386，并提取主要贡献。', 'status': 'in_progress'}, {'content': '搜索论文 1605.08387，并比较两篇论文的研究主题差异。', 'status': 'pending'}, {'content': '最后写一个 300 字总结，说明它们在研究方法上的共同点。', 'status': 'pending'}]}, 'id': 'call_94d704fa7743401b9c38a2', 'type': 'tool_call'}]), ToolMessage(content=\"Updated todo list to [{'content': '使用 arxiv 搜索论文 1605.08386，并提取主要贡献。', 'status': 'in_progress'}, {'content': '搜索论文 1605.08387，并比较两篇论文的研究主题差异。', 'status': 'pending'}, {'content': '最后写一个 300 字总结，说明它们在研究方法上的共同点。', 'status': 'pending'}]\", name='write_todos', id='d1741f17-a451-4043-b25b-679ca2889b80', tool_call_id='call_94d704fa7743401b9c38a2'), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"query\": \"1605.08386\"}', 'name': 'arxiv'}, 'id': 'call_03332bf379624b9e9febf5', 'index': 0, 'type': 'function'}]}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': '7afe615e-905b-4d9c-9a8a-63a770dff4c2', 'token_usage': {'input_tokens': 1668, 'output_tokens': 28, 'prompt_tokens_details': {'cached_tokens': 1424}, 'total_tokens': 1696}}, id='lc_run--019b220e-31e7-7543-8a51-7a50767418cf-0', tool_calls=[{'name': 'arxiv', 'args': {'query': '1605.08386'}, 'id': 'call_03332bf379624b9e9febf5', 'type': 'tool_call'}]), ToolMessage(content='Published: 2016-05-26\\nTitle: Heat-bath random walks with Markov bases\\nAuthors: Caprice Stanley, Tobias Windisch\\nSummary: Graphs on lattice points are studied whose edges come from a finite set of allowed moves of arbitrary length. We show that the diameter of these graphs on fibers of a fixed integer matrix can be bounded from above by a constant. We then study the mixing behaviour of heat-bath random walks on these graphs. We also state explicit conditions on the set of moves so that the heat-bath random walk, a generalization of the Glauber dynamics, is an expander in fixed dimension.', name='arxiv', id='54550364-0544-47b6-9147-0967d1246af5', tool_call_id='call_03332bf379624b9e9febf5'), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"todos\": [{\"content\": \"使用 arxiv 搜索论文 1605.08386，并提取主要贡献。\", \"status\": \"completed\"}, {\"content\": \"搜索论文 1605.08387，并比较两篇论文的研究主题差异。\", \"status\": \"in_progress\"}, {\"content\": \"最后写一个 300 字总结，说明它们在研究方法上的共同点。\", \"status\": \"pending\"}]}', 'name': 'write_todos'}, 'id': 'call_add8bb0a24ea4ad9bbc5fb', 'index': 0, 'type': 'function'}]}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': 'b40cdfe9-57f1-4b0a-becf-a2413d14c5f6', 'token_usage': {'input_tokens': 1845, 'output_tokens': 116, 'prompt_tokens_details': {'cached_tokens': 1664}, 'total_tokens': 1961}}, id='lc_run--019b220e-3e96-70e3-aec5-c308a7d91d75-0', tool_calls=[{'name': 'write_todos', 'args': {'todos': [{'content': '使用 arxiv 搜索论文 1605.08386，并提取主要贡献。', 'status': 'completed'}, {'content': '搜索论文 1605.08387，并比较两篇论文的研究主题差异。', 'status': 'in_progress'}, {'content': '最后写一个 300 字总结，说明它们在研究方法上的共同点。', 'status': 'pending'}]}, 'id': 'call_add8bb0a24ea4ad9bbc5fb', 'type': 'tool_call'}]), ToolMessage(content=\"Updated todo list to [{'content': '使用 arxiv 搜索论文 1605.08386，并提取主要贡献。', 'status': 'completed'}, {'content': '搜索论文 1605.08387，并比较两篇论文的研究主题差异。', 'status': 'in_progress'}, {'content': '最后写一个 300 字总结，说明它们在研究方法上的共同点。', 'status': 'pending'}]\", name='write_todos', id='9601b712-ee84-494f-ba6c-12a0ab441898', tool_call_id='call_add8bb0a24ea4ad9bbc5fb'), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"query\": \"1605.08387\"}', 'name': 'arxiv'}, 'id': 'call_011f4539badc48a694ad5a', 'index': 0, 'type': 'function'}]}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': '1b462dc9-8f88-4eb8-93fa-5bb54a8a57c8', 'token_usage': {'input_tokens': 2076, 'output_tokens': 28, 'prompt_tokens_details': {'cached_tokens': 0}, 'total_tokens': 2104}}, id='lc_run--019b220e-456b-7ce3-a619-e81882322443-0', tool_calls=[{'name': 'arxiv', 'args': {'query': '1605.08387'}, 'id': 'call_011f4539badc48a694ad5a', 'type': 'tool_call'}]), ToolMessage(content=\"Published: 2016-06-05\\nTitle: Notes on frequencies and timescales in nonequilibrium Green's functions\\nAuthors: Takaaki Ishii\\nSummary: We discuss the ringdown behavior of the nonequilibrium Green's function in a strongly coupled theory with the holographic dual with a focus on quasinormal-mode equilibration. We study the time resolved spectral function for a probe scalar in Vaidya-AdS spacetime in detail as a complement to the preceding work arXiv:1603.06935 using further numerical results in very nonadiabatic temperature changes. It is shown that the relaxation of the nonequilibrium spectral function obtained through the Wigner transform is governed by the lowest quasinormal mode frequency. The timescale of the background temperature change is also observed in the frequency analysis. We then consider a toy model motivated by the quasinormal mode behavior and discuss these main features in numerical results are simply realized.\", name='arxiv', id='8c63413d-850d-4616-91d9-eeeac1aac0af', tool_call_id='call_011f4539badc48a694ad5a'), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"todos\": [{\"content\": \"使用 arxiv 搜索论文 1605.08386，并提取主要贡献。\", \"status\": \"completed\"}, {\"content\": \"搜索论文 1605.08387，并比较两篇论文的研究主题差异。\", \"status\": \"completed\"}, {\"content\": \"最后写一个 300 字总结，说明它们在研究方法上的共同点。\", \"status\": \"in_progress\"}]}', 'name': 'write_todos'}, 'id': 'call_c19f239263524275baee1c', 'index': 0, 'type': 'function'}]}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': '59f42ee3-eabb-44ad-a3c1-654cab35a7a1', 'token_usage': {'input_tokens': 2321, 'output_tokens': 116, 'prompt_tokens_details': {'cached_tokens': 0}, 'total_tokens': 2437}}, id='lc_run--019b220e-510f-73e3-930f-24a6663052c1-0', tool_calls=[{'name': 'write_todos', 'args': {'todos': [{'content': '使用 arxiv 搜索论文 1605.08386，并提取主要贡献。', 'status': 'completed'}, {'content': '搜索论文 1605.08387，并比较两篇论文的研究主题差异。', 'status': 'completed'}, {'content': '最后写一个 300 字总结，说明它们在研究方法上的共同点。', 'status': 'in_progress'}]}, 'id': 'call_c19f239263524275baee1c', 'type': 'tool_call'}]), ToolMessage(content=\"Updated todo list to [{'content': '使用 arxiv 搜索论文 1605.08386，并提取主要贡献。', 'status': 'completed'}, {'content': '搜索论文 1605.08387，并比较两篇论文的研究主题差异。', 'status': 'completed'}, {'content': '最后写一个 300 字总结，说明它们在研究方法上的共同点。', 'status': 'in_progress'}]\", name='write_todos', id='b7813c72-cabf-44dc-a1e7-bcd90ae5a9d0', tool_call_id='call_c19f239263524275baee1c'), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"todos\": [{\"content\": \"使用 arxiv 搜索论文 1605.08386，并提取主要贡献。\", \"status\": \"completed\"}, {\"content\": \"搜索论文 1605.08387，并比较两篇论文的研究主题差异。\", \"status\": \"completed\"}, {\"content\": \"最后写一个 300 字总结，说明它们在研究方法上的共同点。\", \"status\": \"completed\"}]}', 'name': 'write_todos'}, 'id': 'call_f14640b88b7c4691a33556', 'index': 0, 'type': 'function'}]}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': 'd865e822-249e-4246-84da-953fd4304e8b', 'token_usage': {'input_tokens': 2552, 'output_tokens': 115, 'prompt_tokens_details': {'cached_tokens': 2304}, 'total_tokens': 2667}}, id='lc_run--019b220e-56e3-7961-9d4b-c3cb09f7fbd5-0', tool_calls=[{'name': 'write_todos', 'args': {'todos': [{'content': '使用 arxiv 搜索论文 1605.08386，并提取主要贡献。', 'status': 'completed'}, {'content': '搜索论文 1605.08387，并比较两篇论文的研究主题差异。', 'status': 'completed'}, {'content': '最后写一个 300 字总结，说明它们在研究方法上的共同点。', 'status': 'completed'}]}, 'id': 'call_f14640b88b7c4691a33556', 'type': 'tool_call'}]), ToolMessage(content=\"Updated todo list to [{'content': '使用 arxiv 搜索论文 1605.08386，并提取主要贡献。', 'status': 'completed'}, {'content': '搜索论文 1605.08387，并比较两篇论文的研究主题差异。', 'status': 'completed'}, {'content': '最后写一个 300 字总结，说明它们在研究方法上的共同点。', 'status': 'completed'}]\", name='write_todos', id='8416f630-3530-4121-bb95-384834d36ffa', tool_call_id='call_f14640b88b7c4691a33556'), AIMessage(content='论文 1605.08386 和 1605.08387 在研究方法上有一些共同点。首先，两者都采用了数值模拟的方法来分析复杂系统的行为。论文 1605.08386 使用了热浴随机游走（heat-bath random walks）来研究格点图的混合行为，而论文 1605.08387 则通过数值结果详细分析了非平衡格林函数的环形衰减行为。\\n\\n其次，两篇论文都关注了系统在不同时间尺度上的演化特性。论文 1605.08386 研究了热浴随机游走在固定维度下的扩展性，而论文 1605.08387 则探讨了非平衡格林函数在强耦合理论中的时间分辨谱函数。\\n\\n最后，两篇论文都利用了数学和物理的工具来描述和分析复杂现象。论文 1605.08386 使用了马尔可夫基（Markov bases）来构建格点图，而论文 1605.08387 则通过准正则模式（quasinormal modes）来解释系统的松弛行为。\\n\\n总的来说，这两篇论文在研究方法上都体现了对复杂系统行为的深入分析，并且都依赖于数值模拟和数学工具来实现其目标。', additional_kwargs={}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'stop', 'request_id': 'a914fa85-8ec9-4248-8440-de0e7c01899c', 'token_usage': {'input_tokens': 2781, 'output_tokens': 305, 'prompt_tokens_details': {'cached_tokens': 2064}, 'total_tokens': 3086}}, id='lc_run--019b220e-5d27-7d13-984d-4f2c343e3fd8-0')], 'todos': [{'content': '使用 arxiv 搜索论文 1605.08386，并提取主要贡献。', 'status': 'completed'}, {'content': '搜索论文 1605.08387，并比较两篇论文的研究主题差异。', 'status': 'completed'}, {'content': '最后写一个 300 字总结，说明它们在研究方法上的共同点。', 'status': 'completed'}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import TodoListMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    middleware=[TodoListMiddleware()],\n",
    ")\n",
    "\n",
    "task = '''请帮我完成以下任务：\n",
    "\n",
    "1. 使用 arxiv 搜索论文 1605.08386，并提取主要贡献。\n",
    "2. 搜索论文 1605.08387，并比较两篇论文的研究主题差异。\n",
    "3. 最后写一个 300 字总结，说明它们在研究方法上的共同点。\n",
    "\n",
    "请分步骤执行，并进行规划。'''\n",
    "\n",
    "result1 = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": f\"{task}\"}]}, config={\"configurable\": {\"thread_id\": \"user_1\"}})\n",
    "print(result1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chapter1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
