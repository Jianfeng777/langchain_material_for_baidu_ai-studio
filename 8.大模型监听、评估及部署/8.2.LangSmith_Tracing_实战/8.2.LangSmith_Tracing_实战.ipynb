{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e5c07f0",
   "metadata": {},
   "source": [
    "# 1. 环境配置\n",
    "\n",
    "## 1.1 python 环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cb38e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: langchain in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: dashscope in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (1.25.2)\n",
      "Requirement already satisfied: langchain_classic in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: wikipedia in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: numexpr in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (2.14.1)\n",
      "Requirement already satisfied: DateTime in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (6.0)\n",
      "Requirement already satisfied: arxiv in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.2 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain) (1.2.0)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain) (1.0.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain) (2.12.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (0.4.56)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.2->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.14)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain-openai) (2.9.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain-community) (2.0.44)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain-community) (3.13.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain-community) (2.3.5)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from langchain_classic) (1.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (2.3.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: websocket-client in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from dashscope) (1.9.0)\n",
      "Requirement already satisfied: cryptography in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from dashscope) (46.0.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from wikipedia) (4.14.3)\n",
      "Requirement already satisfied: zope.interface in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from DateTime) (8.1.1)\n",
      "Requirement already satisfied: pytz in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from DateTime) (2025.2)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from arxiv) (6.0.12)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.8)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from cryptography->dashscope) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\76391\\.conda\\envs\\agent\\lib\\site-packages (from cffi>=2.0.0->cryptography->dashscope) (2.23)\n"
     ]
    }
   ],
   "source": [
    "! pip install gradio==6.1.0 openai==2.11.0 dashscope==1.25.4 langchain-classic==1.0.0 langchain==1.1.3 langchain-community==0.4.1 langchain-openai==1.1.3 beautifulsoup4==4.14.3 langchain_chroma==1.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449a5130",
   "metadata": {},
   "source": [
    "## 1.2 大模型密钥准备\n",
    "\n",
    "请根据第一章内容获取相关平台的 API KEY，如若未在系统变量中填入，请将 API_KEY 信息写入以下代码（若已设置请忽略）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6326071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxx\"\n",
    "# os.environ[\"DASHSCOPE_API_KEY\"] = \"sk-yyyyyyyy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e477f80",
   "metadata": {},
   "source": [
    "## 1.3 LangSmith 环境配置\n",
    "我们需要先前往 LangSmith 的官网并进行注册登录。\n",
    "\n",
    "登录后我们就进入了下面这个初始界面，此时我们需要找到左下角的 Setting ，然后在里面先获取新建一个 API Key。\n",
    "\n",
    "创建完成后，我们就可以将其配置到环境变量中。除了 API_Key 以外，通常 LangSmith 的项目还需要设置是否跟踪、上传地址以及项目名称信息（这个需要自定义设置）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e72577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"your langsmith api key\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"ai-studio-tracing\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ece1dc",
   "metadata": {},
   "source": [
    "# 2. LangSmith Tracing\n",
    "\n",
    "## 2.1 wrap_openai() \n",
    "\n",
    "### 2.1.1 单次调用\n",
    "\n",
    "假如我们的目的只是单独跟踪应用中使用的大模型的调用情况的话，可以使用 LangSmith 提供 wrap_openai() 来自动包装 OpenAI SDK，让所有 API 调用自动记录。\n",
    "\n",
    "目前绝大部分的模型都支持 OpenAI 格式进行调用，包括我们前面讲到的通义千问以及 AI Studio 中的所有模型：\n",
    "\n",
    "我们只需要导入 openai 库后创建客户端 OpenAI()，并传入 api_key 以及 base_url 两个变量即可创建客户端等待后续的调用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebdcb87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "raw_client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6c9e20",
   "metadata": {},
   "source": [
    "为了能够顺利的上传到 LangSmith 上，我们需要使用 LangSmith 里的 wrappers 来进行一层包裹，从而能够让这个模型调用的信息能够实时同步到 LangSmith 中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66fd0ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.wrappers import wrap_openai\n",
    "traced_client = wrap_openai(raw_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8bd482",
   "metadata": {},
   "source": [
    "在包裹完后，我们就可以使用包裹后的客户端进行调用了并打印结果了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb826940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是能陪你畅快聊天、为你答疑解惑、还能辅助创作各类文本的智能小助手。\n"
     ]
    }
   ],
   "source": [
    "response = traced_client.chat.completions.create(\n",
    "    model=\"ernie-3.5-8k\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"用一句话介绍一下你自己。\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ce72ee",
   "metadata": {},
   "source": [
    "### 2.1.2 添加元数据或标签\n",
    "\n",
    "假如我们希望往里再额外添加一些元数据或标签的话，可以在 wrap_openai 中添加内容："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f9b0e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个能陪你畅快聊天、为你答疑解惑、辅助创作各类文本的智能助手。\n"
     ]
    }
   ],
   "source": [
    "from langsmith.wrappers import wrap_openai\n",
    "traced_client = wrap_openai(raw_client, tracing_extra={\"metadata\": {\"my-key\": \"my-value\"}, \"tags\": [\"a-tag\"]})\n",
    "\n",
    "response = traced_client.chat.completions.create(\n",
    "    model=\"ernie-3.5-8k\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"用一句话介绍一下你自己。\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051ddecd",
   "metadata": {},
   "source": [
    "又或者是在 chat_completion 中添加相关内容："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68e65d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是能陪你畅快聊天、为你答疑解惑、帮你处理各类事务的智能小助手。\n"
     ]
    }
   ],
   "source": [
    "from langsmith.wrappers import wrap_openai\n",
    "traced_client = wrap_openai(raw_client)\n",
    "\n",
    "response = traced_client.chat.completions.create(\n",
    " model=\"ernie-3.5-8k\",\n",
    " messages=[\n",
    " {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    " {\"role\": \"user\", \"content\": \"用一句话介绍一下你自己。\"}], \n",
    " langsmith_extra={ \"tags\": [\"my-other-tag\"], \"metadata\": {\"my-other-key\": \"my-value\"}, },\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d0a29e",
   "metadata": {},
   "source": [
    "### 2.1.3 多次调用并对比\n",
    "在 LangSmith 里除了监控单次的调用以外，其还有一个很重要的能力就是对比多次调用并找到最优解。对于 AI Studio 里调用的模型而言，本质上就是修改调用时候的 model 参数（具体的模型信息可到 AI Studio-帮助文档 中查询）。\n",
    "\n",
    "比如这里修改为 DeepSeek-Chat 这个模型（输入参数应该是 deepseek-v3） ："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f299a960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"我是你的智能AI助手，随时为你解答问题、提供建议或陪你聊天！\"\n"
     ]
    }
   ],
   "source": [
    "from langsmith.wrappers import wrap_openai\n",
    "traced_client = wrap_openai(raw_client)\n",
    "\n",
    "response = traced_client.chat.completions.create(\n",
    "    model=\"deepseek-v3\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"用一句话介绍一下你自己。\"}])\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447555c3",
   "metadata": {},
   "source": [
    "## 2.2 @traceable\n",
    "\n",
    "除了通过 Wrap_openai 监控大模型调用外，我们还可以将大模型调用转换成函数并使用LangSmith 中的 @traceable 装饰器实现动态的跟踪（也要配置 LangSmith 环境）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f39cbfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from langsmith import traceable \n",
    "\n",
    "@traceable()\n",
    "def baidu(query):\n",
    "    # 创建 OpenAI Client\n",
    "    raw_client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "        base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "    # 调用大模型\n",
    "    response = raw_client.chat.completions.create(\n",
    "        model=\"ernie-3.5-8k\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": query}])\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17500cd7",
   "metadata": {},
   "source": [
    "假如此时对该函数进行调用并获取回复："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e628ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是能帮你答疑解惑、陪你谈天说地，还能提供各类实用信息与建议的智能助手。\n"
     ]
    }
   ],
   "source": [
    "print(baidu(\"用一句话介绍一下你自己。\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a77166",
   "metadata": {},
   "source": [
    "在这个装饰器里，我们可以添加几个常用的参数，比如说：\n",
    "- name：设置到时候在 LangSmith 上显示的名称\n",
    "- metadata：添加部分元数据，比如直接在 @traceable 里添加参数 metadata={\"vectordb\": \"sklearn\"}，或者可以在调用函数时添加 baidu(question, langsmith_extra={\"metadata\": {\"runtime_metadata\": \"foo\"}})\n",
    "- run_type：运行时展示的类型，这个具体影响在 LangSmith 上显示的信息（没有设置 run_type 时默认使用 Chain 类型）\n",
    "\n",
    "比如对于我们模型调用这个函数，我们就可以为其添加上这两个参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc561e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"baidu_ernie\", run_type=\"llm\")\n",
    "def baidu(query):\n",
    "    # 创建 OpenAI Client\n",
    "    raw_client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "        base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "    # 调用大模型\n",
    "    response = raw_client.chat.completions.create(\n",
    "        model=\"ernie-3.5-8k\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": query}])\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1346cee",
   "metadata": {},
   "source": [
    "假如此时对该函数再次进行调用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ac8c0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是能陪你畅快聊天、答疑解惑、辅助创作，提供各类知识服务的智能助手。\n"
     ]
    }
   ],
   "source": [
    "print(baidu(\"用一句话介绍一下你自己。\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dec7622",
   "metadata": {},
   "source": [
    "除了大模型调用可以跟踪以外，其实所有我们想要跟踪的函数都可以进行跟踪。比如说一段简单的打招呼函数和乘法函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59660362",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"multiply_numbers\")\n",
    "def multiply(a, b):\n",
    "    return a * b\n",
    "\n",
    "@traceable(name=\"greet_user\")\n",
    "def greet(name):\n",
    "    return f\"你好，{name}！欢迎使用 LangSmith 追踪功能。\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a361d7b",
   "metadata": {},
   "source": [
    "那假如我们希望将其组合起来获取输出结果的话，我们也可以设计一个组合的函数，并对其进行追踪："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56d260ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"workflow_example\")\n",
    "def workflow(name):\n",
    "    # 追踪普通函数\n",
    "    msg = greet(name)\n",
    "    result = multiply(len(name), 3)\n",
    "\n",
    "    # 追踪 LLM 调用\n",
    "    messages=f\"{msg} 请评价一下数字 {result}。\"\n",
    "    llm_answer = baidu(messages)\n",
    "\n",
    "    return {\n",
    "        \"greet\": msg,\n",
    "        \"multiply_result\": result,\n",
    "        \"llm_answer\": llm_answer\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d06df4",
   "metadata": {},
   "source": [
    "假如此时对该函数再次进行调用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f6d9858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'greet': '你好，李老师！欢迎使用 LangSmith 追踪功能。', 'multiply_result': 9, 'llm_answer': '李老师呀，数字9可是个很有意思的数字呢！从好多方面看，它都有独特之处。\\n\\n在数学里，9是3的平方，也是个完全平方数。而且呀，它还有很多奇妙的数学性质，比如一个数和9相乘，得到的数的各位数字之和还是9的倍数，像3×9 = 27，2 + 7 = 9；还有把一个数各个数位上的数字相加，如果和是9的倍数，那这个数也能被9整除。\\n\\n在文化方面，不同地方对9有不同的寓意。在中国文化里，9常常和“久”联系在一起，代表着长久、永恒，像长长久久就是很美好的祝福。在古代，9还是极数，有至高无上的意思，比如皇帝被称为“九五之尊”。\\n\\n总体来说，数字9不管是数学特性还是文化寓意，都特别丰富，是个很有魅力的数字呢！'}\n"
     ]
    }
   ],
   "source": [
    "print(workflow(\"李老师\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1ce118",
   "metadata": {},
   "source": [
    "## 2.3 自动跟踪\n",
    "\n",
    "对于非 LangChain 原生的代码而言，我们需要使用添加 @traceable 来实现 LangSmith 的跟踪。但是对于 LangChain 的原生代码而言，其实我们只需要配置好 LangSmith 的环境变量即可自动实现跟踪。\n",
    "\n",
    "### 2.3.1 LCEL 链\n",
    "\n",
    "比如下面这段使用 LCEL 进行链式调用的代码，我们可以先定义一个大模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbc04418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "llm = ChatOpenAI(model=\"ernie-3.5-8k\",\n",
    "openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e2f9e",
   "metadata": {},
   "source": [
    "然后定义一个提示词模版："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "111fa66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "解析以下产品评价中的信息，按格式要求输出：\n",
    "{format_instructions}\n",
    "评价：{input}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a96f60a",
   "metadata": {},
   "source": [
    "在然后定义一个格式化输出的 parser："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "677c0915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ProductInfo(BaseModel):\n",
    " product: str = Field(description=\"产品名称\")\n",
    " price: float = Field(description=\"产品价格\")\n",
    " rating: float = Field(description=\"评分（1-5的数字）\")\n",
    "parser = JsonOutputParser(pydantic_object=ProductInfo)\n",
    "format_instructions = parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e21af5",
   "metadata": {},
   "source": [
    "最后用 LCEL 的链将其串起来并进行调用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d47ca1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "结构化结果： {'product': '无线耳机', 'price': 399, 'rating': 4.5}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "response = chain.invoke({\"input\": \"这款无线耳机很好用，价格399元，我给4.5星好评\",\n",
    "  \"format_instructions\": format_instructions})\n",
    "print(\"结构化结果：\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e35115",
   "metadata": {},
   "source": [
    "### 2.3.2 RAG 系统\n",
    "\n",
    "对于 RAG 和 Agent 的系统也是一样的，只要我们在之前的代码上面加上 LangSmith 的环境配置，即可详细的查看到内部的情况。\n",
    "\n",
    "比如对于 RAG 系统而言，需要先创建数据库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd75fd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# RAG_db_create.py\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://zh.d2l.ai/chapter_introduction/index.html\")\n",
    "docs = loader.load()\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "  chunk_size = 1500,\n",
    "  chunk_overlap = 150)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "import os\n",
    "embeddings = DashScopeEmbeddings(\n",
    "  dashscope_api_key=os.getenv('DASHSCOPE_API_KEY'), \n",
    "  model=\"text-embedding-v1\")\n",
    "vectordb = Chroma.from_documents(documents=splits,\n",
    "  embedding=embeddings,\n",
    "  persist_directory='./chroma')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45666fb5",
   "metadata": {},
   "source": [
    "然后再对数据库进行调用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e39f75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "语音识别系统（如Siri）和地图路线筛选应用了机器学习。这些场景通过数据积累经验并提升性能。谢谢提问！\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "import os\n",
    "\n",
    "embeddings = DashScopeEmbeddings(\n",
    "  dashscope_api_key=os.getenv('DASHSCOPE_API_KEY'), \n",
    "  model=\"text-embedding-v1\")\n",
    "vectordb = Chroma(persist_directory=\"./chroma\", embedding_function=embeddings)\n",
    "template = \"\"\"请使用以下上下文信息回答最后的问题。如果您不知道答案，就直接说您不知道，不要试图编造答案。回答最多使用三句话。请尽可能简洁地回答。最后一定要说“谢谢提问！”。\n",
    "上下文：{context}\n",
    "问题：{question}\n",
    "有帮助的回答：\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "llm = ChatOpenAI(model=\"ernie-4.0-turbo-128k\",\n",
    " openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    " base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "retriever = vectordb.as_retriever(search_type=\"mmr\", \n",
    " search_kwargs={\"k\": 1, \"fetch_k\": 10, \"lambda_mult\": 0.25})\n",
    "def format_docs(docs):\n",
    " return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "qa_chain = (\n",
    " {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    " | QA_CHAIN_PROMPT\n",
    " | llm\n",
    " | StrOutputParser())\n",
    "print(qa_chain.invoke(\"日常生活里，哪里用到了机器学习呢？\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8e850e",
   "metadata": {},
   "source": [
    "### 2.3.5 Agent 系统\n",
    "\n",
    "又比如对于 Agent 系统而言，我们可以先创建好智能体再调用（此时我们可以在调用时传入 thread_id）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed2a8f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "论文编号 1605.08386 的标题是 \"Heat-bath random walks with Markov bases\"，作者是 Caprice Stanley 和 Tobias Windisch。该论文发布于 2016 年 5 月 26 日。\n",
      "\n",
      "这篇论文研究了格点上的图，其边来自于有限的允许移动集。我们证明了在固定整数矩阵的纤维上，这些图的直径可以从上方由一个常数来限制。然后我们研究了这些图上的热浴随机游走的混合行为。我们还给出了移动集的显式条件，使得热浴随机游走（Glauber 动态的一种推广）在固定维度中是一个扩展器。\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "llm = ChatTongyi(api_key=os.environ.get(\"DASHSCOPE_API_KEY\"), model=\"qwen-turbo\")\n",
    "\n",
    "from langchain_community.agent_toolkits.load_tools import load_tools\n",
    "tools = load_tools([\"arxiv\"])\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver \n",
    "memory = InMemorySaver()\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "agent = create_agent(model=llm, \n",
    "                     tools=tools, \n",
    "                     system_prompt=\"You are a helpful assistant\", \n",
    "                     checkpointer=memory)\n",
    "\n",
    "result1 = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"请使用 arxiv 工具查询论文编号 1605.08386\"}]}, config={\"configurable\": {\"thread_id\": \"user_1\"}})\n",
    "print(result1[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaecc2f",
   "metadata": {},
   "source": [
    "## 2.4 Thread 线程\n",
    "\n",
    "除了在模型调用时候添加 thread_id 外，对于添加 @traceable 装饰器实现模型跟踪的方式也可以添加 thread_id ，这个就是在调用函数的时候添加上一些元数据即可，比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8b5aea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'greet': '你好，李老师！欢迎使用 LangSmith 追踪功能。', 'multiply_result': 9, 'llm_answer': '数字9呀，它可是个很有意思的数字呢！在数学里，9是最大的个位数，还是3的倍数，有很多特别的性质。在中国文化里，9还常常和长久、圆满联系在一起，象征着好运和幸福。你觉得9怎么样呢？是不是也觉得它很特别呀？'}\n"
     ]
    }
   ],
   "source": [
    "print(workflow(\"李老师\",langsmith_extra={\"metadata\": {\"thread_id\": \"user_1\"}}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4169ca27",
   "metadata": {},
   "source": [
    "我们可以点击右上角的 Thread 按钮或在 Tracing 界面的上方就可以看到同一 thread_id 的对话信息。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chapter1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
