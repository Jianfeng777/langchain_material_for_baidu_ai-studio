{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f499a55b",
   "metadata": {},
   "source": [
    "# 1. 环境配置\n",
    "\n",
    "## 1.1 python 环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32ecfc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: openai==2.11.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: dashscope==1.25.4 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (1.25.4)\n",
      "Requirement already satisfied: langchain-classic==1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain==1.1.3 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: langchain-community==0.4.1 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-openai==1.1.3 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from openai==2.11.0) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from openai==2.11.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from openai==2.11.0) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from openai==2.11.0) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from openai==2.11.0) (2.12.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from openai==2.11.0) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from openai==2.11.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from openai==2.11.0) (4.15.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (3.13.2)\n",
      "Requirement already satisfied: requests in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (2.32.5)\n",
      "Requirement already satisfied: websocket-client in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (1.9.0)\n",
      "Requirement already satisfied: cryptography in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (46.0.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (2025.11.12)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (1.2.2)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (1.1.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.17 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (0.5.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (6.0.3)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (2.0.45)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langchain==1.1.3) (1.0.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (2.3.5)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langchain-openai==1.1.3) (0.12.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from anyio<5,>=3.5.0->openai==2.11.0) (3.11)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1) (0.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from httpx<1,>=0.23.0->openai==2.11.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==2.11.0) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic==1.0.0) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic==1.0.0) (25.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic==1.0.0) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-classic==1.0.0) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (0.3.0)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (1.12.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic==1.0.0) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic==1.0.0) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==2.11.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==2.11.0) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==2.11.0) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community==0.4.1) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from requests->dashscope==1.25.4) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from requests->dashscope==1.25.4) (2.3.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from sqlalchemy<3.0.0,>=1.4.0->langchain-classic==1.0.0) (3.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai==1.1.3) (2025.11.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from tqdm>4->openai==2.11.0) (0.4.6)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from cryptography->dashscope==1.25.4) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\76391\\.conda\\envs\\chapter_7_2025_12_15\\lib\\site-packages (from cffi>=2.0.0->cryptography->dashscope==1.25.4) (2.23)\n"
     ]
    }
   ],
   "source": [
    "! pip install openai==2.11.0 dashscope==1.25.4 langchain-classic==1.0.0 langchain==1.1.3 langchain-community==0.4.1 langchain-openai==1.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35226695",
   "metadata": {},
   "source": [
    "## 1.2 大模型密钥准备\n",
    "\n",
    "请根据第一章内容获取相关平台的 API KEY，如若未在系统变量中填入，请将 API_KEY 信息写入以下代码（若已设置请忽略）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d92e6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxx\"\n",
    "# os.environ[\"DASHSCOPE_API_KEY\"] = \"sk-yyyyyyyy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9367ec12",
   "metadata": {},
   "source": [
    "# 2. SQL Agent 应用开发\n",
    "\n",
    "## 2.1 简介\n",
    "\n",
    "和向量数据库一样，假如我们想把关系数据库转变为智能体的工具，第一步就是要获取到一个存储着和任务相关内容的关系数据库。\n",
    "\n",
    "这里我们可以从 google 那下载一个经典的关系数据库 Chinook.db 进行演示。\n",
    "\n",
    "这是一个模拟数字音乐商店（Digital Media Store）的数据库。它包含了音乐专辑、艺术家、客户、发票、员工等数据。也推荐大家使用自己的数据库进行尝试。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3657ceb6",
   "metadata": {},
   "source": [
    "## 2.2 应用开发\n",
    "\n",
    "我们可以先使用 requests 库下载这个库并存放到本地的文件夹中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81249b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as Chinook.db\n"
     ]
    }
   ],
   "source": [
    "import requests, pathlib\n",
    "\n",
    "url = \"https://storage.googleapis.com/benchmarks-artifacts/chinook/Chinook.db\"\n",
    "local_path = pathlib.Path(\"Chinook.db\")\n",
    "\n",
    "if local_path.exists():\n",
    "    print(f\"{local_path} already exists, skipping download.\")\n",
    "else:\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        local_path.write_bytes(response.content)\n",
    "        print(f\"File downloaded and saved as {local_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download the file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d37fd8",
   "metadata": {},
   "source": [
    "下载完成后，我们可以使用 LangChain 中的 SQLDatabase 来实现连接。这里我们打印一下数据库语言、可用的表名称以及通过 db.run 执行了一个简单的 SQL 查询语句："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13d8f633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialect: sqlite\n",
      "Available tables: ['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n",
      "Sample output: [(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
    "\n",
    "print(f\"Dialect: {db.dialect}\")\n",
    "print(f\"Available tables: {db.get_usable_table_names()}\")\n",
    "print(f'Sample output: {db.run(\"SELECT * FROM Artist LIMIT 5;\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d7d3ed",
   "metadata": {},
   "source": [
    "完成数据准备后，我们就可以开始尝试与关系数据库进行交互了。对于这类结构化数据，通常需要通过 SQL 语句来完成查询与分析操作。然而，手动编写 SQL 查询既繁琐又容易出错，特别是在面对复杂表结构或多表关联时。\n",
    "\n",
    "为此，LangChain 提供了一个专门面向关系数据库的工具包 — SQLDatabaseToolkit。它能够结合大语言模型的自然语言理解能力，自动将用户提出的问题转化为正确的 SQL 查询语句并执行，从而显著简化数据库交互过程。我们只需将语言模型（LLM）和数据库实例（DB）传入该工具包即可完成初始化，整个查询过程无需手动编写 SQL："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01a44520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "\n",
    "model = ChatTongyi(model=\"qwen-max\")\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ed413f",
   "metadata": {},
   "source": [
    "我们可以打印一下这里面包含的工具信息及对应的描述："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d28c0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql_db_query: Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\n",
      "\n",
      "sql_db_schema: Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3\n",
      "\n",
      "sql_db_list_tables: Input is an empty string, output is a comma-separated list of tables in the database.\n",
      "\n",
      "sql_db_query_checker: Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tools = toolkit.get_tools()\n",
    "for tool in tools:\n",
    "  print(f\"{tool.name}: {tool.description}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bacd55",
   "metadata": {},
   "source": [
    "下一步我们就可以准备开始组装 agent 了，和之前一样，假如我们不需要考虑记忆的话，我们需要准备模型、工具以及系统提示词三部分。\n",
    "\n",
    "前两部分我们已经准备好了，下面我们就来看看如何设计系统提示词："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66ddc196",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an agent designed to interact with a SQL database.\n",
    "Given an input question, create a syntactically correct {dialect} query to run,\n",
    "then look at the results of the query and return the answer. Unless the user\n",
    "specifies a specific number of examples they wish to obtain, always limit your\n",
    "query to at most {top_k} results.\n",
    "\n",
    "You can order the results by a relevant column to return the most interesting\n",
    "examples in the database. Never query for all the columns from a specific table,\n",
    "only ask for the relevant columns given the question.\n",
    "\n",
    "You MUST double check your query before executing it. If you get an error while\n",
    "executing a query, rewrite the query and try again.\n",
    "\n",
    "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the\n",
    "database.\n",
    "\n",
    "To start you should ALWAYS look at the tables in the database to see what you\n",
    "can query. Do NOT skip this step.\n",
    "\n",
    "Then you should query the schema of the most relevant tables.\n",
    "\"\"\".format(\n",
    "    dialect=db.dialect,\n",
    "    top_k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9025d8",
   "metadata": {},
   "source": [
    "然后我们就可以将这三部分内容串联起来组合成最后的 agent："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2983665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(model, tools, system_prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0bf153",
   "metadata": {},
   "source": [
    "然后将这个 agent 进行调用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "608a3f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Which genre on average has the longest tracks?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_list_tables (call_17de76bc7e3a4358bb0f9c)\n",
      " Call ID: call_17de76bc7e3a4358bb0f9c\n",
      "  Args:\n",
      "    tool_input: \n",
      "  sql_db_schema (call_12f7cfaed7544a88ad9dd1)\n",
      " Call ID: call_12f7cfaed7544a88ad9dd1\n",
      "  Args:\n",
      "    table_names: tracks, genres\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_schema\n",
      "\n",
      "Error: table_names {'tracks', 'genres'} not found in database\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_schema (call_38f5b6d1a5a048888d927f)\n",
      " Call ID: call_38f5b6d1a5a048888d927f\n",
      "  Args:\n",
      "    table_names: Track, Genre\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_schema\n",
      "\n",
      "\n",
      "CREATE TABLE \"Genre\" (\n",
      "\t\"GenreId\" INTEGER NOT NULL, \n",
      "\t\"Name\" NVARCHAR(120), \n",
      "\tPRIMARY KEY (\"GenreId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Genre table:\n",
      "GenreId\tName\n",
      "1\tRock\n",
      "2\tJazz\n",
      "3\tMetal\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE \"Track\" (\n",
      "\t\"TrackId\" INTEGER NOT NULL, \n",
      "\t\"Name\" NVARCHAR(200) NOT NULL, \n",
      "\t\"AlbumId\" INTEGER, \n",
      "\t\"MediaTypeId\" INTEGER NOT NULL, \n",
      "\t\"GenreId\" INTEGER, \n",
      "\t\"Composer\" NVARCHAR(220), \n",
      "\t\"Milliseconds\" INTEGER NOT NULL, \n",
      "\t\"Bytes\" INTEGER, \n",
      "\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \n",
      "\tPRIMARY KEY (\"TrackId\"), \n",
      "\tFOREIGN KEY(\"MediaTypeId\") REFERENCES \"MediaType\" (\"MediaTypeId\"), \n",
      "\tFOREIGN KEY(\"GenreId\") REFERENCES \"Genre\" (\"GenreId\"), \n",
      "\tFOREIGN KEY(\"AlbumId\") REFERENCES \"Album\" (\"AlbumId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Track table:\n",
      "TrackId\tName\tAlbumId\tMediaTypeId\tGenreId\tComposer\tMilliseconds\tBytes\tUnitPrice\n",
      "1\tFor Those About To Rock (We Salute You)\t1\t1\t1\tAngus Young, Malcolm Young, Brian Johnson\t343719\t11170334\t0.99\n",
      "2\tBalls to the Wall\t2\t2\t1\tNone\t342562\t5510424\t0.99\n",
      "3\tFast As a Shark\t3\t2\t1\tF. Baltes, S. Kaufman, U. Dirkscneider & W. Hoffman\t230619\t3990994\t0.99\n",
      "*/\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "To find out which genre on average has the longest tracks, I will join the `Track` and `Genre` tables using the `GenreId` column. Then I will calculate the average track length (in milliseconds) for each genre and order the results to find the genre with the highest average.\n",
      "\n",
      "Let me write the query to get this information.\n",
      "Tool Calls:\n",
      "  sql_db_query (call_3ee94d9bcb724035983100)\n",
      " Call ID: call_3ee94d9bcb724035983100\n",
      "  Args:\n",
      "    query: SELECT g.Name, AVG(t.Milliseconds) AS AverageLength FROM Track t JOIN Genre g ON t.GenreId = g.GenreId GROUP BY g.Name ORDER BY AverageLength DESC LIMIT 5;\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_query\n",
      "\n",
      "[('Sci Fi & Fantasy', 2911783.0384615385), ('Science Fiction', 2625549.076923077), ('Drama', 2575283.78125), ('TV Shows', 2145041.0215053763), ('Comedy', 1585263.705882353)]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The genre with the longest average track length is \"Sci Fi & Fantasy\" with an average of approximately 2,911,783 milliseconds (or about 48.53 minutes per track). Here are the top 5 genres with the longest average track lengths:\n",
      "\n",
      "1. Sci Fi & Fantasy - 2,911,783 ms\n",
      "2. Science Fiction - 2,625,549 ms\n",
      "3. Drama - 2,575,284 ms\n",
      "4. TV Shows - 2,145,041 ms\n",
      "5. Comedy - 1,585,264 ms\n",
      "\n",
      "Please note that these genres and their average track lengths seem unusually long, which might indicate that the data includes audiobooks or other long-form audio content rather than typical music tracks.\n"
     ]
    }
   ],
   "source": [
    "question = \"Which genre on average has the longest tracks?\"\n",
    "\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6fb9d1",
   "metadata": {},
   "source": [
    "其实对于让模型直接使用 SQL 语言进行操作时有风险的，虽然提示词已经进行了提醒，但是我们还可以给这个智能体加上人类介入的中间件 HumanInTheLoopMiddleware 来进一步规避最后使用 sql_db_query 工具时进行查询或调用的风险："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84c3521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware \n",
    "from langgraph.checkpoint.memory import InMemorySaver \n",
    "\n",
    "agent = create_agent(model, tools, system_prompt=system_prompt,\n",
    "    middleware=[HumanInTheLoopMiddleware( \n",
    "            interrupt_on={\"sql_db_query\": True}, \n",
    "            description_prefix=\"Tool execution pending approval\" )], \n",
    "    checkpointer=InMemorySaver(), \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26241ccd",
   "metadata": {},
   "source": [
    "然后我们同样可以对其进行调用，但这里添加了一个判定，假如遇到了 \"__interrupt__\" 的话就会停下来并返回相关的调用信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "988e99be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Which genre on average has the longest tracks?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_list_tables (call_bf20d9019f8044119e2ccc)\n",
      " Call ID: call_bf20d9019f8044119e2ccc\n",
      "  Args:\n",
      "    tool_input: \n",
      "  sql_db_schema (call_71fd9cdf0a144542b8877a)\n",
      " Call ID: call_71fd9cdf0a144542b8877a\n",
      "  Args:\n",
      "    table_names: tracks,genres\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_schema\n",
      "\n",
      "Error: table_names {'tracks', 'genres'} not found in database\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "It seems there was an error because the table names 'tracks' and 'genres' were not correctly recognized in the database. Let me first confirm the correct table names from the list of available tables.\n",
      "Tool Calls:\n",
      "  sql_db_schema (call_9fdfb8b710bc4a1c9ad89c)\n",
      " Call ID: call_9fdfb8b710bc4a1c9ad89c\n",
      "  Args:\n",
      "    table_names: Genre,Track\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_schema\n",
      "\n",
      "\n",
      "CREATE TABLE \"Genre\" (\n",
      "\t\"GenreId\" INTEGER NOT NULL, \n",
      "\t\"Name\" NVARCHAR(120), \n",
      "\tPRIMARY KEY (\"GenreId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Genre table:\n",
      "GenreId\tName\n",
      "1\tRock\n",
      "2\tJazz\n",
      "3\tMetal\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE \"Track\" (\n",
      "\t\"TrackId\" INTEGER NOT NULL, \n",
      "\t\"Name\" NVARCHAR(200) NOT NULL, \n",
      "\t\"AlbumId\" INTEGER, \n",
      "\t\"MediaTypeId\" INTEGER NOT NULL, \n",
      "\t\"GenreId\" INTEGER, \n",
      "\t\"Composer\" NVARCHAR(220), \n",
      "\t\"Milliseconds\" INTEGER NOT NULL, \n",
      "\t\"Bytes\" INTEGER, \n",
      "\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \n",
      "\tPRIMARY KEY (\"TrackId\"), \n",
      "\tFOREIGN KEY(\"MediaTypeId\") REFERENCES \"MediaType\" (\"MediaTypeId\"), \n",
      "\tFOREIGN KEY(\"GenreId\") REFERENCES \"Genre\" (\"GenreId\"), \n",
      "\tFOREIGN KEY(\"AlbumId\") REFERENCES \"Album\" (\"AlbumId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Track table:\n",
      "TrackId\tName\tAlbumId\tMediaTypeId\tGenreId\tComposer\tMilliseconds\tBytes\tUnitPrice\n",
      "1\tFor Those About To Rock (We Salute You)\t1\t1\t1\tAngus Young, Malcolm Young, Brian Johnson\t343719\t11170334\t0.99\n",
      "2\tBalls to the Wall\t2\t2\t1\tNone\t342562\t5510424\t0.99\n",
      "3\tFast As a Shark\t3\t2\t1\tF. Baltes, S. Kaufman, U. Dirkscneider & W. Hoffman\t230619\t3990994\t0.99\n",
      "*/\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "To find out which genre on average has the longest tracks, I will need to join the `Track` and `Genre` tables on the `GenreId` field. Then I can group by the genre and calculate the average track length (in milliseconds) for each genre. Finally, I'll order the results in descending order of the average length and limit the result to 1 to get the genre with the longest average track.\n",
      "\n",
      "Let me now construct and execute the SQL query.\n",
      "Tool Calls:\n",
      "  sql_db_query (call_8485fe6487cc43248df0d4)\n",
      " Call ID: call_8485fe6487cc43248df0d4\n",
      "  Args:\n",
      "    query: SELECT g.Name AS GenreName, AVG(t.Milliseconds) AS AverageLength FROM Track t JOIN Genre g ON t.GenreId = g.GenreId GROUP BY g.Name ORDER BY AverageLength DESC LIMIT 1;\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "To find out which genre on average has the longest tracks, I will need to join the `Track` and `Genre` tables on the `GenreId` field. Then I can group by the genre and calculate the average track length (in milliseconds) for each genre. Finally, I'll order the results in descending order of the average length and limit the result to 1 to get the genre with the longest average track.\n",
      "\n",
      "Let me now construct and execute the SQL query.\n",
      "Tool Calls:\n",
      "  sql_db_query (call_8485fe6487cc43248df0d4)\n",
      " Call ID: call_8485fe6487cc43248df0d4\n",
      "  Args:\n",
      "    query: SELECT g.Name AS GenreName, AVG(t.Milliseconds) AS AverageLength FROM Track t JOIN Genre g ON t.GenreId = g.GenreId GROUP BY g.Name ORDER BY AverageLength DESC LIMIT 1;\n"
     ]
    }
   ],
   "source": [
    "question = \"Which genre on average has the longest tracks?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}} \n",
    "\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
    "    config, stream_mode=\"values\"):\n",
    "    if \"messages\" in step:\n",
    "        step[\"messages\"][-1].pretty_print()\n",
    "    elif \"__interrupt__\" in step: \n",
    "        print(\"INTERRUPTED:\") \n",
    "        interrupt = step[\"__interrupt__\"][0] \n",
    "        for request in interrupt.value[\"action_requests\"]: \n",
    "            print(request[\"description\"]) \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60afce79",
   "metadata": {},
   "source": [
    "出现中断后我们可以通过 Command 里传入同意、不同意或修改几个可选项，然后让其进一步完成即可，最后模型找到足够的信息就会生成最终的回复："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30731aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "To find out which genre on average has the longest tracks, I will need to join the `Track` and `Genre` tables on the `GenreId` field. Then I can group by the genre and calculate the average track length (in milliseconds) for each genre. Finally, I'll order the results in descending order of the average length and limit the result to 1 to get the genre with the longest average track.\n",
      "\n",
      "Let me now construct and execute the SQL query.\n",
      "Tool Calls:\n",
      "  sql_db_query (call_8485fe6487cc43248df0d4)\n",
      " Call ID: call_8485fe6487cc43248df0d4\n",
      "  Args:\n",
      "    query: SELECT g.Name AS GenreName, AVG(t.Milliseconds) AS AverageLength FROM Track t JOIN Genre g ON t.GenreId = g.GenreId GROUP BY g.Name ORDER BY AverageLength DESC LIMIT 1;\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "To find out which genre on average has the longest tracks, I will need to join the `Track` and `Genre` tables on the `GenreId` field. Then I can group by the genre and calculate the average track length (in milliseconds) for each genre. Finally, I'll order the results in descending order of the average length and limit the result to 1 to get the genre with the longest average track.\n",
      "\n",
      "Let me now construct and execute the SQL query.\n",
      "Tool Calls:\n",
      "  sql_db_query (call_8485fe6487cc43248df0d4)\n",
      " Call ID: call_8485fe6487cc43248df0d4\n",
      "  Args:\n",
      "    query: SELECT g.Name AS GenreName, AVG(t.Milliseconds) AS AverageLength FROM Track t JOIN Genre g ON t.GenreId = g.GenreId GROUP BY g.Name ORDER BY AverageLength DESC LIMIT 1;\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_query\n",
      "\n",
      "[('Sci Fi & Fantasy', 2911783.0384615385)]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The genre with the longest average track length is \"Sci Fi & Fantasy\" with an average track length of approximately 2,911,783 milliseconds, or about 48.53 minutes.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.types import Command \n",
    "\n",
    "for step in agent.stream(\n",
    "    Command(resume={\"decisions\": [{\"type\": \"approve\"}]}), \n",
    "    config, stream_mode=\"values\",):\n",
    "    if \"messages\" in step:\n",
    "        step[\"messages\"][-1].pretty_print()\n",
    "    elif \"__interrupt__\" in step:\n",
    "        print(\"INTERRUPTED:\")\n",
    "        interrupt = step[\"__interrupt__\"][0]\n",
    "        for request in interrupt.value[\"action_requests\"]:\n",
    "            print(request[\"description\"])\n",
    "    else:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chapter_7_2025_12_15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
