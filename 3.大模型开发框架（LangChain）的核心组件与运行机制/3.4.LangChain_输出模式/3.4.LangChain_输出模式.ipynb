{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ç¯å¢ƒé…ç½®\n",
    "\n",
    "## 1.1 python ç¯å¢ƒå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: gradio==6.1.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (6.1.0)\n",
      "Requirement already satisfied: openai==2.11.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: dashscope==1.25.4 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (1.25.4)\n",
      "Requirement already satisfied: langchain-classic==1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain==1.1.3 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: langchain-community==0.4.1 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-openai==1.1.3 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (4.12.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (1.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (0.125.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (1.0.0)\n",
      "Requirement already satisfied: gradio-client==2.0.1 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (2.0.1)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (1.2.3)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (3.0.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (2.3.5)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (3.11.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (25.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (2.3.3)\n",
      "Requirement already satisfied: pillow<13.0,>=8.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (12.0.0)\n",
      "Requirement already satisfied: pydantic<=2.12.4,>=2.11.10 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (2.12.4)\n",
      "Requirement already satisfied: pydub in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (0.0.21)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (6.0.3)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (0.1.7)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (0.50.0)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (4.15.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (0.38.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from openai==2.11.0) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from openai==2.11.0) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from openai==2.11.0) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from openai==2.11.0) (4.67.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (3.13.2)\n",
      "Requirement already satisfied: requests in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (2.32.5)\n",
      "Requirement already satisfied: websocket-client in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (1.9.0)\n",
      "Requirement already satisfied: cryptography in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (46.0.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (2025.11.12)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (1.2.2)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (1.1.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.17 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (0.5.0)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (2.0.45)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain==1.1.3) (1.0.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (0.4.3)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain-openai==1.1.3) (0.12.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio-client==2.0.1->gradio==6.1.0) (2025.12.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from anyio<5.0,>=3.0->gradio==6.1.0) (3.11)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1) (0.9.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from fastapi<1.0,>=0.115.2->gradio==6.1.0) (0.0.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio==6.1.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio==6.1.0) (0.16.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio==6.1.0) (3.20.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio==6.1.0) (1.2.0)\n",
      "Requirement already satisfied: shellingham in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio==6.1.0) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio==6.1.0) (0.20.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic==1.0.0) (1.33)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic==1.0.0) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-classic==1.0.0) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (0.3.0)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (1.12.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic==1.0.0) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic==1.0.0) (0.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from pandas<3.0,>=1.0->gradio==6.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from pandas<3.0,>=1.0->gradio==6.1.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from pandas<3.0,>=1.0->gradio==6.1.0) (2025.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from pydantic<=2.12.4,>=2.11.10->gradio==6.1.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from pydantic<=2.12.4,>=2.11.10->gradio==6.1.0) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from pydantic<=2.12.4,>=2.11.10->gradio==6.1.0) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community==0.4.1) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from requests->dashscope==1.25.4) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from requests->dashscope==1.25.4) (2.6.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from sqlalchemy<3.0.0,>=1.4.0->langchain-classic==1.0.0) (3.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai==1.1.3) (2025.11.3)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from typer<1.0,>=0.12->gradio==6.1.0) (8.3.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from typer<1.0,>=0.12->gradio==6.1.0) (14.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio==6.1.0) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio==6.1.0) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==6.1.0) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==6.1.0) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==6.1.0) (0.1.2)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from cryptography->dashscope==1.25.4) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from cffi>=2.0.0->cryptography->dashscope==1.25.4) (2.23)\n"
     ]
    }
   ],
   "source": [
    "! pip install gradio==6.1.0 openai==2.11.0 dashscope==1.25.4 langchain-classic==1.0.0 langchain==1.1.3 langchain-community==0.4.1 langchain-openai==1.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 å¤§æ¨¡å‹å¯†é’¥å‡†å¤‡\n",
    "\n",
    "è¯·æ ¹æ®ç¬¬ä¸€ç« å†…å®¹è·å–ç›¸å…³å¹³å°çš„ API KEYï¼Œå¦‚è‹¥æœªåœ¨ç³»ç»Ÿå˜é‡ä¸­å¡«å…¥ï¼Œè¯·å°† API_KEY ä¿¡æ¯å†™å…¥ä»¥ä¸‹ä»£ç ï¼ˆè‹¥å·²è®¾ç½®è¯·å¿½ç•¥ï¼‰ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxx\"\n",
    "# os.environ[\"DASHSCOPE_API_KEY\"] = \"sk-yyyyyyyy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. æµå¼è¾“å‡º\n",
    "\n",
    "## 2.1 æµå¼è¾“å‡ºç®€ä»‹\n",
    "\n",
    "åœ¨ä¼ ç»Ÿ LLM åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬å¸¸è§çš„äº¤äº’æ¨¡å¼æ˜¯ï¼šå‘é€å®Œæ•´è¯·æ±‚ â†’ æ¨¡å‹æ€è€ƒ â†’ ç­‰å¾…ä¸€æ®µæ—¶é—´ â†’ è¿”å›å®Œæ•´ç­”æ¡ˆã€‚\n",
    "\n",
    "ä½†åœ¨çœŸå®åº”ç”¨ï¼ˆå°¤å…¶æ˜¯èŠå¤©ã€æ™ºèƒ½ä½“ã€å·¥å…·è°ƒç”¨ï¼‰ä¸­ï¼Œè¿™ç§â€œå…¨ç­‰å¼å“åº”â€ä¼šé€ æˆä»¥ä¸‹é—®é¢˜ï¼š\n",
    "- å“åº”å»¶è¿Ÿé«˜ï¼ˆè¦ç­‰æ‰€æœ‰ token è¾“å‡ºå®Œæ‰æ˜¾ç¤ºï¼‰ï¼›\n",
    "- ç”¨æˆ·ä½“éªŒå·®ï¼ˆçœ‹èµ·æ¥å¡é¡¿ï¼‰ï¼›\n",
    "- æ— æ³•å®æ—¶å±•ç¤ºæ¨¡å‹çš„æ¨ç†è¿‡ç¨‹æˆ–ä¸­é—´é˜¶æ®µï¼ˆå¦‚ tool è°ƒç”¨ã€çŠ¶æ€æ›´æ–°ï¼‰ã€‚\n",
    "\n",
    "æ‰€ä»¥ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå°±å‡ºç°äº†æµå¼è¾“å‡ºï¼ˆStreamingï¼‰çš„æœºåˆ¶ï¼Œè®©æ¨¡å‹è¿˜æ²¡æœ‰ç”Ÿæˆå®Œç­”æ¡ˆçš„æ—¶å€™å°±èƒ½å¤Ÿè·å–æ­£åœ¨è¾“å‡ºçš„ç»“æœã€‚ç›®å‰å¤§éƒ¨åˆ†çš„å¤§æ¨¡å‹å¯¹è¯åº”ç”¨éƒ½å·²ç»å®ç°äº†è¯¥æŠ€æœ¯ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 æ™®é€šè¾“å‡ºä¸æµå¼è¾“å‡ºå¯¹æ¯”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 æ™®é€šè¾“å‡º\n",
    "\n",
    "æ™®é€šè¾“å‡ºæˆ‘ä»¬éœ€è¦ç­‰å¾…æ¯”è¾ƒé•¿æ—¶é—´æ‰èƒ½è·å¾—å›å¤ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='äººå·¥æ™ºèƒ½æ˜¯æ¨¡æ‹Ÿäººç±»æ™ºèƒ½ï¼Œä½¿æœºå™¨å…·å¤‡å­¦ä¹ ã€æ¨ç†ã€æ„ŸçŸ¥ä¸å†³ç­–ç­‰èƒ½åŠ›ä»¥è‡ªä¸»å®Œæˆå¤æ‚ä»»åŠ¡çš„å…ˆè¿›æŠ€æœ¯ã€‚' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 5, 'total_tokens': 30, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'ernie-4.0-turbo-128k', 'system_fingerprint': None, 'id': 'as-w0w6h9wcqe', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b2fb2-bb50-7f93-87df-44634676cd1a-0' usage_metadata={'input_tokens': 5, 'output_tokens': 25, 'total_tokens': 30, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "llm = ChatOpenAI(model=\"ernie-4.0-turbo-128k\",\n",
    "  openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "  base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä¸€ä¸‹ {topic}\")\n",
    "\n",
    "chain = prompt | llm \n",
    "\n",
    "result = chain.invoke({\"topic\": \"äººå·¥æ™ºèƒ½\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 æµå¼è¾“å‡º\n",
    "\n",
    "æµå¼è¾“å‡ºæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸€ä¸ªä¸ª token è¾“å‡ºå±•ç¤ºå‡ºæ¥ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "äººå·¥æ™ºèƒ½æ˜¯æ¨¡æ‹Ÿäººç±»æ™ºèƒ½ï¼Œä½¿æœºå™¨å…·å¤‡å­¦ä¹ ã€æ¨ç†ã€æ„ŸçŸ¥ä¸å†³ç­–ç­‰èƒ½åŠ›ä»¥å®Œæˆå¤æ‚ä»»åŠ¡çš„è·¨å­¦ç§‘æŠ€æœ¯ã€‚"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "llm = ChatOpenAI(model=\"ernie-4.0-turbo-128k\",\n",
    "  openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "  base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä¸€ä¸‹ {topic}\")\n",
    "\n",
    "chain = prompt | llm \n",
    "\n",
    "for chunk in chain.stream({\"topic\": \"äººå·¥æ™ºèƒ½\"}):\n",
    "  # chunk æ˜¯ ChatMessage å¯¹è±¡æˆ–å­—ç¬¦ä¸²ç‰‡æ®µ\n",
    "  print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Gradio é¡µé¢å®ç°æµå¼è¾“å‡º\n",
    "\n",
    "### 2.3.1 åœ¨ ChatBot ä¸­å®ç°æµå¼è¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "import os\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "model=\"ernie-3.5-8k\",\n",
    "openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"You are a helpful assistant.\"),\n",
    "  MessagesPlaceholder(variable_name=\"chat_history\"), \n",
    "  (\"human\", \"{input}\")])\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "session_store = {}\n",
    "\n",
    "def get_session_history(session_id):\n",
    "  if session_id not in session_store:\n",
    "    session_store[session_id] = ChatMessageHistory()\n",
    "  return session_store[session_id]\n",
    "\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "  runnable=chain,\n",
    "  get_session_history=get_session_history,\n",
    "  input_messages_key=\"input\",\n",
    "  history_messages_key=\"chat_history\"\n",
    ")\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "session_id = \"session_test5\"\n",
    "\n",
    "def chat_stream(message, history):\n",
    "  history = history or []\n",
    "  full_reply = \"\"\n",
    "\n",
    "  # ä½¿ç”¨ stream() é€æ­¥è¾“å‡º\n",
    "  for chunk in chain_with_history.stream(\n",
    "    {\"input\": message},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}):\n",
    "    delta = getattr(chunk, \"content\", None) or \"\"\n",
    "    full_reply += delta\n",
    "\n",
    "    # é€æ­¥è¿”å›ç´¯ç§¯çš„å®Œæ•´å†…å®¹\n",
    "    yield \"\", history + [\n",
    "      {\"role\": \"user\", \"content\": message},\n",
    "      {\"role\": \"assistant\", \"content\": full_reply}]\n",
    "    \n",
    "with gr.Blocks() as demo:\n",
    "  gr.Markdown(\"## ğŸ¤– æµå¼èŠå¤©æœºå™¨äººï¼ˆå¸¦è®°å¿†åŠŸèƒ½ï¼‰\")\n",
    "  chatbot = gr.Chatbot(label=\"LangChain ChatBot\")\n",
    "  msg = gr.Textbox(placeholder=\"å’Œæˆ‘èŠèŠå§...\", lines=1)\n",
    "\n",
    "  # ç”¨ stream å‡½æ•°ç»‘å®š msg.submit\n",
    "  msg.submit(chat_stream, [msg, chatbot], [msg, chatbot])\n",
    "\n",
    "  gr.ClearButton([msg, chatbot])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 åœ¨ ChatInterface ä¸­å®ç°æµå¼è¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "session_store = {}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in session_store:\n",
    "        session_store[session_id] = ChatMessageHistory()\n",
    "    return session_store[session_id]\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"ernie-3.5-8k\",\n",
    "    openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    runnable=chain,\n",
    "    get_session_history=get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "def llm_response(message, history):\n",
    "    session_id = \"session_test6\"\n",
    "    stream = chain_with_history.stream(\n",
    "        {\"input\": message},\n",
    "        config={\"configurable\": {\"session_id\": session_id}})\n",
    "\n",
    "    partial_text = \"\"\n",
    "    \n",
    "    for chunk in stream: \n",
    "        if hasattr(chunk, \"content\") and chunk.content:\n",
    "            partial_text += chunk.content\n",
    "            yield partial_text\n",
    "\n",
    "\n",
    "demo = gr.ChatInterface(fn=llm_response)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. è¾“å‡ºè§£æå™¨\n",
    "\n",
    "## 3.1 ç®€ä»‹\n",
    "\n",
    "åœ¨ä¼ ç»Ÿçš„ LLM åº”ç”¨ä¸­ï¼Œæ¨¡å‹çš„è¾“å‡ºç»“æœé€šå¸¸æ˜¯çº¯è‡ªç„¶è¯­è¨€æ–‡æœ¬ï¼Œä¾‹å¦‚ä¸€å¤§æ®µæè¿°æ€§å›ç­”ã€‚\n",
    "\n",
    "ç„¶è€Œï¼Œåœ¨å¾ˆå¤šå®é™…åº”ç”¨ä¸­ï¼ˆå¦‚é—®ç­”ç³»ç»Ÿã€æ•°æ®æŠ½å–ã€ä»£ç ç”Ÿæˆã€æ™ºèƒ½ä½“ä»»åŠ¡åˆ†è§£ç­‰ï¼‰ï¼Œæˆ‘ä»¬å¸Œæœ›æ¨¡å‹çš„è¾“å‡ºèƒ½è¢«ç¨‹åºç›´æ¥è§£æå’Œä½¿ç”¨ï¼Œè€Œä¸ä»…ä»…æ˜¯â€œè¯»èµ·æ¥é€šé¡ºâ€çš„æ–‡å­—ã€‚\n",
    "\n",
    "ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå°±å‡ºç°äº†â€œç»“æ„åŒ–è¾“å‡ºï¼ˆStructured Outputï¼‰â€æœºåˆ¶â€”â€”è®©å¤§æ¨¡å‹åœ¨ç”Ÿæˆå†…å®¹æ—¶ï¼Œéµå¾ªç‰¹å®šçš„ç»“æ„æˆ–æ ¼å¼ï¼ˆå¦‚ JSONã€Pydanticã€Schemaï¼‰ï¼Œä»è€Œå®ç°å¯æ§ã€å¯è§£æã€å¯ç¼–ç¨‹åŒ–çš„ç»“æœè¿”å›ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 å­—ç¬¦ä¸²è§£æå™¨ï¼ˆStrOutputParserï¼‰\n",
    "\n",
    "åœ¨å‰é¢ LCEL é‡Œæˆ‘ä»¬çŸ¥é“ï¼Œåœ¨ç»è¿‡ llm åï¼Œæˆ‘ä»¬è¿”å›å†…å®¹çš„æ ¼å¼æ˜¯ AIMessageã€‚ä½†æ˜¯è¿™ä¸ªæ ¼å¼æ˜¯ LangChain é‡Œè‡ªè¡Œå®šä¹‰çš„ç±»ï¼Œåå¤„ç†èµ·æ¥æ¯”è¾ƒéº»çƒ¦ã€‚å› æ­¤æˆ‘ä»¬å¯ä»¥è€ƒè™‘åœ¨åé¢æ·»åŠ ä¸€ä¸ªå­—ç¬¦ä¸²è§£æå™¨ï¼ˆStrOutputParserï¼‰ï¼Œä»è€Œä½¿å¾—è¿”å›çš„å†…å®¹æ ¼å¼å˜ä¸ºå­—ç¬¦ä¸²ï¼Œè¿™æ ·ç›¸å¯¹å°±å¥½å¤„ç†ä¸€äº›\n",
    "\n",
    "### 3.2.1 æœªæ·»åŠ è¾“å‡ºè§£æå™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'> content='äººå·¥æ™ºèƒ½æ˜¯æ¨¡æ‹Ÿäººç±»æ™ºèƒ½ï¼Œä½¿æœºå™¨å…·å¤‡å­¦ä¹ ã€æ¨ç†ã€æ„ŸçŸ¥ä¸å†³ç­–ç­‰èƒ½åŠ›çš„æŠ€æœ¯é¢†åŸŸã€‚' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 7, 'total_tokens': 27, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'ernie-4.0-turbo-128k', 'system_fingerprint': None, 'id': 'as-dfrmyevhgb', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b2fb2-dad7-7a01-8a39-aad1978ec462-0' usage_metadata={'input_tokens': 7, 'output_tokens': 20, 'total_tokens': 27, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "llm = ChatOpenAI(model=\"ernie-4.0-turbo-128k\",\n",
    "  openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "  base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä¸€ä¸‹ {topic}\")\n",
    "\n",
    "chain = prompt | llm \n",
    "\n",
    "result = chain.invoke({\"topic\": \"ä¸€å¥è¯ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½\"})\n",
    "print(type(result), result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 æ·»åŠ å­—ç¬¦ä¸²è§£æå™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> äººå·¥æ™ºèƒ½æ˜¯æ¨¡æ‹Ÿäººç±»æ™ºèƒ½ï¼Œä½¿æœºå™¨èƒ½æ‰§è¡Œå­¦ä¹ ã€æ¨ç†ã€è§£å†³é—®é¢˜ç­‰å¤æ‚ä»»åŠ¡çš„å…ˆè¿›æŠ€æœ¯ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "\n",
    "llm = ChatOpenAI(model=\"ernie-4.0-turbo-128k\",\n",
    "  openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "  base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä¸€ä¸‹ {topic}\")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "result = chain.invoke({\"topic\": \"ä¸€å¥è¯ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½\"})\n",
    "print(type(result), result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 åˆ—è¡¨è§£æå™¨ï¼ˆCommaSeparatedListOutputParserï¼‰\n",
    "å½“æˆ‘ä»¬éœ€è¦å°†è¾“å‡ºçš„å†…å®¹è½¬åŒ–ä¸ºä¸€ä¸ªæ ¼å¼åŒ–çš„åˆ—è¡¨ï¼Œé‚£æˆ‘ä»¬å°±éœ€è¦ä½¿ç”¨LangChain ä¸­çš„è¾“å‡ºè§£æå™¨ CommaSeparatedListOutputParserã€‚å…¶åŸç†æ˜¯åŸºäºé€—å·å°†å¤šä¸ªå…ƒç´ è¿›è¡Œåˆ†éš”ï¼ˆå¦‚åœ°åã€å•†å“åã€å…³é”®å­—ç­‰ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åˆ—è¡¨ç»“æœï¼š ['`Python', 'Java', 'C++', 'JavaScript`']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹\n",
    "llm = ChatOpenAI(model=\"ernie-3.5-8k\",\n",
    "openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "# åˆå§‹åŒ–è§£æå™¨\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# è·å–æ ¼å¼æŒ‡ä»¤ï¼ˆåç»­è½½å…¥åˆ°å†…éƒ¨æç¤ºè¯ä¸­ï¼‰\n",
    "format_instructions = parser.get_format_instructions()\n",
    "# åˆ›å»ºå†…éƒ¨å¯¹è¯æç¤ºè¯æ¨¡ç‰ˆ\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "æå–ä»¥ä¸‹å¥å­ä¸­çš„ç¼–ç¨‹è¯­è¨€ï¼ŒæŒ‰æ ¼å¼è¦æ±‚è¾“å‡ºï¼š{format_instructions}\n",
    "å¥å­ï¼š{input}\"\"\")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "response = chain.invoke({\n",
    "  \"input\": \"ä»–ç†Ÿæ‚‰Pythonã€Javaå’ŒC++ï¼Œè¿˜å­¦è¿‡JavaScript\",\n",
    "  \"format_instructions\": format_instructions\n",
    "})\n",
    "\n",
    "print(\"åˆ—è¡¨ç»“æœï¼š\", response) # ['`Python', 'Java', 'C++', 'JavaScript`']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 å­—å…¸è§£æå™¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4.1 StructuredOutputParser\n",
    "\n",
    "StructuredOutputParser ä¼šå°†æ¨¡å‹è¾“å‡ºçš„ç»“æ„åŒ–å­—ç¬¦ä¸²è§£ææˆä¸€ä¸ª Python å­—å…¸ï¼ˆdictï¼‰ã€‚ä¸ºäº†ç²¾ç¡®çš„æ›´æ”¹å¯¹åº”çš„å†…å®¹ï¼Œéœ€è¦é€šè¿‡ ResponseSchema æ¥å¯¹å­—å…¸çš„é”®å’Œå€¼è¿›è¡Œæ˜ç¡®ï¼Œä¹Ÿå°±æ˜¯ä¸‹é¢æ‰€ç¤ºçš„ name å’Œ description ã€‚ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç»“æ„åŒ–ç»“æœï¼š {'product': 'æ— çº¿è€³æœº', 'price': '399', 'rating': '4.5'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_classic.output_parsers import StructuredOutputParser, ResponseSchema \n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "\n",
    "# 1. å®šä¹‰å­—æ®µ schemaï¼ˆåç§°+æè¿°ï¼‰\n",
    "response_schemas = [\n",
    "  ResponseSchema(name=\"product\", description=\"äº§å“åç§°\"),\n",
    "  ResponseSchema(name=\"price\", description=\"äº§å“ä»·æ ¼ï¼ˆæ•°å­—ï¼‰\"),\n",
    "  ResponseSchema(name=\"rating\", description=\"è¯„åˆ†ï¼ˆ1-5çš„æ•°å­—ï¼‰\")\n",
    "]\n",
    "# 2. åˆå§‹åŒ–ç»“æ„åŒ–è§£æå™¨\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "# 3. æ ¼å¼æŒ‡ä»¤ä¸æç¤ºè¯\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "llm = ChatOpenAI(model=\"ernie-3.5-8k\",\n",
    "openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "# è®¾ç½®æç¤ºè¯æ¨¡ç‰ˆ\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "è§£æä»¥ä¸‹äº§å“è¯„ä»·ä¸­çš„ä¿¡æ¯ï¼ŒæŒ‰æ ¼å¼è¦æ±‚è¾“å‡ºï¼š\n",
    "{format_instructions}\n",
    "è¯„ä»·ï¼š{input}\n",
    "\"\"\")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "response = chain.invoke({\n",
    "  \"input\": \"è¿™æ¬¾æ— çº¿è€³æœºå¾ˆå¥½ç”¨ï¼Œä»·æ ¼399å…ƒï¼Œæˆ‘ç»™4.5æ˜Ÿå¥½è¯„\",\n",
    "  \"format_instructions\": format_instructions\n",
    "})\n",
    "print(\"ç»“æ„åŒ–ç»“æœï¼š\", response)\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 JsonOutputParser + Pydantic\n",
    "\n",
    "ä½†æ˜¯å‰é¢è¿™ä¸ªæ–¹æ³•å·²ç»ä¸å†è¢«æ¨èä½¿ç”¨äº†ï¼ˆå·²ç»ç§»åŠ¨åˆ° langchain_classic ä¸­ï¼‰\n",
    "\n",
    "å‡å¦‚æˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿå¯¹é”®å’Œå€¼çš„æ•°æ®ç±»å‹è¿›è¡Œæ§åˆ¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ JsonOutputParser + Pydantic çš„æ–¹å¼è¿›è¡Œå®ç°ï¼Œå…¶ä¼šå°† LLM è¾“å‡ºè§£æä¸º JSON å­—ç¬¦ä¸² â†’ ç„¶åä½¿ç”¨ä½ å®šä¹‰çš„ Pydantic æ¨¡å‹ å¯¹è¿™ä¸ªç»“æ„è¿›è¡Œä¸¥æ ¼ç±»å‹æ ¡éªŒä¸éªŒè¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç»“æ„åŒ–ç»“æœï¼š {'product': 'æ— çº¿è€³æœº', 'price': 399, 'rating': 4.5}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# ä½¿ç”¨ Pydantic æ¨¡å‹å®šä¹‰è¾“å‡ºç»“æ„\n",
    "class ProductInfo(BaseModel):\n",
    " product: str = Field(description=\"äº§å“åç§°\")\n",
    " price: float = Field(description=\"äº§å“ä»·æ ¼\")\n",
    " rating: float = Field(description=\"è¯„åˆ†ï¼ˆ1-5çš„æ•°å­—ï¼‰\")\n",
    "parser = JsonOutputParser(pydantic_object=ProductInfo)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "llm = ChatOpenAI(model=\"ernie-3.5-8k\",\n",
    "openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "è§£æä»¥ä¸‹äº§å“è¯„ä»·ä¸­çš„ä¿¡æ¯ï¼ŒæŒ‰æ ¼å¼è¦æ±‚è¾“å‡ºï¼š\n",
    "{format_instructions}\n",
    "è¯„ä»·ï¼š{input}\"\"\")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "response = chain.invoke({\n",
    "  \"input\": \"è¿™æ¬¾æ— çº¿è€³æœºå¾ˆå¥½ç”¨ï¼Œä»·æ ¼399å…ƒï¼Œæˆ‘ç»™4.5æ˜Ÿå¥½è¯„\",\n",
    "  \"format_instructions\": format_instructions\n",
    "})\n",
    "print(\"ç»“æ„åŒ–ç»“æœï¼š\", response)\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 æ ¼å¼åŒ–è§£æå™¨\n",
    "\n",
    "åœ¨æ›´æ–°åçš„ LangChain æ ¼å¼åŒ–è¾“å‡ºæ–‡æ¡£ä¸­ï¼Œä¸€ç§ç»“åˆäº†æ¨¡å‹å’Œç»“æ„åŒ–è¾“å‡ºçš„æ–¹æ³• llm.with_structured_output()ï¼Œè¿™ä¸ªæ–¹æ³•å¯ä»¥ç›´æ¥æ”¾åœ¨ prompt åä½¿ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 ChatOpenAI æ ¼å¼åŒ–è§£æå™¨\n",
    "\n",
    "åœ¨ ChatOpenAI æ¨¡å‹é‡Œçš„ with_structured_output() ä¸­æ”¯æŒè¾“å…¥ä¸‰ç§æ ¼å¼çš„å†…å®¹ï¼š\n",
    "- function_callingï¼šä½¿ç”¨ OpenAI å·¥å…·è°ƒç”¨çš„æ–¹æ³•ï¼ˆä½†æ˜¯å½“å‰çš„æ¨¡å‹å¹¶ä¸æ”¯æŒï¼‰\n",
    "- json_modeï¼šåŸºäº OpenAI çš„ JSON æ¨¡å¼ï¼Œå¼ºåˆ¶æ¨¡å‹è¾“å‡ºçº¯ JSON å­—ç¬¦ä¸²\n",
    "- json_schemaï¼ˆé»˜è®¤ä½¿ç”¨ï¼‰ï¼šåŸºäº OpenAI æœ€æ–°çš„ç»“æ„åŒ–è¾“å‡º APIï¼Œç›´æ¥é€šè¿‡ response_format å‚æ•°æŒ‡å®š JSON schemaï¼Œæ¨¡å‹ä¼šä¸¥æ ¼æŒ‰ç…§ schema ç”Ÿæˆè¾“å‡º\n",
    "\n",
    "![gr.ren](images/æ–°6.png)\n",
    "\n",
    "é™¤æ­¤ä¹‹å¤–ï¼ŒInclude raw å‚æ•°è¡¨ç¤ºæœ€åè¾“å‡ºæ˜¯å¦è¿”å›å®Œæ•´çš„å­—å…¸ä¿¡æ¯ï¼ˆåŒ…å«ä¸‰ä¸ªé”® raw, parsed å’Œ parsing_errorï¼‰è€Œéå•çº¯çš„ç»“æ„åŒ–è¾“å‡ºå†…å®¹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### schema ç±»å‹\n",
    "é‚£åœ¨å‡½æ•°æ³¨é‡Šä¸­ï¼Œæ˜¾ç¤ºäº†å¯è¢«ä¼ å…¥çš„ schema æ ¼å¼åŒ…æ‹¬ï¼š\n",
    "\n",
    "- Pydantic class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ProductInfo(BaseModel):\n",
    "  \"\"\"äº§å“ä¿¡æ¯ç»“æ„ï¼ŒåŒ…æ‹¬åç§°ã€ä»·æ ¼ä¸è¯„åˆ†\"\"\"\n",
    "  product: str = Field(description=\"äº§å“åç§°\")\n",
    "  price: float = Field(description=\"äº§å“ä»·æ ¼\")\n",
    "  rating: float = Field(description=\"è¯„åˆ†ï¼ˆ1-5çš„æ•°å­—ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TypedDict class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict, Annotated\n",
    "\n",
    "class ProductInfoDict(TypedDict):\n",
    "  \"\"\"äº§å“ä¿¡æ¯ç»“æ„ï¼ŒåŒ…æ‹¬åç§°ã€ä»·æ ¼ä¸è¯„åˆ†\"\"\"\n",
    "  product: Annotated[str, {\"description\": \"äº§å“åç§°\"}]\n",
    "  price: Annotated[float, {\"description\": \"äº§å“ä»·æ ¼ï¼ˆæ•°å­—ï¼‰\"}]\n",
    "  rating: Annotated[float, {\"description\": \"è¯„åˆ†ï¼ˆ1-5ï¼‰\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- JSON Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = {\n",
    " \"title\": \"ProductInfo\",\n",
    " \"description\": \"äº§å“ä¿¡æ¯ç»“æ„ï¼ŒåŒ…æ‹¬åç§°ã€ä»·æ ¼ä¸è¯„åˆ†\",\n",
    " \"type\": \"object\",\n",
    " \"properties\": {\n",
    "  \"product\": {\n",
    "   \"type\": \"string\",\n",
    "   \"description\": \"äº§å“åç§°\"\n",
    "  },\n",
    "  \"price\": {\n",
    "   \"type\": \"number\",\n",
    "   \"description\": \"äº§å“ä»·æ ¼\"\n",
    "  },\n",
    "  \"rating\": {\n",
    "   \"type\": \"number\",\n",
    "   \"description\": \"è¯„åˆ†ï¼ˆ1-5ï¼‰\"\n",
    "  }\n",
    " },\n",
    " \"required\": [\"product\", \"price\", \"rating\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OpenAI function/tool schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_tool_schema = {\n",
    "  \"name\": \"ProductInfo\",\n",
    "  \"description\": \"äº§å“ä¿¡æ¯ç»“æ„ï¼ŒåŒ…æ‹¬åç§°ã€ä»·æ ¼ä¸è¯„åˆ†\",\n",
    "  \"parameters\": {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"product\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"äº§å“åç§°\"\n",
    "      },\n",
    "      \"price\": {\n",
    "        \"type\": \"number\",\n",
    "        \"description\": \"äº§å“ä»·æ ¼\"\n",
    "      },\n",
    "      \"rating\": {\n",
    "        \"type\": \"number\",\n",
    "        \"description\": \"è¯„åˆ†ï¼ˆ1-5ï¼‰\"\n",
    "      }\n",
    "    },\n",
    "    \"required\": [\"product\", \"price\", \"rating\"]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å®é™…ä¸Šï¼Œè¿™å››ç§æ ¼å¼çš„å†…å®¹éƒ½å¯ä»¥ç›´æ¥è½½å…¥ï¼Œå¹¶ä¸”æ–¹æ³•ä¹Ÿå¯ä»¥è¿›è¡Œéšæ„è¿›è¡Œé€‰æ‹©ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "llm = ChatOpenAI(model=\"ernie-3.5-8k\",\n",
    "openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "\n",
    "structured_model1 = llm.with_structured_output(openai_tool_schema, method=\"json_schema\")\n",
    "structured_model2 = llm.with_structured_output(json_schema, method=\"json_mode\")\n",
    "structured_model3 = llm.with_structured_output(ProductInfoDict, method=\"function_calling\")\n",
    "structured_model4 = llm.with_structured_output(ProductInfo, method=\"json_schema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é‚£æœ€åå¾—åˆ°çš„ç»“æœé™¤äº† Pydantic ç”Ÿæˆçš„æ˜¯ `<class '__main__.ProductInfo'>` ä»¥å¤–ï¼Œå…¶ä½™çš„éƒ½æ˜¯æ™®é€šçš„å­—å…¸å½¢æ€ `dict`ã€‚é‚£è¿™ä¸‰ä¸ªæ–¹æ³•çš„åŒºåˆ«åœ¨äºåˆ¤å®šçš„ä¸¥æ ¼ç¨‹åº¦ï¼š\n",
    "- json_schemaï¼šæœ€ä¸¥æ ¼ï¼ŒæŒ‰ schema æ ¼å¼ç”Ÿæˆ\n",
    "- function_callingï¼šéƒ¨åˆ†ä¸¥æ ¼ï¼ˆå­—æ®µå®Œæ•´ï¼Œä½†å†…å®¹çµæ´»ï¼‰\n",
    "- json_modeï¼šä¸ä¸¥æ ¼ï¼Œåªä¿è¯ JSON æ ¼å¼\n",
    "\n",
    "è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆåœ¨ LangChain ä¸­é»˜è®¤ä½¿ç”¨çš„æ˜¯ json_schema å½¢å¼ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é‚£å¯¹äºè¿™äº›ç”Ÿæˆçš„ structured_mode æ˜¯å¯ä»¥é€šè¿‡ LCEL é“¾ä¸ prompt è¿›è¡Œè¿æ¥çš„ï¼Œè¿™é‡Œæˆ‘ä»¬å°±ä»¥ Pydantic å’Œ json_schema æ¥è¿›è¡Œæ¼”ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç»“æ„åŒ–ç»“æœ1ï¼š {'äº§å“åç§°': 'æ— çº¿è€³æœº', 'äº§å“ä¼˜ç‚¹': 'å¾ˆå¥½ç”¨', 'ä»·æ ¼': '399å…ƒ', 'è¯„åˆ†': '4.5åˆ†', 'è¯„ä»·æ€åº¦': 'å¥½è¯„'} ç»“æ„åŒ–ç»“æœ2ï¼š product='æ— çº¿è€³æœº' price=399.0 rating=4.5\n",
      "<class 'dict'> <class '__main__.ProductInfo'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "è§£æä»¥ä¸‹äº§å“è¯„ä»·ä¸­çš„ä¿¡æ¯ï¼ŒæŒ‰æ ¼å¼è¦æ±‚è¾“å‡ºã€‚\n",
    "è¯„ä»·ï¼š{input}\"\"\")\n",
    "\n",
    "chain2 = prompt | structured_model2\n",
    "chain4 = prompt | structured_model4\n",
    "\n",
    "response1 = chain2.invoke({\"input\": \"è¿™æ¬¾æ— çº¿è€³æœºå¾ˆå¥½ç”¨ï¼Œä»·æ ¼399å…ƒï¼Œæˆ‘ç»™4.5åˆ†å¥½è¯„\"})\n",
    "response2 = chain4.invoke({\"input\": \"è¿™æ¬¾æ— çº¿è€³æœºå¾ˆå¥½ç”¨ï¼Œä»·æ ¼399å…ƒï¼Œæˆ‘ç»™4.5åˆ†å¥½è¯„\"})\n",
    "print(\"ç»“æ„åŒ–ç»“æœ1ï¼š\", response1, \"ç»“æ„åŒ–ç»“æœ2ï¼š\", response2)\n",
    "print(type(response1), type(response2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 ChatTongyi æ ¼å¼åŒ–è§£æå™¨\n",
    "\n",
    "è€Œåœ¨ ChatTongyi ä¸­ï¼Œè™½ç„¶åŒæ ·æœ‰ with_structured_output æ–¹æ³•ï¼Œä½†æ˜¯å†…éƒ¨å´å¹¶æ²¡æœ‰ method è¿™ä¸ªå‚æ•°ï¼š\n",
    "\n",
    "![gr.ren1](images/æ–°7.png)\n",
    "\n",
    "ä½†æ˜¯åœ¨æºä»£ç ä¸­ä¹Ÿæ˜¯åˆ’åˆ†äº†ä¸¤ç§ä¸åŒçš„å¤„ç†åœºæ™¯ï¼Œä¸€ç§æ˜¯å¯¹äºæ™®é€šçš„ç»“æ„åŒ–è¾“å…¥ï¼Œé‚£ä¼šä½¿ç”¨ function_calling çš„æ–¹å¼è¿›è¡Œå¤„ç†ã€‚è€Œé’ˆå¯¹äº Pydantic æ ¼å¼çš„å†…å®¹ï¼Œåˆ™ä¼šè¿›è¡Œç‰¹æ®Šå¤„ç†å°†æ ¼å¼åŒ–çš„å†…å®¹è½¬ä¸º Pydantic å¯¹è±¡ã€‚\n",
    "\n",
    "#### Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product='æ— çº¿è€³æœº' price=399.0 rating=4.5\n",
      "<class '__main__.ProductInfo'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatTongyi\n",
    "llm = ChatTongyi(model=\"qwen-max\") \n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ProductInfo(BaseModel):\n",
    "  \"\"\"äº§å“ä¿¡æ¯ç»“æ„ï¼ŒåŒ…æ‹¬åç§°ã€ä»·æ ¼ä¸è¯„åˆ†\"\"\"\n",
    "  product: str = Field(description=\"äº§å“åç§°\")\n",
    "  price: float = Field(description=\"äº§å“ä»·æ ¼\")\n",
    "  rating: float = Field(description=\"è¯„åˆ†ï¼ˆ1-5çš„æ•°å­—ï¼‰\")\n",
    "\n",
    "structured_llm = llm.with_structured_output(ProductInfo)\n",
    "\n",
    "chain = prompt | structured_llm\n",
    "\n",
    "resp = chain.invoke({\"input\": \"è¿™æ¬¾æ— çº¿è€³æœºå¾ˆå¥½ç”¨ï¼Œä»·æ ¼399å…ƒï¼Œæˆ‘ç»™4.5æ˜Ÿå¥½è¯„\"})\n",
    "print(resp)\n",
    "print(type(resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ— çº¿è€³æœº\n"
     ]
    }
   ],
   "source": [
    "print(resp.product)   # è¾“å‡ºç»“æœä¸ºâ€œæ— çº¿è€³æœºâ€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TypeDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'product': 'æ— çº¿è€³æœº', 'price': 399, 'rating': 4.5}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import TypedDict, Annotated\n",
    "class ProductInfoDict(TypedDict):\n",
    "  product: Annotated[str, {\"description\": \"äº§å“åç§°\"}]\n",
    "  price: Annotated[float, {\"description\": \"äº§å“ä»·æ ¼ï¼ˆæ•°å­—ï¼‰\"}]\n",
    "  rating: Annotated[float, {\"description\": \"è¯„åˆ†ï¼ˆ1-5ï¼‰\"}]\n",
    "  \n",
    "structured_llm = llm.with_structured_output(ProductInfoDict)\n",
    "\n",
    "chain = prompt | structured_llm\n",
    "\n",
    "resp = chain.invoke({\"input\": \"è¿™æ¬¾æ— çº¿è€³æœºå¾ˆå¥½ç”¨ï¼Œä»·æ ¼399å…ƒï¼Œæˆ‘ç»™4.5æ˜Ÿå¥½è¯„\"})\n",
    "print(resp)\n",
    "print(type(resp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç»“æ„åŒ–ç»“æœï¼š {'product': 'æ— çº¿è€³æœº', 'price': 399, 'rating': 4.5}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "json_schema = {\n",
    "  \"title\": \"ProductInfo\",\n",
    "  \"description\": \"a product with details\",\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"product\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"äº§å“åç§°\"\n",
    "    },\n",
    "    \"price\": {\n",
    "      \"type\": \"number\",\n",
    "      \"description\": \"äº§å“ä»·æ ¼\"\n",
    "    },\n",
    "    \"rating\": {\n",
    "      \"type\": \"number\",\n",
    "      \"description\": \"è¯„åˆ†ï¼ˆ1-5ï¼‰\"\n",
    "    }\n",
    "  },\n",
    "  \"required\": [\"product\", \"price\", \"rating\"]\n",
    "}\n",
    "\n",
    "structured_model = llm.with_structured_output(json_schema)\n",
    "chain = prompt | structured_model\n",
    "response = chain.invoke({\"input\": \"è¿™æ¬¾æ— çº¿è€³æœºå¾ˆå¥½ç”¨ï¼Œä»·æ ¼399å…ƒï¼Œæˆ‘ç»™4.5æ˜Ÿå¥½è¯„\"})\n",
    "print(\"ç»“æ„åŒ–ç»“æœï¼š\", response)\n",
    "print(type(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chapter_3_2025_12_15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
