{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. LangChain 简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LangChain 是一个开源框架，旨在帮助开发者构建由大型语言模型（LLM）驱动的应用程序。\n",
    "- 它提供了一套模块化的工具和接口，简化了将语言模型集成到实际应用中的过程。\n",
    "- 通过 LangChain，开发者可以轻松地将 LLM 与外部数据源、工具和用户交互界面连接起来，构建功能丰富的智能应用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 主要模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 模型接口：支持接入各种语言模型，如 OpenAI、阿里通义千问等。\n",
    "2. 提示词模板：封装提示词结构，让提示词生成更加灵活、结构化。\n",
    "3. 内存：为模型添加“记忆力”，使其能记住上下文对话历史，构建更自然的多轮对话。\n",
    "4. 链：可以把多个模型调用组合成一个流程。例如：“用户问题 → 检索资料 → 整理答案 → 生成回复”。\n",
    "5. 文档加载与向量检索：支持将 PDF、网页、数据库等内容加载并构建向量索引，实现“检索增强生成”（RAG）。\n",
    "6. 工具调用与智能体：结合工具调用（如搜索引擎、计算器、数据库等）实现 LLM 自动决策与执行能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 环境配置\n",
    "\n",
    "## 2.1 python 环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T07:23:21.908705Z",
     "iopub.status.busy": "2025-09-20T07:23:21.908333Z",
     "iopub.status.idle": "2025-09-20T07:23:23.976947Z",
     "shell.execute_reply": "2025-09-20T07:23:23.975842Z",
     "shell.execute_reply.started": "2025-09-20T07:23:21.908674Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: gradio==6.1.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (6.1.0)\n",
      "Requirement already satisfied: openai==2.11.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: dashscope==1.25.4 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (1.25.4)\n",
      "Requirement already satisfied: langchain-classic==1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain==1.1.3 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: langchain-community==0.4.1 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-openai==1.1.3 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (4.12.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (1.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (0.125.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (1.0.0)\n",
      "Requirement already satisfied: gradio-client==2.0.1 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (2.0.1)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (1.2.3)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (3.0.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (2.3.5)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (3.11.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (25.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (2.3.3)\n",
      "Requirement already satisfied: pillow<13.0,>=8.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (12.0.0)\n",
      "Requirement already satisfied: pydantic<=2.12.4,>=2.11.10 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (2.12.4)\n",
      "Requirement already satisfied: pydub in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (0.0.21)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (6.0.3)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (0.1.7)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (0.50.0)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (4.15.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio==6.1.0) (0.38.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from openai==2.11.0) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from openai==2.11.0) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from openai==2.11.0) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from openai==2.11.0) (4.67.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (3.13.2)\n",
      "Requirement already satisfied: requests in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (2.32.5)\n",
      "Requirement already satisfied: websocket-client in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (1.9.0)\n",
      "Requirement already satisfied: cryptography in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (46.0.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from dashscope==1.25.4) (2025.11.12)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (1.2.2)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (1.1.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.17 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (0.5.0)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain-classic==1.0.0) (2.0.45)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain==1.1.3) (1.0.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain-community==0.4.1) (0.4.3)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain-openai==1.1.3) (0.12.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from gradio-client==2.0.1->gradio==6.1.0) (2025.12.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from aiohttp->dashscope==1.25.4) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from anyio<5.0,>=3.0->gradio==6.1.0) (3.11)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1) (0.9.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from fastapi<1.0,>=0.115.2->gradio==6.1.0) (0.0.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio==6.1.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio==6.1.0) (0.16.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio==6.1.0) (3.20.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio==6.1.0) (1.2.0)\n",
      "Requirement already satisfied: shellingham in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio==6.1.0) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio==6.1.0) (0.20.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic==1.0.0) (1.33)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic==1.0.0) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-classic==1.0.0) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (0.3.0)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain==1.1.3) (1.12.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic==1.0.0) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic==1.0.0) (0.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from pandas<3.0,>=1.0->gradio==6.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from pandas<3.0,>=1.0->gradio==6.1.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from pandas<3.0,>=1.0->gradio==6.1.0) (2025.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from pydantic<=2.12.4,>=2.11.10->gradio==6.1.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from pydantic<=2.12.4,>=2.11.10->gradio==6.1.0) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from pydantic<=2.12.4,>=2.11.10->gradio==6.1.0) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community==0.4.1) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from requests->dashscope==1.25.4) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from requests->dashscope==1.25.4) (2.6.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from sqlalchemy<3.0.0,>=1.4.0->langchain-classic==1.0.0) (3.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai==1.1.3) (2025.11.3)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from typer<1.0,>=0.12->gradio==6.1.0) (8.3.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from typer<1.0,>=0.12->gradio==6.1.0) (14.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio==6.1.0) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio==6.1.0) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==6.1.0) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==6.1.0) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==6.1.0) (0.1.2)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from cryptography->dashscope==1.25.4) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\lib\\site-packages (from cffi>=2.0.0->cryptography->dashscope==1.25.4) (2.23)\n"
     ]
    }
   ],
   "source": [
    "! pip install gradio==6.1.0 openai==2.11.0 dashscope==1.25.4 langchain-classic==1.0.0 langchain==1.1.3 langchain-community==0.4.1 langchain-openai==1.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 大模型密钥准备\n",
    "\n",
    "请根据第一章内容获取相关平台的 API KEY，如若未在系统变量中填入，请将 API_KEY 信息写入以下代码（若已设置请忽略）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxx\"\n",
    "# os.environ[\"DASHSCOPE_API_KEY\"] = \"sk-yyyyyyyy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 模型调用\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3.1 LangChain 中的模型调用方式概览\n",
    "\n",
    "在 LangChain 中，模型调用的方式主要分为两大类：\n",
    "\n",
    "1. **专门的模型库（langchain 库内置模型）**\n",
    "2. **LangChain Community（社区版模型集成）**\n",
    "\n",
    "下面详细介绍这两种方式的特点与适用场景。\n",
    "\n",
    "### 3.1.1 专门的模型库（LangChain 官方支持）\n",
    "\n",
    "LangChain 官方为主流大模型提供了专门的支持库，通常以 `langchain_<provider>` 的形式出现，例如：\n",
    "\n",
    "* **OpenAI**：`langchain_openai`\n",
    "* **Anthropic**：`langchain_anthropic`\n",
    "* **Cohere**：`langchain_cohere`\n",
    "\n",
    "#### 特点\n",
    "\n",
    "* **维护稳定**：由官方团队支持，API 更新及时\n",
    "* **文档完善**：有详细的官方示例与参数说明\n",
    "* **适合生产**：推荐在正式项目中使用\n",
    "\n",
    "\n",
    "### 3.1.2 LangChain Community（社区版模型集成）\n",
    "\n",
    "`langchain_community` 提供了大量社区贡献的模型、工具与数据源支持，包括：\n",
    "\n",
    "* **国产大模型**（如通义千问、文心一言）\n",
    "* **实验性模型**（如一些学术或个人项目）\n",
    "\n",
    "#### 特点\n",
    "\n",
    "* **模型多样**：覆盖官方未支持的大量模型\n",
    "* **更新频繁**：社区驱动，支持更多新兴模型\n",
    "* **适合探索**：适合做原型和尝鲜性功能\n",
    "\n",
    "\n",
    "### 3.1.3 对比总结\n",
    "\n",
    "| 方式                  | 主要来源 | 稳定性 | 覆盖模型    | 适用场景      |\n",
    "| ------------------- | ---- | --- | ------- | --------- |\n",
    "| 专门的模型库              | 官方维护 | 高   | 主流大模型   | 生产项目、长期维护 |\n",
    "| LangChain Community | 社区贡献 | 中   | 小众/国产模型 | 原型验证、功能扩展 |\n",
    "\n",
    "### 3.1.4 实际开发建议\n",
    "\n",
    "* **生产环境**：优先选择官方支持的专门模型库，稳定、文档完善\n",
    "* **快速原型**：可以结合社区模型，尝试更多模型和功能\n",
    "* **混合使用**：同一个项目中可根据需求混合调用两类模型，提升灵活性\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 AI Studio 模型调用\n",
    "\n",
    "由于 AI Studio 并未区分 LangChain 的社区版本和官方专门版本，但考虑到绝大多数模型均兼容 OpenAI 的调用格式，因此后续我们将统一使用 **langchain-openai** 库进行模型调用，以保证调用方式的简洁性、兼容性和维护的便利性。\n",
    "\n",
    "### 3.2.1 代码示例\n",
    "\n",
    "我们会发现，其实这个和我们前面通过 openai 库调用模型是非常类似的：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您好！AI Studio 是百度推出的一个集成了AI开发、实训、竞赛及社区交流的一站式平台，它主要面向AI开发者、学生及爱好者，旨在提供一个便捷、高效、全面的开发环境与学习资源。以下是对AI Studio的详细介绍：\n",
      "\n",
      "### 一、平台功能\n",
      "\n",
      "1. **在线开发环境**：\n",
      "\n",
      "\t* AI Studio提供了基于Jupyter Notebook的在线开发环境，支持Python语言，用户无需本地安装任何开发工具，只需通过浏览器即可进行AI模型的开发、训练和部署。\n",
      "\t* 平台内置了丰富的AI框架和库，如PaddlePaddle（飞桨）、TensorFlow、PyTorch等，以及数据处理、可视化等常用工具，方便用户快速搭建和调试模型。\n",
      "\n",
      "2. **实训项目**：\n",
      "\n",
      "\t* AI Studio提供了大量的实训项目，涵盖计算机视觉、自然语言处理、语音识别等多个AI领域。这些项目由浅入深，适合不同水平的开发者进行学习和实践。\n",
      "\t* 每个实训项目都配备了详细的教程和代码示例，帮助用户快速上手并理解AI模型的开发流程。\n",
      "\n",
      "3. **竞赛活动**：\n",
      "\n",
      "\t* AI Studio定期举办各种AI竞赛活动，如算法挑战赛、创新应用赛等。这些竞赛不仅为用户提供了展示自己才华的舞台，还有机会获得丰厚的奖金和荣誉证书。\n",
      "\t* 竞赛活动通常与实际应用场景紧密结合，有助于用户将所学知识应用于实际问题解决中。\n",
      "\n",
      "4. **社区交流**：\n",
      "\n",
      "\t* AI Studio拥有一个活跃的社区，用户可以在这里分享自己的开发经验、交流技术心得、寻求帮助和支持。\n",
      "\t* 社区中还有许多AI领域的专家和学者，他们会定期发布技术文章、举办线上讲座，为用户提供宝贵的学习资源。\n",
      "\n",
      "### 二、平台优势\n",
      "\n",
      "1. **一站式服务**：AI Studio集成了开发、实训、竞赛和社区交流等多种功能，为用户提供了一站式的AI开发体验。\n",
      "2. **资源丰富**：平台内置了大量的AI框架、库、教程和项目案例，方便用户快速学习和实践。\n",
      "3. **互动性强**：通过社区交流和竞赛活动，用户可以与其他开发者互动学习，共同进步。\n",
      "4. **支持广泛**：AI Studio支持多种操作系统和浏览器，用户可以在不同设备上随时随地进行开发和学习。\n",
      "\n",
      "### 三、使用场景\n",
      "\n",
      "1. **初学者入门**：对于AI领域的初学者来说，AI Studio提供了一个便捷的学习平台。他们可以通过实训项目和教程快速掌握AI开发的基础知识和技能。\n",
      "2. **进阶开发者实践**：对于有一定经验的开发者来说，AI Studio提供了丰富的项目案例和竞赛活动，帮助他们提升自己的实践能力和解决实际问题的能力。\n",
      "3. **团队协作与交流**：AI Studio的社区功能为开发者提供了一个团队协作和交流的平台。他们可以在这里分享自己的开发经验、寻求帮助和支持，共同推动AI技术的发展。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"), # 替换为你的 AI Studio API Key\n",
    "    base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\",  \n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[ \n",
    "        {\n",
    "            'role': 'system',  \n",
    "            'content': '你是 AI Studio 实训AI开发平台的开发者助理，你精通开发相关的知识，负责给开发者提供搜索帮助建议。'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user', \n",
    "            'content': '你好，请介绍一下AI Studio'\n",
    "        }\n",
    "    ],\n",
    "    model=\"ernie-3.5-8k\", \n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只不过这里定义的模型只有三个主要的参数需要设置：\n",
    "\n",
    "- **model**：调用模型的名称\n",
    "- **openai_api_key**：调用平台的 API_KEY\n",
    "- **base_url**：具体调用平台的位置\n",
    "\n",
    "那当然，这里只是把模型的实例生成出来了而已，后续的话我们还是需要基于这个实例去实现调用的，所以这个时候就需要 LangChain 里的 .invoke() 方法来实现调用了。最简单的场景下我们可以直接写入字符串的内容进去（作为 user_prompt）。假如我们还想设置系统提示词等等的内容，就需要我们后面讲到的 **提示词模版** 部分的内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T07:23:28.030850Z",
     "iopub.status.busy": "2025-09-20T07:23:28.030523Z",
     "iopub.status.idle": "2025-09-20T07:23:35.553950Z",
     "shell.execute_reply": "2025-09-20T07:23:35.553096Z",
     "shell.execute_reply.started": "2025-09-20T07:23:28.030823Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您好，我是百度公司开发的知识增强大语言模型，中文名是文心一言，英文名是ERNIE Bot。我基于Transformer结构，依托飞桨和文心大模型研发，擅长中文处理，也会英文，其他语言正在学习。我能够完成知识问答、文本创作、知识推理、数学计算、代码理解与编写等任务，没有个人属性或观点情感，严格遵守法律法规，注重用户隐私和数据安全。请问有什么可以帮您的吗？\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "  model=\"ernie-3.5-8k\",\n",
    "  openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "  base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\" \n",
    ")\n",
    "\n",
    "response = llm.invoke(\"你好，请介绍一下你自己\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 课堂练习\n",
    "\n",
    "请将上面的代码转化为函数(名称为llm_development)并用gradio界面进行连接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T07:24:09.951446Z",
     "iopub.status.busy": "2025-09-20T07:24:09.951091Z",
     "iopub.status.idle": "2025-09-20T07:24:09.954721Z",
     "shell.execute_reply": "2025-09-20T07:24:09.954036Z",
     "shell.execute_reply.started": "2025-09-20T07:24:09.951418Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！我是文心一言，英文名是ERNIE Bot，是百度公司研发的知识增强大语言模型。我基于Transformer结构，依托飞桨（PaddlePaddle）框架和文心大模型技术研发而成。我能够提供知识问答、文本创作、知识推理、数学计算、代码理解与编写、翻译等服务，还可以陪你聊天、分享笑话或讲故事。我严格遵守法律法规，注重用户隐私保护和数据安全。如果你有任何问题或需要帮助，欢迎随时告诉我！\n"
     ]
    }
   ],
   "source": [
    "# TODO：修改以下代码以完成任务\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "  model=\"ernie-3.5-8k\",\n",
    "  openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "  base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\" \n",
    ")\n",
    "\n",
    "response = llm.invoke(\"你好，请介绍一下你自己\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 习题答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\76391\\.conda\\envs\\chapter_3_2025_12_15\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7887\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7887/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 答案 gr.Interface \n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import gradio as gr\n",
    "import os\n",
    "\n",
    "def llm_development(question):\n",
    "    llm = ChatOpenAI(\n",
    "    model=\"ernie-3.5-8k\",\n",
    "    openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "    response = llm.invoke(question)\n",
    "    return response.content\n",
    "\n",
    "demo = gr.Interface(fn=llm_development, inputs=gr.Textbox(), outputs=gr.Textbox())\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7888\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7888/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 答案 gr.Blocks\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import gradio as gr\n",
    "import os\n",
    "\n",
    "def llm_development(question):\n",
    "    llm = ChatOpenAI(\n",
    "    model=\"ernie-3.5-8k\",\n",
    "    openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "    response = llm.invoke(question)\n",
    "    return response.content\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "  with gr.Row():\n",
    "    with gr.Column():\n",
    "      input = gr.Textbox()\n",
    "      send = gr.Button('发送')\n",
    "    output = gr.Textbox()\n",
    "  send.click(fn=llm_development, inputs=input,outputs=output)\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 LangChain-Community 模型调用\n",
    "\n",
    "- 并不是每个模型都有自己单独的包，大部分都是国外的大厂（比如 OpenAI、Google、Anthropic 等），而国内只有 Deepseek 有，并且支持力度也相对较低。\n",
    "- 而更多其他的模型是通过 langchain-community 来实现支持，比如前面提到的通义千问，这也是国内厂商里与 LangChain 适配程度比较高的模型（前提是根据第一章的指引获取到了 DASHSCOPE_API_KEY ："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！我是Qwen，是阿里云开发的一款超大规模语言模型。我被设计用来帮助用户生成各种类型的文本，如文章、故事、诗歌、故事等，并能够根据不同的场景和需求提供信息查询、知识解答、对话聊天等服务。无论是需要创意写作的灵感，还是寻求问题的答案，或是仅仅想找个人聊聊天，我都乐意尽我所能提供帮助。希望我能成为你的好帮手！如果你有任何问题或需要什么帮助，请随时告诉我。\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "\n",
    "# 不需要写入 url，已在内部默认写入\n",
    "llm = ChatTongyi(\n",
    "  model=\"qwen-max\",\n",
    "  api_key=os.environ.get(\"DASHSCOPE_API_KEY\"))  # 替换为你的 DashScope API Key\n",
    "\n",
    "response = llm.invoke(\"你好，请介绍一下你自己\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. LangChain 中的提示词模板\n",
    "\n",
    "在 LangChain 中，提示词模板（Prompt Template）是构建与模型交互的核心工具。它们用于将用户输入与固定的模板结构结合，从而生成结构化的 Prompt 传递给大模型。LangChain 提供了两种主要的提示词模板：\n",
    "\n",
    "1. **PromptTemplate**（适用于文本生成任务）\n",
    "2. **ChatPromptTemplate**（适用于多轮对话和聊天场景）\n",
    "\n",
    "下面分别介绍这两种模板的特点与使用方法。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 PromptTemplate\n",
    "\n",
    "`PromptTemplate` 主要用于**单轮文本生成**，适合于需要将变量动态填入固定模板的场景。\n",
    "\n",
    "### 4.1.1 PromptTemplate 使用示例（单变量）\n",
    "那在前面调用的时候，我们其实是直接在 .invoke() 里传入字符串来将问题传给大模型的。但是这种方式我们没有办法将动态的变量传入，所以我们可以使用 LangChain 的 PromptTemplate 来进行实现。\n",
    "\n",
    "比如下面我们传入的就一个变量 question ，这个时候假如我们把问题传入（“一句话介绍什么是人工智能”），在程序里并不是直接把这个问题传给大模型，而是先经过 template.format() 的方法，把变量先传进提示词里，然后再把组合后的提示词（“请回答以下问题：一句话介绍什么是人工智能”）传给到模型中。这样我们就可以动态的进行变量的调整了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T07:24:11.494686Z",
     "iopub.status.busy": "2025-09-20T07:24:11.494356Z",
     "iopub.status.idle": "2025-09-20T07:24:14.171151Z",
     "shell.execute_reply": "2025-09-20T07:24:14.170511Z",
     "shell.execute_reply.started": "2025-09-20T07:24:11.494661Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型回答: 人工智能是一门研究如何使计算机系统能够模拟、延伸和扩展人类智能，以实现类似人类感知、理解、学习、决策等能力的学科与技术。\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import os\n",
    "\n",
    "# 定义提示词模板\n",
    "template = PromptTemplate.from_template(\"请回答以下问题：{question}\")\n",
    "\n",
    "# 定义模型调用函数\n",
    "def llm_development(user_input):\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"ernie-3.5-8k\",\n",
    "        openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "        base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "    prompt = template.format(question=user_input)\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "user_question = \"一句话介绍什么是人工智能？\"\n",
    "answer = llm_development(user_question)\n",
    "print(\"模型回答:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 PromptTemplate 使用示例（多变量）\n",
    "\n",
    "假如有多个变量的调用方式也是类似的，我们也只需要在 template.format() 里依次将这些变量传入进去，这样就可以组合出我们想要的提示词了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型回答: 人工智能嘛，就是让电脑这“铁憨憨”努力学会像人类一样聪明地“搞事情”！\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import os\n",
    "\n",
    "# 定义包含多个变量的模板\n",
    "template = PromptTemplate.from_template(\n",
    "\"请用{style}的语气，回答以下{topic}问题：{question}\"\n",
    ")\n",
    "\n",
    "# 定义模型调用函数\n",
    "def llm_development(question, style, topic):\n",
    "    llm = ChatOpenAI(\n",
    "    model=\"ernie-3.5-8k\",\n",
    "    openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\"\n",
    "    )\n",
    "    # 在 format() 中传入多个变量\n",
    "    prompt = template.format(question=question, style=style, topic=topic)\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "# 调用示例\n",
    "question = \"一句话介绍人工智能的核心概念是什么？\"\n",
    "style = \"幽默\"\n",
    "topic = \"科技\"\n",
    "answer = llm_development(question, style, topic)\n",
    "print(\"模型回答:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 特点\n",
    "\n",
    "* **适合单轮交互**：简单、直接\n",
    "* **支持动态变量**：可在模板中插入多个变量\n",
    "* **灵活性强**：可结合任意模型使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 ChatPromptTemplate\n",
    "\n",
    "`ChatPromptTemplate` 专为**多轮对话**设计，支持系统消息（system）、用户消息（human）与 AI 消息（AI）的组合，非常适合聊天或多角色提示场景。\n",
    "\n",
    "### 4.2.1 ChatPromptTemplate 使用示例（单变量）\n",
    "\n",
    "相比于上面的的 PromptTemplate ，通过下面的代码我们可以看到，我们可以像 openai 格式一样的传入 system 和 user 的信息。类似的，我们也可以将变量传给 ChatPromptTemplate ，使其能够进行提示词的格式化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型回答: 人工智能是使计算机系统能模拟人类智能，具备学习、推理、感知、决策等能力以解决复杂问题的技术领域。\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"你是一个知识渊博、表达清晰的问答助手。\"),\n",
    "  (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "def llm_development(user_input):\n",
    "  llm = ChatOpenAI(\n",
    "    model=\"ernie-3.5-8k\",\n",
    "    openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\" \n",
    "  )\n",
    "  messages = chat_prompt.format_messages(question=user_input)\n",
    "  response = llm.invoke(messages)\n",
    "  return response.content\n",
    "\n",
    "user_question = \"一句话介绍什么是人工智能？\"\n",
    "answer = llm_development(user_question)\n",
    "print(\"模型回答:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 ChatPromptTemplate 使用示例（多变量）\n",
    "\n",
    "和 PromptTemplate 类似，ChatPromptTemplate 也可以传入多个变量。并且更好的一点是可以将变量放在不同的位置，比如下面的例子里我们就将变量分别放在 system 和 user 中，那在调用的时候只要名称是能够对应上就不会影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T14:43:23.636327Z",
     "iopub.status.busy": "2025-09-18T14:43:23.635986Z",
     "iopub.status.idle": "2025-09-18T14:43:23.894300Z",
     "shell.execute_reply": "2025-09-18T14:43:23.893092Z",
     "shell.execute_reply.started": "2025-09-18T14:43:23.636301Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型回答: 人工智能是使计算机系统能模拟人类智能，实现学习、推理、感知与决策等能力的技术领域。\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"你是一个{type}的问答助手。\"),\n",
    "  (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "def llm_development(user_input,system_input):\n",
    "    llm = ChatOpenAI(\n",
    "    model=\"ernie-3.5-8k\",\n",
    "    openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\" \n",
    "    )\n",
    "    messages = chat_prompt.format_messages(question=user_input, type=system_input)\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content\n",
    "\n",
    "type_assistant = \"知识渊博、表达清晰\"\n",
    "question = \"一句话介绍什么是人工智能？\"\n",
    "answer = llm_development(question, type_assistant)\n",
    "print(\"模型回答:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 课堂练习\n",
    "\n",
    "请将下边的代码从原本简单的输入 question 改造为通过 langchian 的 ChatPromptTemplate 传入系统提示词及用户提示词信息（页面也需要有两个输入的文本框来让用户进行设置）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7889\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7889/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO：请使用提示词模版对其进行改造\n",
    "from langchain_openai import ChatOpenAI\n",
    "import gradio as gr\n",
    "import os\n",
    "\n",
    "def llm_development(question):\n",
    "  llm = ChatOpenAI(model=\"ernie-3.5-8k\",\n",
    "  openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "  base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "  response = llm.invoke(question)\n",
    "  return response.content\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "  with gr.Row():\n",
    "    with gr.Column():\n",
    "      input = gr.Textbox()\n",
    "      send = gr.Button('发送')\n",
    "    output = gr.Textbox()\n",
    "  send.click(fn=llm_development, inputs=input,outputs=output)\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.2.3 特点\n",
    "\n",
    "* **支持多角色**：可定义 system、human、AI 等不同角色消息\n",
    "* **适合多轮对话**：自然模拟对话上下文\n",
    "* **可扩展性强**：适合复杂交互场景"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 对比总结\n",
    "\n",
    "| 模板类型               | 适用场景      | 主要特点        |\n",
    "| ------------------ | --------- | ----------- |\n",
    "| PromptTemplate     | 单轮文本生成    | 简单直接、动态变量支持 |\n",
    "| ChatPromptTemplate | 多轮对话、聊天场景 | 多角色支持、上下文管理 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chapter_3_2025_12_15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
