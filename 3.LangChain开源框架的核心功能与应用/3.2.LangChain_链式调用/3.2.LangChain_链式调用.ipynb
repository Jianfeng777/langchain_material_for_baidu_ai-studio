{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ç¯å¢ƒé…ç½®\n",
    "\n",
    "## 1.1 python ç¯å¢ƒå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T07:23:21.908705Z",
     "iopub.status.busy": "2025-09-20T07:23:21.908333Z",
     "iopub.status.idle": "2025-09-20T07:23:23.976947Z",
     "shell.execute_reply": "2025-09-20T07:23:23.975842Z",
     "shell.execute_reply.started": "2025-09-20T07:23:21.908674Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: langchain in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: openai in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langchain) (1.1.1)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langchain) (1.0.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langchain) (2.12.4)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (0.4.56)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.14)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langchain-community) (2.0.44)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langchain-community) (3.13.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langchain-community) (2.3.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.6.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\76391\\.conda\\envs\\baidu\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install openai==2.11.0 dashscope==1.25.4 langchain-classic==1.0.0 langchain==1.1.3 langchain-community==0.4.1 langchain-openai==1.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 å¤§æ¨¡å‹å¯†é’¥å‡†å¤‡\n",
    "\n",
    "è¯·æ ¹æ®ç¬¬ä¸€ç« å†…å®¹è·å–ç›¸å…³å¹³å°çš„ API KEYï¼Œå¦‚è‹¥æœªåœ¨ç³»ç»Ÿå˜é‡ä¸­å¡«å…¥ï¼Œè¯·å°† API_KEY ä¿¡æ¯å†™å…¥ä»¥ä¸‹ä»£ç ï¼ˆè‹¥å·²è®¾ç½®è¯·å¿½ç•¥ï¼‰ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxx\"\n",
    "# os.environ[\"DASHSCOPE_API_KEY\"] = \"sk-yyyyyyyy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LangChain é“¾è¯¦è§£\n",
    "\n",
    "åœ¨ LangChain ä¸­ï¼Œ**é“¾ï¼ˆChainï¼‰** æ˜¯æŒ‡å°†å¤šä¸ªç»„ä»¶ï¼ˆå¦‚æç¤ºè¯ã€æ¨¡å‹ã€è§£æå™¨ç­‰ï¼‰æŒ‰ç…§ä¸€å®šçš„é€»è¾‘é¡ºåºç»„åˆåœ¨ä¸€èµ·ï¼Œä»è€Œå®ç°ç«¯åˆ°ç«¯çš„ä»»åŠ¡å¤„ç†ã€‚ä¸‹é¢æˆ‘ä»¬ä¾æ¬¡ä»‹ç»ä¸»è¦çš„é“¾ç±»å‹å’Œå®ƒä»¬çš„æ¼”è¿›ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 LLMChain ï¼ˆæ—©æœŸç‰ˆæœ¬ï¼Œå·²è¢«æ·˜æ±°ï¼‰\n",
    "\n",
    "**LLMChain** æ˜¯ LangChain æ—©æœŸçš„æ ¸å¿ƒé“¾ï¼Œä¸»è¦ç”±å››ä¸ªéƒ¨åˆ†ç»„æˆï¼š\n",
    "\n",
    "1. **PromptTemplate**ï¼šæç¤ºè¯æ¨¡æ¿ï¼Œå®šä¹‰è¾“å…¥ç»“æ„\n",
    "2. **LLM**ï¼šè¯­è¨€æ¨¡å‹ï¼Œæ‰§è¡Œæ¨ç†\n",
    "3. **OutputParser**ï¼šè¾“å‡ºè§£æå™¨ï¼Œæ ¼å¼åŒ–æ¨¡å‹ç»“æœ\n",
    "4. **memory**ï¼šèŠå¤©è®°å¿†ï¼Œå­˜å‚¨å¯¹è¯çš„è¿‡ç¨‹\n",
    "\n",
    "åé¢ä¸¤éƒ¨åˆ†æˆ‘ä»¬å°†åœ¨åç»­çš„è¯¾ç¨‹ä¸­è¿›è¡Œè®²è§£ï¼Œé‚£åœ¨ä¸‹é¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡å°† LLMChain ç»‘å®š llm å’Œ ChatPromptTemplate ä¸¤éƒ¨åˆ†å†…å®¹ï¼Œæœ€ç»ˆå®ç°é“¾çš„è°ƒç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\76391\\AppData\\Local\\Temp\\ipykernel_26500\\514214940.py:20: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use `RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  conversation = LLMChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¨¡å‹å›ç­”: äººå·¥æ™ºèƒ½åº”ç”¨è¶…å¹¿æ³›å•¦ï¼Œåƒæ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ã€å›¾åƒè¯†åˆ«æŠ€æœ¯ã€è‡ªåŠ¨é©¾é©¶æ±½è½¦ã€æ™ºèƒ½åŒ»ç–—è¯Šæ–­ã€ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿè¿™äº›å¯éƒ½æ˜¯å®ƒå¤§æ˜¾èº«æ‰‹çš„åœ°æ–¹å‘¢ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_classic.chains import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "\n",
    "# 1. å®šä¹‰æç¤ºè¯æ¨¡æ¿\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ AI åŠ©æ‰‹\"),\n",
    "    (\"human\", \"å½“å‰é—®é¢˜ï¼š{current_question}\")\n",
    "])\n",
    "\n",
    "# 2. å®šä¹‰è¯­è¨€æ¨¡å‹\n",
    "llm = ChatOpenAI(\n",
    "    model=\"ernie-3.5-8k\",\n",
    "    openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\"\n",
    ")\n",
    "\n",
    "# 3. æ„å»º LLMChain\n",
    "conversation = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "# ç®€å•æ¼”ç¤º\n",
    "question = \"ä¸€å¥è¯äººå·¥æ™ºèƒ½çš„åº”ç”¨æœ‰å“ªäº›ï¼Ÿ\"\n",
    "response = conversation.invoke({\"current_question\": question})\n",
    "print(\"æ¨¡å‹å›ç­”:\", response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½†æ˜¯è‡ª LangChain v0.2 ä»¥åï¼ŒLLMChain ä¸å†è¢«å®˜æ–¹æ‰€æ¨èä½¿ç”¨ï¼ˆå¹¶å°†åœ¨ v1.0 æ—¶è¢«ä¸¢å¼ƒï¼‰ï¼Œè½¬è€Œæ˜¯æ¨å‡º LangChain çš„ä¸€ç§è¡¨è¾¾å¼è¯­è¨€ LCELã€‚\n",
    "LLMChainçš„ä¸»è¦é—®é¢˜åœ¨äºï¼š\n",
    "- è®°å¿†/å·¥å…·/è§£æè€¦åˆåº¦é«˜ï¼šè¿ç§»åˆ«çš„æ¨¡å‹æˆ–æ”¹è¾“å‡ºæ ¼å¼å®¹æ˜“ç‰µä¸€å‘è€ŒåŠ¨å…¨èº«ã€‚\n",
    "- æ‰©å±•æ€§å·®ï¼šä¸€æ—¦éœ€è¦æ–°å¢é€»è¾‘ï¼Œå¼€å‘è€…åªèƒ½é¢å¤–ç¼–å†™ Python ä»£ç ï¼Œæ— æ³•åœ¨é“¾ä¸­ç›´æ¥å®Œæˆæ‰©å±•ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 LCELï¼ˆLangChain Expression Languageï¼‰\n",
    "\n",
    "### 2.2.1 LCEL ç®€ä»‹\n",
    "\n",
    "**LCEL**ï¼ˆLangChain Expression Languageï¼‰æ˜¯ LangChain åœ¨ 0.2 ç‰ˆæœ¬ä¸­å¼•å…¥çš„ä¸€ç§å…¨æ–°æ„å»ºé“¾çš„æ–¹å¼ã€‚å®ƒä½¿ç”¨ç®¡é“ç¬¦ `|` å°†ä¸åŒçš„ç»„ä»¶çµæ´»ä¸²è”èµ·æ¥ï¼Œè®©é“¾å¼è°ƒç”¨çš„å¯è¯»æ€§å’Œæ‰©å±•æ€§å¤§å¹…æå‡ï¼ŒçœŸæ­£å®ç°äº†æ¨¡å—åŒ–ã€å£°æ˜å¼çš„å·¥ä½œæµè®¾è®¡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 RunnableLambda å°è£…å‡½æ•°èŠ‚ç‚¹\n",
    "\n",
    "å…ˆç®€å•è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯ RunnableLambda ï¼š\n",
    "- **Runnable**ï¼šéµå¾ª LangChain çš„ç»Ÿä¸€æ¥å£æ ‡å‡†ï¼Œå¯ä»¥æ¥å…¥ LCEL ç®¡é“ã€‚\n",
    "- **Lambda**ï¼šå…è®¸å°†ä»»æ„ Python å‡½æ•°ï¼ˆåŒæ­¥æˆ–å¼‚æ­¥ï¼‰å¿«é€ŸåŒ…è£…ä¸ºä¸€ä¸ªå¯æ‰§è¡ŒèŠ‚ç‚¹ã€‚\n",
    "\n",
    "\n",
    "å®ƒæœ¬è´¨ä¸Šå°±æ˜¯ä¸€ä¸ª **å‡½æ•° â†’ Runnable çš„é€‚é…å™¨**ï¼Œè®©ä½ åªéœ€ä¼ å…¥ä¸€ä¸ªç®€å•å‡½æ•°ï¼Œå°±èƒ½å¿«é€ŸæŠŠå®ƒæ¥åˆ°æ•´ä¸ª LCEL é“¾è·¯ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### åº”ç”¨åœºæ™¯1ï¼šç±»å‹å®¡æŸ¥\n",
    "\n",
    "æˆ‘ä»¬å¯ä»¥è®¾ç½®ä¸€ä¸ªç®€å•çš„ lambda å‡½æ•° `lambda x: print(\"ğŸ§ª å½“å‰æ•°æ®ç±»å‹ï¼š\", type(x)) or x` ï¼Œä»è€Œå®ç°ä¼ å…¥ä¸€ä¸ªå†…å®¹ `x` ï¼Œè¾“å‡ºæ‰“å°è¾“å…¥ x çš„ç±»å‹ï¼Œç„¶åæŠŠåŸæ ·çš„ x å†ä¼ ä¸‹å» `print(\"ğŸ§ª å½“å‰æ•°æ®ç±»å‹ï¼š\", type(x)) or x` ã€‚è¿™æ ·æˆ‘ä»¬æŠŠè¿™éƒ¨åˆ†å†…å®¹æ¥å…¥åˆ°åˆé€‚çš„ä½ç½®é‡Œï¼Œå°±èƒ½çœ‹åˆ° Runnable å¯¹è±¡çš„è¾“å…¥å’Œè¾“å‡ºæ ¼å¼äº†ã€‚\n",
    "\n",
    "è¿™é‡Œæˆ‘å†å¤šè®²ä¸€äº›ï¼Œå°±æ˜¯ä¸ºä»€ä¹ˆå¿…é¡» `or x` ï¼š\n",
    "\n",
    "* å¦‚æœåªæœ‰ `print(...)`ï¼Œå› ä¸ºè¿”å›å€¼æ˜¯ `None`ï¼Œåç»­èŠ‚ç‚¹ä¼šæ¥æ”¶åˆ° `None`ï¼Œå°±ä¸èƒ½æ­£å¸¸è¾“å‡ºæˆ‘ä»¬æƒ³è¦çš„å†…å®¹äº†ã€‚ä¹Ÿå°±æ„å‘³ç€ç®¡é“è¿ç®—ç¬¦çš„å‰åæ ¼å¼ä¸ç»Ÿä¸€ï¼Œæ— æ³•å°†çœŸå®çš„ä¿¡æ¯æ²¿ç€ç®¡é“è¿ç®—ç¬¦è¿è¾“äº†ã€‚\n",
    "* åŠ ä¸Š `or x`ï¼Œç¡®ä¿è¡¨è¾¾å¼çš„æœ€ç»ˆè¿”å›å€¼æ˜¯ `x` æœ¬èº«ã€‚å…¶å®è¿™æ ·çš„å†™æ³•ç­‰åŒäºä»¥ä¸‹çš„å‡½æ•°å†™æ³•ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug(x):\n",
    "    print(\"ğŸ§ª å½“å‰æ•°æ®ç±»å‹ï¼š\", type(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¯”å¦‚è¿™é‡Œæˆ‘ä»¬å°±å¯ä»¥çœ‹åˆ° `prompt` éœ€è¦ä¼ å…¥çš„æ ¼å¼æ˜¯ `<class 'dict'>` å­—å…¸ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª å½“å‰æ•°æ®ç±»å‹ï¼š <class 'dict'>\n",
      "å¹¿å·æ˜¯ä¸€åº§å†å²æ‚ ä¹…ã€å•†è´¸ç¹è£ã€ç¾é£ŸèŸèƒä¸”å…¼å…·ç°ä»£éƒ½å¸‚é­…åŠ›ä¸å²­å—æ–‡åŒ–ç‰¹è‰²çš„å›½é™…åŒ–å¤§éƒ½å¸‚ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "import os\n",
    "prompt = ChatPromptTemplate.from_template(\"ç”¨ä¸€å¥è¯ä»‹ç» {topic}\")\n",
    "llm = ChatOpenAI(model=\"ernie-3.5-8k\",\n",
    "openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "debug = RunnableLambda(lambda x: print(\"ğŸ§ª å½“å‰æ•°æ®ç±»å‹ï¼š\", type(x)) or x)\n",
    "chain = debug | prompt | llm\n",
    "print(chain.invoke({\"topic\":\"å¹¿å·\"}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™é‡Œæˆ‘ä»¬ä¹Ÿå°±å¯ä»¥è§‚å¯Ÿåˆ° `prompt` çš„è¾“å‡ºå’Œ `llm` çš„è¾“å…¥åº”è¯¥æ˜¯æ”¯æŒ `<class 'langchain_core.prompt_values.ChatPromptValue'> `ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª å½“å‰æ•°æ®ç±»å‹ï¼š <class 'langchain_core.prompt_values.ChatPromptValue'>\n",
      "å¹¿å·æ˜¯ä¸€åº§å†å²æ‚ ä¹…ã€å•†è´¸ç¹è£ã€ç¾é£ŸèŸèƒä¸”å……æ»¡ç°ä»£æ´»åŠ›çš„å›½é™…åŒ–å¤§éƒ½å¸‚ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "import os\n",
    "prompt = ChatPromptTemplate.from_template(\"ç”¨ä¸€å¥è¯ä»‹ç» {topic}\")\n",
    "llm = ChatOpenAI(model=\"ernie-3.5-8k\",\n",
    "openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "debug = RunnableLambda(lambda x: print(\"ğŸ§ª å½“å‰æ•°æ®ç±»å‹ï¼š\", type(x)) or x)\n",
    "chain = prompt | debug | llm\n",
    "print(chain.invoke({\"topic\":\"å¹¿å·\"}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™é‡Œæˆ‘ä»¬ä¹Ÿå°±å¯ä»¥è§‚å¯Ÿåˆ° `llm` çš„è¾“å‡ºåº”è¯¥æ˜¯ `<class 'langchain_core.messages.ai.AIMessage'>` ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª å½“å‰æ•°æ®ç±»å‹ï¼š <class 'langchain_core.messages.ai.AIMessage'>\n",
      "å¹¿å·æ˜¯ä¸€åº§å†å²æ‚ ä¹…ã€å•†è´¸ç¹è£ã€ç¾é£Ÿæ±‡èšä¸”å…¼å…·ç°ä»£éƒ½å¸‚é­…åŠ›ä¸å²­å—æ–‡åŒ–ç‰¹è‰²çš„å›½é™…åŒ–å¤§éƒ½å¸‚ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "import os\n",
    "prompt = ChatPromptTemplate.from_template(\"ç”¨ä¸€å¥è¯ä»‹ç» {topic}\")\n",
    "llm = ChatOpenAI(model=\"ernie-3.5-8k\",\n",
    "openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "debug = RunnableLambda(lambda x: print(\"ğŸ§ª å½“å‰æ•°æ®ç±»å‹ï¼š\", type(x)) or x)\n",
    "chain = prompt | llm | debug\n",
    "print(chain.invoke({\"topic\":\"å¹¿å·\"}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### åº”ç”¨åœºæ™¯2ï¼šæ’å…¥å‡½æ•°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å®é™…ä¸Š RunnableLambda ä¸ä»…ä»…èƒ½å°è£… Lambda å‡½æ•°ï¼Œæ­£å¸¸çš„ python å‡½æ•°ä¹Ÿèƒ½å¤Ÿè¿›è¡Œå°è£…ã€‚æ¯”å¦‚ä¸‹é¢æˆ‘ä»¬å°±åœ¨è¾“å…¥çš„å­—å…¸é‡ŒåŠ äº†ä¸€ä¸ªè¡¨æƒ…ç¬¦ğŸ”¥ã€‚æ¯”å¦‚ä¸‹é¢çš„ä¾‹å­é‡Œæˆ‘ä»¬ä¼ å…¥çš„æ˜¯ä¸€ä¸ªå­—å…¸ `{\"topic\":\"å¼€å¿ƒ\"}` ï¼Œé‚£ä¹ˆå½“ç»è¿‡è¿™ä¸ªå‡½æ•°ä»¥åå°±ä¼šå˜æˆ `{\"topic\":\"å¼€å¿ƒğŸ”¥\"}` ã€‚å½“ç„¶è¿™ä¸ªåªæ˜¯ä¸€ä¸ªå¾ˆç®€å•çš„ä¾‹å­ï¼Œæ²¡æœ‰å¤ªå¤šå®é™…ç”¨å¤„ï¼Œä½†æ˜¯æˆ‘ä»¬ä¹Ÿè¿˜æ˜¯å¯ä»¥æ ¹æ®éœ€è¦çš„æ ¼å¼å†…å®¹è¿›è¡Œä¿®æ”¹çš„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å¿ƒå¦‚ç‡åŸä¹‹ç«ï¼Œç¬é—´ç‚¹ç‡ƒå†…å¿ƒæ¯ä¸€å¤„è§’è½ï¼Œè®©ç”Ÿæ´»æ»¡æ˜¯ç¿çƒ‚å…‰èŠ’ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "import os\n",
    "prompt = ChatPromptTemplate.from_template(\"ç”¨ä¸€å¥è¯ä»‹ç» {topic}\")\n",
    "llm = ChatOpenAI(model=\"ernie-3.5-8k\",\n",
    "openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "\n",
    "def add_fire(input):\n",
    "    input[\"topic\"] += \"ğŸ”¥\"\n",
    "    return input\n",
    "\n",
    "chain = RunnableLambda(add_fire) | prompt | llm \n",
    "\n",
    "print(chain.invoke({\"topic\":\"å¼€å¿ƒ\"}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨ LangChain ä¸­ï¼Œé™¤äº†ä½¿ç”¨ RunnableLambda ä»¥å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥ç”¨ä¸€ä¸ªè£…é¥°å™¨ @chain æ¥å®šä¹‰ä¸€ä¸ªå‡½æ•°æˆä¸º Runnable å¯¹è±¡ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨è¯¥å‡½æ•°åç§°è½½å…¥åˆ° LCEL ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å¿ƒå¦‚ç‡åŸä¹‹ç«ï¼Œç¬é—´ç‚¹ç‡ƒå†…å¿ƒæ¯ä¸€å¯¸è§’è½ï¼Œè®©ç”Ÿæ´»æ»¡æ˜¯ç¿çƒ‚å…‰èŠ’ä¸æ— å°½æ¬¢ç•…ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import chain\n",
    "import os\n",
    "prompt = ChatPromptTemplate.from_template(\"ç”¨ä¸€å¥è¯ä»‹ç» {topic}\")\n",
    "llm = ChatOpenAI(model=\"ernie-3.5-8k\",\n",
    "openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "\n",
    "@chain\n",
    "def add_fire(input):\n",
    "    input[\"topic\"] += \"ğŸ”¥\"\n",
    "    return input\n",
    "\n",
    "chain = add_fire | prompt | llm \n",
    "\n",
    "print(chain.invoke({\"topic\":\"å¼€å¿ƒ\"}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 ä½¿ç”¨ RunnableMap å¹¶è¡Œå¤„ç†å¤šä¸ªå­—æ®µ\n",
    "\n",
    "æœ‰äº›ä»»åŠ¡æˆ‘ä»¬å¸Œæœ›åŒæ—¶å¤„ç†å¤šä¸ªæ•°æ®é¡¹ï¼Œæ¯”å¦‚å¤šä¸ªæç¤ºè¯æˆ–å¤šä¸ªæ¨¡å‹ï¼Œè¿™æ—¶å€™å°±å¯ä»¥ä½¿ç”¨ **RunnableMap** æ¥å®ç°ã€‚ **RunnableMap** æ˜¯ LangChain LCEL æä¾›çš„ä¸€ä¸ªç‰¹æ®Šçš„ Runnable èŠ‚ç‚¹ï¼Œç”¨äº**å¹¶è¡Œæ‰§è¡Œå¤šä¸ªå­ Runnable**ï¼Œå¹¶å°†å®ƒä»¬çš„ç»“æœæ”¶é›†åˆ°ä¸€ä¸ªå­—å…¸ä¸­è¿”å›ã€‚å®ƒé€‚åˆåŒæ—¶æ‰§è¡Œå¤šä¸ªäº’ä¸ä¾èµ–çš„ä»»åŠ¡ï¼Œæœ€ç»ˆæŠŠç»“æœç»Ÿä¸€æ±‡æ€»ã€‚è¿™ä¸ªæ—¶å€™ï¼Œä¸€æ¬¡ .invoke å°±ä¼šæœ‰å¤šä¸ªç»“æœåœ¨è¾“å‡ºä¸Šï¼Œå¹¶ä¸”ä¼šä»¥å¯¹åº”çš„åç§°å±•ç¤ºã€‚\n",
    "\n",
    "#### å·¥ä½œåŸç†\n",
    "\n",
    "* è¾“å…¥ï¼šä¸€ä¸ªæ•°æ® `x`\n",
    "* å†…éƒ¨ï¼šå°†åŒä¸€ä¸ªè¾“å…¥ `x` ä¼ é€’ç»™å¤šä¸ªå­ Runnableï¼Œæ¯ä¸ª Runnable ç‹¬ç«‹æ‰§è¡Œ\n",
    "* è¾“å‡ºï¼šä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºå­ Runnable çš„åå­—ï¼Œå€¼ä¸ºå¯¹åº”çš„æ‰§è¡Œç»“æœ\n",
    "\n",
    "#### ä»£ç ç¤ºä¾‹\n",
    "\n",
    "æ¯”å¦‚æˆ‘ä»¬åˆ†åˆ«è®¾ç½®äº†ä¸¤ä¸ªæç¤ºè¯ï¼Œç„¶åè®©è¿™ä¸¤ä¸ªæç¤ºè¯åˆ†åˆ«ä¼ ç»™åŒä¸€ä¸ªå¤§æ¨¡å‹ã€‚è¿è¡Œä¸‹é¢çš„ä»£ç æˆ‘ä»¬å°±ä¼šå‘ç°è¿”å›çš„ç»“æœå°±æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«äº† `a_result` å’Œ `b_result` çš„ä¸¤ä¸ªé”®ã€‚é‚£å…¶å¯¹åº”å›å¤çš„æ–‡æœ¬å†…å®¹å°±åœ¨å€¼é‡Œçš„ `content` é‡Œè¿›è¡Œä¿å­˜ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a_result': AIMessage(content='æˆ‘æ˜¯ç™¾åº¦å…¬å¸ç ”å‘çš„çŸ¥è¯†å¢å¼ºå¤§è¯­è¨€æ¨¡å‹ï¼Œä¸­æ–‡åæ˜¯æ–‡å¿ƒä¸€è¨€ï¼Œè‹±æ–‡åæ˜¯ERNIE Botã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 15, 'total_tokens': 35, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'ernie-3.5-8k', 'system_fingerprint': None, 'id': 'as-76cumv7epm', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b215d-dc79-7800-903e-12d3f999a92b-0', usage_metadata={'input_tokens': 15, 'output_tokens': 20, 'total_tokens': 35, 'input_token_details': {}, 'output_token_details': {}}), 'b_result': AIMessage(content='æˆ‘æ˜¯ç™¾åº¦å…¬å¸ç ”å‘çš„æ–‡å¿ƒä¸€è¨€ï¼Œå¹¶éOpenAIåˆ¶ä½œçš„å¤§æ¨¡å‹å“¦ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 16, 'total_tokens': 30, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'ernie-3.5-8k', 'system_fingerprint': None, 'id': 'as-mc4t7x05r5', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b215d-dc7b-7d31-9b2f-e438d45dbfb6-0', usage_metadata={'input_tokens': 16, 'output_tokens': 14, 'total_tokens': 30, 'input_token_details': {}, 'output_token_details': {}})}\n",
      "æˆ‘æ˜¯ç™¾åº¦å…¬å¸ç ”å‘çš„çŸ¥è¯†å¢å¼ºå¤§è¯­è¨€æ¨¡å‹ï¼Œä¸­æ–‡åæ˜¯æ–‡å¿ƒä¸€è¨€ï¼Œè‹±æ–‡åæ˜¯ERNIE Botã€‚\n",
      "æ ¹æ®ç›¸å…³è®¾å®šè¦æ±‚ï¼Œæˆ‘å¹¶éOpenAIåˆ¶ä½œçš„å¤§æ¨¡å‹ï¼Œæˆ‘æ˜¯ç™¾åº¦å…¬å¸ç ”å‘çš„æ–‡å¿ƒä¸€è¨€ï¼ˆERNIE Botï¼‰ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableMap\n",
    "import os\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(\"ä½ æ˜¯ç™¾åº¦åˆ¶ä½œçš„å¤§æ¨¡å‹ï¼Œä¸€å¥è¯å›ç­”ç”¨æˆ·å‘ä½ æå‡ºé—®é¢˜ï¼š {topic}\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\"ä½ æ˜¯OpenAIåˆ¶ä½œçš„å¤§æ¨¡å‹ï¼Œä¸€å¥è¯å›ç­”ç”¨æˆ·å‘ä½ æå‡ºé—®é¢˜ï¼š {topic}\")\n",
    "llm = ChatOpenAI(model=\"ernie-3.5-8k\",\n",
    "openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "\n",
    "chain = RunnableMap({\n",
    "    \"a_result\": prompt1 | llm,\n",
    "    \"b_result\": prompt2 | llm,\n",
    "})\n",
    "\n",
    "print(chain.invoke({\"topic\":\"ä½ æ˜¯è°ï¼Ÿ\"}))\n",
    "print(chain.invoke({\"topic\":\"ä½ æ˜¯è°ï¼Ÿ\"})[\"a_result\"].content)\n",
    "print(chain.invoke({\"topic\":\"ä½ æ˜¯è°ï¼Ÿ\"})[\"b_result\"].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 LCEL æ€»ç»“\n",
    "\n",
    "- é€šè¿‡ä¸Šé¢çš„ä»‹ç»ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ŒLCEL çš„å‡ºç°ä¸º LangChain å¸¦æ¥äº†å…¨æ–°çš„å·¥ä½œæµç¼–æ’æ–¹å¼ã€‚å®ƒä¸ä»…è®© Prompt â†’ LLM â†’ è§£æ â†’ åå¤„ç† çš„é“¾è·¯è¡¨è¾¾æ›´åŠ ç›´è§‚ï¼Œè¿˜é€šè¿‡ Runnable æ¥å£ã€ç®¡é“å¼è¯­æ³• å’Œ å¯ç»„åˆç»„ä»¶ï¼Œè®©æˆ‘ä»¬å¯ä»¥éšæ—¶æ¥å…¥è®°å¿†ã€æ£€ç´¢ã€å¹¶è¡Œå¤„ç†ç­‰å¤æ‚åŠŸèƒ½ï¼Œæå¤§æå‡äº†åº”ç”¨çš„çµæ´»æ€§å’Œå¯æ‰©å±•æ€§ã€‚\n",
    "\n",
    "- ç›¸æ¯”æ—©æœŸçš„ LLMChainï¼ŒLCEL æ›´åƒæ˜¯ä¸€ç§ å£°æ˜å¼å·¥ä½œæµè¯­è¨€ï¼Œå®ƒç»Ÿä¸€äº†è¾“å…¥è¾“å‡ºè§„èŒƒï¼Œæ”¯æŒå¼‚æ­¥ä¸æµå¼æ‰§è¡Œï¼ŒåŒæ—¶ä¸ LangSmith ç­‰å·¥å…·æ·±åº¦é›†æˆï¼Œæ–¹ä¾¿æˆ‘ä»¬è¿›è¡Œå¯è§†åŒ–è°ƒè¯•ä¸æ€§èƒ½ä¼˜åŒ–ã€‚æœªæ¥éšç€ LangChain ç”Ÿæ€çš„ä¸æ–­ä¸°å¯Œï¼ŒLCEL ä¹Ÿå°†æˆä¸ºæ„å»ºæ™ºèƒ½ä½“ã€å¤šæ¨¡å‹ååŒåº”ç”¨çš„æ ¸å¿ƒåŸºçŸ³ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 ç»„åˆé“¾ï¼ˆSequentialChainï¼‰\n",
    "\n",
    "åœ¨ LangChain ä¸­ï¼Œé™¤äº†æœ€åŸºç¡€çš„ **LLMChainï¼ˆæˆ–ç°åœ¨æ¨èçš„ LCEL é“¾ï¼‰** ä¹‹å¤–ï¼Œè¿˜å¯ä»¥æŠŠå¤šä¸ªé“¾ç»„åˆåœ¨ä¸€èµ·ï¼Œå½¢æˆä¸€ä¸ªæ›´å¤æ‚çš„å·¥ä½œæµï¼Œè¿™å°±æ˜¯**ç»„åˆé“¾ï¼ˆSequential Chainsï¼‰**ã€‚\n",
    "\n",
    "### 2.3.1 ç»„åˆé“¾çš„æ¦‚å¿µ\n",
    "\n",
    "ç»„åˆé“¾å…è®¸**å¤šä¸ªé“¾é¡ºåºæ‰§è¡Œ**ï¼Œä¸Šä¸€æ­¥çš„è¾“å‡ºå¯ä»¥ä½œä¸ºä¸‹ä¸€æ­¥çš„è¾“å…¥ï¼Œç›´åˆ°å½¢æˆä¸€ä¸ªå®Œæ•´çš„å¤šæ­¥éª¤å·¥ä½œæµã€‚ä¸»è¦åŒ…æ‹¬ä¸¤ç±»ï¼š\n",
    "\n",
    "* ç®€å•é¡ºåºé“¾\n",
    "* æ™®é€šé¡ºåºé“¾\n",
    "\n",
    "ä¸‹é¢æˆ‘ä»¬å°±æ¥è¯¦ç»†çš„ä»‹ç»ä¸€ä¸‹è¿™ä¸¤ç§é“¾çš„ä½¿ç”¨æ–¹å¼ï¼š\n",
    "\n",
    "### 2.3.2 SimpleSequentialChain\n",
    "\n",
    "### æ¦‚å¿µ\n",
    "\n",
    "* SimpleSequentialChain æ˜¯æœ€åŸºç¡€çš„ç»„åˆé“¾ã€‚\n",
    "* æ‰€æœ‰å­é“¾å…±äº«åŒä¸€ä¸ªè¾“å…¥è¾“å‡ºï¼ŒæŒ‰é¡ºåºä¾æ¬¡æ‰§è¡Œã€‚\n",
    "* ä¸Šä¸€ä¸ªå­é“¾çš„è¾“å‡ºä¼šè‡ªåŠ¨ä½œä¸ºä¸‹ä¸€ä¸ªå­é“¾çš„è¾“å…¥ï¼Œæ— éœ€æ‰‹åŠ¨æŒ‡å®šå˜é‡ã€‚\n",
    "\n",
    "#### ä»£ç ç¤ºä¾‹\n",
    "\n",
    "åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯ï¼šé€šè¿‡è¾“å…¥ä¸€ä¸ªä¸»é¢˜ï¼Œæœ€ç»ˆè·å–ä¸è¯¥ä¸»é¢˜ç›¸å…³çš„å…³é”®è¯ã€‚ä½†å¦‚æœç›´æ¥è®©å¤§æ¨¡å‹ä¸€æ­¥åˆ°ä½åœ°ç”Ÿæˆå…³é”®è¯ï¼Œå¾€å¾€ä¸å¤Ÿç²¾å‡†ã€‚å› æ­¤æˆ‘ä»¬é‡‡ç”¨**åˆ†æ­¥éª¤æ‹†è§£**çš„æ–¹å¼ï¼š\n",
    "\n",
    "1. **æ–‡ç« æ’°å†™**ï¼šå…ˆè®©æ¨¡å‹æ ¹æ®ä¸»é¢˜ç”Ÿæˆä¸€æ®µç®€çŸ­æ–‡ç« ã€‚\n",
    "2. **æ‘˜è¦æå–**ï¼šå†è®©æ¨¡å‹å¯¹æ–‡ç« è¿›è¡Œæ‘˜è¦ï¼Œä¿ç•™æ ¸å¿ƒä¿¡æ¯ã€‚\n",
    "3. **å…³é”®è¯æå–**ï¼šæœ€åä»æ‘˜è¦ä¸­æå–å…³é”®è¯ï¼Œç¡®ä¿å…³é”®è¯çš„å‡†ç¡®æ€§å’Œä»£è¡¨æ€§ã€‚\n",
    "\n",
    "è¿™ç§â€œåˆ†è€Œæ²»ä¹‹â€çš„ç­–ç•¥èƒ½è®©æ¯ä¸ªæ­¥éª¤èšç„¦äºä¸€ä¸ªå°ä»»åŠ¡ï¼Œé™ä½å‡ºé”™ç‡ï¼Œæå‡æœ€ç»ˆç»“æœçš„è´¨é‡ã€‚\n",
    "\n",
    "æ¥ä¸‹æ¥æˆ‘ä»¬å°†ä¸‰ä¸ªå­é“¾ç”¨ LCEL ç®¡é“ `|` ä¸²è”èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„å¤šæ­¥éª¤å·¥ä½œæµï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å…³é”®è¯ï¼š\n",
      "1. æ•°å­—åŒ–æ—¶ä»£\n",
      "2. äººå·¥æ™ºèƒ½\n",
      "3. AIæ•™è‚²\n",
      "4. å¤åˆå‹äººæ‰\n",
      "5. æ€ç»´å‡çº§\n",
      "6. æŒ‘æˆ˜\n",
      "7. ç”Ÿæ€ä½“ç³»\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "import os\n",
    "\n",
    "llm = ChatOpenAI(model=\"ernie-3.5-8k\",\n",
    "openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "\n",
    "prompt_1 = PromptTemplate.from_template(\"å†™ä¸€æ®µå…³äº{input}çš„ç®€çŸ­æ–‡ç« ã€‚\")\n",
    "chain_1 = prompt_1 | llm\n",
    "\n",
    "prompt_2 = PromptTemplate.from_template(\"è¯·æ€»ç»“ä»¥ä¸‹æ–‡ç« ï¼š{input}\")\n",
    "chain_2 = prompt_2 | llm\n",
    "\n",
    "prompt_3 = PromptTemplate.from_template(\"è¯·æå–ä»¥ä¸‹å†…å®¹çš„å…³é”®è¯ï¼š{input}\")\n",
    "chain_3 = prompt_3 | llm\n",
    "\n",
    "map_input = RunnableLambda(lambda x: {\"input\": x.content})\n",
    "\n",
    "# å°†ä¸‰ä¸ªå­é“¾ä¸²èµ·æ¥\n",
    "overall_chain = (\n",
    "    chain_1 |\n",
    "    map_input | chain_2 |\n",
    "    map_input | chain_3\n",
    ")\n",
    "\n",
    "# è°ƒç”¨æ•´ä¸ªé“¾\n",
    "result = overall_chain.invoke({\"input\": \"äººå·¥æ™ºèƒ½æ•™è‚²\"})\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### æŠ€æœ¯ç»†èŠ‚\n",
    "\n",
    "è¿™é‡Œæˆ‘è¡¥å……å‡ ä¸ªå­é“¾ä¸²è”çš„ä»£ç ç»†èŠ‚ã€‚é¦–å…ˆä¹‹æ‰€ä»¥è¦åœ¨ `chain_1` ã€`chain_2` å’Œ `chain_3` ä¹‹é—´æ·»åŠ ä¸Š `map_input` ï¼Œä¹Ÿå°±æ˜¯ `RunnableLambda(lambda x: {\"input\": x.content})` ã€‚å…¶å®ä¸»è¦åŸå› æ˜¯ `chain` çš„è¾“å‡ºæ ¼å¼æ˜¯ `AIMessages` ï¼Œè€Œ `chain` çš„è¾“å…¥æ ¼å¼æ˜¯å­—å…¸ã€‚å› æ­¤ä¸ºäº†èƒ½å¤Ÿæ»¡è¶³æ­£å¸¸çš„è¾“å…¥å’Œè¾“å‡ºï¼Œæˆ‘ä»¬å°±éœ€è¦å°†æ¯æ¬¡ `chain` çš„è¾“å‡ºå†…å®¹æå–ï¼ˆä¹Ÿå°±æ˜¯ `x.content` ï¼‰è¿›è¡Œæ ¼å¼ä¿®æ”¹ï¼Œå¹¶ä¸”å°†å…¶æ”¹é€ æˆåˆé€‚çš„å­—å…¸æ ¼å¼ï¼Œä¹Ÿå°±æ˜¯ `{\"input\": x.content}` ã€‚è¿™æ ·æˆ‘ä»¬å°±èƒ½å¤Ÿå­é“¾éƒ½è¿æ¥åœ¨ä¸€èµ·å¹¶è¿›è¡Œè°ƒç”¨äº†ã€‚\n",
    "\n",
    "å¦å¤–ï¼Œå…¶å®ä»æœ¬è´¨ä¸Šæ¥è¯´ï¼Œç›´æ¥ç”¨ lambda å‡½æ•°ä¹Ÿå¯ä»¥æŠŠè¿™äº›å†…å®¹ä¸²èµ·æ¥ï¼Œæ¯”å¦‚ `chain_1 | (lambda x:{\"input\": x.content}) | chain_2 ` è¿™æ ·ï¼Œä¹‹æ‰€ä»¥è¦æ”¹æˆ `RunnableLambda` çš„å½¢å¼æ˜¯å› ä¸ºå…¶æ˜¯ LangChain æ ‡å‡†åŒ–çš„ Runnable èŠ‚ç‚¹ï¼Œæ”¯æŒæ‰€æœ‰é“¾å¼åŠŸèƒ½ï¼Œå¯ä¸ LCEL ç®¡é“æ— ç¼è¡”æ¥ï¼Œæ‰©å±•æ€§æ›´å¼ºã€‚å¹¶ä¸”åæœŸè¿˜èƒ½é€šè¿‡å›è°ƒå’Œç›‘å¬æœºåˆ¶æ¥è·å–ä¿¡æ¯ã€‚å› æ­¤è¿™é‡Œå°±è¿˜æ˜¯ä½¿ç”¨ `RunnableLambda` çš„å½¢å¼ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Sequential Chain\n",
    "\n",
    "#### æ¦‚å¿µ\n",
    "\n",
    "**SequentialChain** æ˜¯ LangChain æä¾›çš„ä¸€ç§é¡ºåºç»„åˆé“¾ï¼Œå®ƒä¸ SimpleSequentialChain çš„åŒºåˆ«åœ¨äºï¼šSequentialChain å…è®¸æˆ‘ä»¬**æ˜¾å¼åœ°å®šä¹‰è¾“å…¥å’Œè¾“å‡ºå˜é‡**ï¼Œå¹¶èƒ½åœ¨å¤šä¸ªå­é“¾ä¹‹é—´çµæ´»ä¼ é€’æ•°æ®ã€‚å› æ­¤å®ƒæ›´é€‚åˆå¤æ‚åœºæ™¯ï¼Œæ¯”å¦‚éœ€è¦ç®¡ç†å¤šä¸ªè¾“å…¥ã€å¤šä¸ªè¾“å‡ºï¼Œæˆ–è€…ä¸åŒå­é“¾ä¹‹é—´å­˜åœ¨ä¾èµ–å…³ç³»çš„ä»»åŠ¡æµã€‚\n",
    "\n",
    "#### å·¥ä½œæœºåˆ¶\n",
    "\n",
    "* **è¾“å…¥å˜é‡**ï¼šç”±ç”¨æˆ·æ˜ç¡®æŒ‡å®šï¼Œå¯ä¼ é€’ç»™ä¸åŒå­é“¾ã€‚\n",
    "* **å­é“¾æ‰§è¡Œ**ï¼šæ¯ä¸ªå­é“¾çš„è¾“å‡ºä¼šè‡ªåŠ¨ä¿å­˜åˆ°ä¸Šä¸‹æ–‡ï¼Œå¹¶å¯ä¾›åç»­å­é“¾è°ƒç”¨ã€‚\n",
    "* **è¾“å‡ºå˜é‡**ï¼šæœ€ç»ˆè¿”å›æ—¶ï¼Œå¯ä»¥é€‰æ‹©éœ€è¦æš´éœ²ç»™å¤–éƒ¨çš„å˜é‡ã€‚\n",
    "\n",
    "SequentialChain çš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äº**å¯æ§æ€§å’Œçµæ´»æ€§**ï¼šä½ å¯ä»¥å†³å®šå“ªäº›å˜é‡ä½œä¸ºè¾“å…¥ï¼Œå“ªäº›ä½œä¸ºè¾“å‡ºï¼Œä»¥åŠå¦‚ä½•åœ¨é“¾è·¯ä¸­å¤ç”¨ä¸­é—´ç»“æœã€‚\n",
    "\n",
    "ä½†æ˜¯è¿™ç§ Chain å…¶å®å’Œ LLMChain ä¸€æ ·éƒ½å³å°†è¢« LCEL æ‰€å–ä»£ã€‚åœ¨ LCEL ä¸­ï¼Œ`SimpleSequentialChain` å’Œ `SequentialChain` çš„å·®åˆ«è¢«å¤§å¤§å¼±åŒ–ï¼Œå› ä¸º LCEL æœ¬èº«å°±é€šè¿‡ç®¡é“ç¬¦ `|` æ”¯æŒ**é¡ºåºç»„åˆ**å’Œ**æ•°æ®ä¼ é€’**ã€‚\n",
    "\n",
    "* **ç®€å•é¡ºåºé“¾**ï¼šåœ¨ LCEL ä¸­å¤©ç„¶å­˜åœ¨ï¼Œç›´æ¥ç”¨ `a | b | c` ä¸²èµ·æ¥å³å¯ï¼Œè¾“å…¥è¾“å‡ºä¼šè‡ªåŠ¨é¡ºåºä¼ é€’ï¼Œç›¸å½“äº SimpleSequentialChain çš„åŠŸèƒ½ã€‚\n",
    "\n",
    "* **æ™®é€šé¡ºåºé“¾**ï¼šåœ¨ LCEL ä¸­å¯ä»¥ç”¨ `RunnablePassthrough.assign(...)`ã€`RunnableMap` ç­‰æœºåˆ¶æ¥æ˜¾å¼ç®¡ç†è¾“å…¥è¾“å‡ºï¼ŒåŠŸèƒ½ä¸Šå’Œ SequentialChain ç±»ä¼¼ï¼Œç”šè‡³æ›´å¼ºå¤§ã€‚\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ä»£ç ç¤ºä¾‹\n",
    "\n",
    "åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬çš„ä»»åŠ¡æ˜¯ï¼š**åŸºäºç”¨æˆ·è¯„è®ºï¼Œè‡ªåŠ¨ç”Ÿæˆä¸€æ¡åˆé€‚çš„å•†å®¶å›å¤**ã€‚è¿™ä¸ªä»»åŠ¡çœ‹ä¼¼ç®€å•ï¼Œä½†å¦‚æœç›´æ¥è®©æ¨¡å‹ä¸€æ­¥ç”Ÿæˆï¼Œå¾€å¾€ä¼šé‡åˆ°ä»¥ä¸‹é—®é¢˜ï¼š\n",
    "\n",
    "* **å‡†ç¡®æ€§ä¸è¶³**ï¼šæ¨¡å‹å¯èƒ½é—æ¼è¯„è®ºä¸­çš„å…³é”®ä¿¡æ¯ã€‚\n",
    "* **è¯­è¨€æ··æ·†**ï¼šå¦‚æœè¯„è®ºä¸æ˜¯ä¸­æ–‡ï¼Œæ¨¡å‹ç”Ÿæˆçš„å›å¤å¯èƒ½ä¸ç¬¦åˆç”¨æˆ·åŸæœ¬çš„è¯­è¨€ä¹ æƒ¯ã€‚\n",
    "* **é€»è¾‘è·³è·ƒ**ï¼šç›´æ¥ç”Ÿæˆå›å¤å¯èƒ½ç¼ºä¹æ¨ç†è¿‡ç¨‹ï¼Œå¯¼è‡´é£æ ¼ä¸ä¸€è‡´æˆ–ç­”éæ‰€é—®ã€‚\n",
    "\n",
    "ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†**åˆ†æ­¥éª¤ã€å¤šé˜¶æ®µ**çš„å¤„ç†æ–¹å¼ï¼š\n",
    "\n",
    "1. **è¯„è®ºç¿»è¯‘**ï¼šæ— è®ºè¯„è®ºåŸæ–‡æ˜¯ä½•ç§è¯­è¨€ï¼Œå…ˆç¿»è¯‘æˆä¸­æ–‡ï¼Œæ–¹ä¾¿åç»­å¤„ç†ã€‚\n",
    "2. **å…³é”®é—®é¢˜æå–**ï¼šåŸºäºä¸­æ–‡ç¿»è¯‘ï¼ŒæŠ½å–è¯„è®ºé‡Œæœ€æ ¸å¿ƒçš„é—®é¢˜æˆ–è¯‰æ±‚ã€‚\n",
    "3. **è¯­è¨€è¯†åˆ«**ï¼šæ£€æµ‹åŸè¯„è®ºä½¿ç”¨çš„è¯­è¨€ï¼Œç¡®ä¿å•†å®¶å›å¤æ—¶ç”¨åŒæ ·çš„è¯­è¨€è¾“å‡ºã€‚\n",
    "4. **ç”Ÿæˆå•†å®¶å›å¤**ï¼šç»“åˆæç‚¼çš„æ€»ç»“ä¸è¯­è¨€ä¿¡æ¯ï¼Œæœ€ç»ˆç”Ÿæˆä¸€æ¡ä¸ç”¨æˆ·è¯­è¨€ä¸€è‡´çš„ã€é€»è¾‘æ¸…æ™°çš„å•†å®¶ç­”å¤ã€‚\n",
    "\n",
    "è¿™ç§åˆ†è€Œæ²»ä¹‹çš„ç­–ç•¥æœ‰å‡ ä¸ªå¥½å¤„ï¼š\n",
    "\n",
    "* **ä¿è¯å‡†ç¡®æ€§**ï¼šå…ˆç¿»è¯‘ã€å†æç‚¼ï¼Œç¡®ä¿æ¨¡å‹èšç„¦è¯„è®ºæœ¬èº«ã€‚\n",
    "* **ä¿æŒä¸€è‡´æ€§**ï¼šé€šè¿‡è¯­è¨€è¯†åˆ«ï¼Œä¿è¯æœ€ç»ˆå›å¤ä¸ç”¨æˆ·çš„è¯­è¨€ç¯å¢ƒä¸€è‡´ã€‚\n",
    "* **å¢å¼ºé²æ£’æ€§**ï¼šå¤šæ­¥éª¤æ‹†è§£ä½¿æ¯ä¸ªå­ä»»åŠ¡éƒ½æ›´ç®€å•ï¼Œé™ä½å¤§æ¨¡å‹â€œä¸€æ­¥åˆ°ä½â€æ—¶çš„åå·®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è°¢è°¢æ‚¨çš„å–œçˆ±å‘€ï¼Œèƒ½å¾—åˆ°æ‚¨è¿™ä¹ˆé«˜çš„è¯„ä»·æˆ‘ä»¬è¶…å¼€å¿ƒçš„ï¼ä¹‹åæˆ‘ä»¬ä¹Ÿä¼šç»§ç»­åŠªåŠ›ï¼Œç»™å¤§å®¶å¸¦æ¥æ›´å¤šä¼˜è´¨äº§å“å“’ï¼\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from langchain_core.runnables import RunnableMap, RunnableLambda\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹\n",
    "llm = ChatOpenAI(model=\"ernie-3.5-8k\",\n",
    "openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "base_url=\"https://aistudio.baidu.com/llm/lmapi/v3\")\n",
    "\n",
    "# ===== Step 1: ç¿»è¯‘è¯„è®º =====\n",
    "first_prompt = PromptTemplate.from_template(\"å°†ä»¥ä¸‹è¯„è®ºç¿»è¯‘æˆä¸­æ–‡ï¼š{Review}\")\n",
    "chain_one = first_prompt | llm  # LCEL é‡Œç”¨ | ä»£æ›¿ LLMChain\n",
    "\n",
    "# ===== Step 2: æå–å…³é”®é—®é¢˜ =====\n",
    "second_prompt = PromptTemplate.from_template(\"è¯·æå–è¯„è®ºä¸­æœ€å…³é”®çš„é—®é¢˜ï¼š{Chinese_Review}\")\n",
    "chain_two = second_prompt | llm\n",
    "\n",
    "# ===== Step 3: è¯†åˆ«è¯­è¨€ =====\n",
    "third_prompt = PromptTemplate.from_template(\"ä»¥ä¸‹è¯„è®ºæ˜¯ç”¨ä»€ä¹ˆè¯­è¨€å†™çš„ï¼š{Review}\")\n",
    "chain_three = third_prompt | llm\n",
    "\n",
    "# ===== Step 4: ç”Ÿæˆåç»­å›å¤ =====\n",
    "fourth_prompt = PromptTemplate.from_template(\n",
    "    \"æ ¹æ®ä»¥ä¸‹æ€»ç»“å’ŒæŒ‡å®šè¯­è¨€ï¼Œä»¥å•†å®¶çš„è§†è§’ï¼Œå†™ä¸€æ¡å¯¹åº”è¯­è¨€çš„åç»­å›å¤ï¼ˆæœ€ç»ˆåªéœ€è¦è¾“å‡ºä¸€æ¡ï¼‰ï¼š\\n\\næ€»ç»“: {summary}\\n\\nè¯­è¨€: {language}\"\n",
    ")\n",
    "chain_four = fourth_prompt | llm\n",
    "\n",
    "# ===== ç»„åˆé€»è¾‘ï¼šå…ˆä¸²è¡Œï¼Œå†ä¼ é€’å¿…è¦å˜é‡ =====\n",
    "overall_chain = (\n",
    "    RunnableMap({\n",
    "        \"summary\": chain_one | RunnableLambda(lambda x: {\"Chinese_Review\": x.content}) | chain_two,  # æå–é—®é¢˜\n",
    "        \"language\": chain_three                      # è¯†åˆ«è¯­è¨€\n",
    "    })\n",
    "    | RunnableLambda(lambda x: {\n",
    "        \"summary\": x[\"summary\"].content,\n",
    "        \"language\": x[\"language\"].content\n",
    "    })\n",
    "    | chain_four                                    # ç”Ÿæˆåç»­å›å¤\n",
    ")\n",
    "\n",
    "# è¿è¡Œ\n",
    "result = overall_chain.invoke({\"Review\": \"æˆ‘å¥½å–œæ¬¢è¿™ä¸ªäº§å“å‘€ï¼\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### æ€è·¯æ€»ç»“ä¸æ‰©å±•\n",
    "\n",
    "é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬å®ç°äº†ä¸€ä¸ª**å¤šé˜¶æ®µå¤„ç†ç®¡é“**ï¼š\n",
    "\n",
    "* **è¾“å…¥ç«¯**åªéœ€æä¾›ä¸€æ¡è¯„è®º\n",
    "* **ä¸­é—´æ­¥éª¤**åˆ†åˆ«è´Ÿè´£ç¿»è¯‘ã€é—®é¢˜æå–ã€è¯­è¨€è¯†åˆ«\n",
    "* **è¾“å‡ºç«¯**ç”Ÿæˆä¸€æ¡åˆé€‚çš„å•†å®¶å›å¤\n",
    "\n",
    "æœªæ¥æˆ‘ä»¬è¿˜å¯ä»¥å‚è€ƒè¿™ä¸ªæ–¹å¼ï¼Œå®ç°æ›´å¤šåˆ†æ”¯ã€å¹¶è¡Œå¤„ç†æˆ–æ›´å¤æ‚çš„å¤šæ­¥éª¤å·¥ä½œæµï¼Œä¾‹å¦‚ï¼š\n",
    "\n",
    "* å¤šè¯­è¨€åœºæ™¯ä¸‹çš„ä¸åŒæ–‡åŒ–é€‚é…\n",
    "* åŒæ—¶ç”Ÿæˆå•†å®¶å›å¤ä¸å†…éƒ¨å·¥å•\n",
    "* å¹¶è¡Œæ‰§è¡Œæƒ…æ„Ÿåˆ†æå’Œç”¨æˆ·ç”»åƒæå–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import trim_messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_2025_12_15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
